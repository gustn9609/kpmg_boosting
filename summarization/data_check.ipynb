{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "with open('/opt/ml/input/summarization/data/valid_original.json') as f:\n",
    "    a = json.load(f)\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'category', 'media_type', 'media_sub_type', 'media_name', 'size', 'char_count', 'publish_date', 'title', 'text', 'annotator_id', 'document_quality_scores', 'extractive', 'abstractive'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['documents'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"고 밝혔다.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내가 원하는 컬럼 원문, abstractive 내용. -> 이걸요약만하면 됨\n",
    "a['documents'][0]['text'][0][0]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No len more one\n"
     ]
    }
   ],
   "source": [
    "for i in a['documents']:\n",
    "    if len(i['abstractive']) != 1:\n",
    "        print(len(i['abstractive']))\n",
    "        break\n",
    "print('No len more one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a[\u001b[39m'\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([ \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([d[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m subls]) \u001b[39mfor\u001b[39;00m subls \u001b[39min\u001b[39;00m sublist[\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m]]) \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m a[\u001b[39m'\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]]))\n",
      "Cell \u001b[0;32mIn[44], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m a[\u001b[39m'\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([ \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([d[\u001b[39m'\u001b[39m\u001b[39msentence\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m subls]) \u001b[39mfor\u001b[39;00m subls \u001b[39min\u001b[39;00m sublist[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]]) \u001b[39mfor\u001b[39;00m sublist \u001b[39min\u001b[39;00m a[\u001b[39m'\u001b[39m\u001b[39mdocuments\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]]))\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
     ]
    }
   ],
   "source": [
    "a['documents'][0]['text'][0][0]['sentence']\n",
    "print('\\n'.join(['\\n'.join([ '\\n'.join([d['sentence'] for d in subls]) for subls in sublist['text']]) for sublist in a['documents'][0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'매우'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['documents'][0]['text'][0][0]['sentence'][67:69]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['documents'][0]['text'][2][1]['sentence']\n",
    "test = a['documents'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'index': 0,\n",
       "   'sentence': '더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"고 밝혔다.',\n",
       "   'highlight_indices': '67,69'}],\n",
       " [{'index': 1,\n",
       "   'sentence': '더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 \\'조국 사태\\'와 관련, \"국민 여러분께 매우 송구하다\"는 입장을 밝혔다.',\n",
       "   'highlight_indices': '52,54'},\n",
       "  {'index': 2,\n",
       "   'sentence': '이 대표는 \"검찰 개혁이란 대의에 집중하다 보니, 국민 특히 청년이 느꼈을 불공정에 대한 상대적 박탈감, 좌절감을 깊이 있게 헤아리지 못했다\"며 \"여당 대표로서 무거운 책임감을 느낀다\"고 머리를 숙였다.',\n",
       "   'highlight_indices': '0,1;31,33;64,66'},\n",
       "  {'index': 3,\n",
       "   'sentence': '조국 전 법무부 장관이 14 일 사퇴한 이후 이 대표가 당 안팎의 쇄신 요구에 대해 입장을 표명한 것은 이번이 처음이다.',\n",
       "   'highlight_indices': '25,26'}],\n",
       " [{'index': 4,\n",
       "   'sentence': \"청와대와 여당은 '조국 정국'을 거치며 분출된 '공정'과 '정의'의 민심을 받들어 검찰 개혁에 매진하겠다면서도 두 달간 극심한 분열과 갈등을 초래한데 대해선 진지하게 성찰하는 모습을 보이지 않았다.\",\n",
       "   'highlight_indices': '62,63'},\n",
       "  {'index': 5,\n",
       "   'sentence': '그나마 초선인 이철희 의원이 \"당이 대통령 뒤에 비겁하게 숨어 있었다\"고 비판했고, 표창원 의원은 \"책임을 느끼는 분들이 각자 형태로 그 책임감을 행동으로 옮겨야 할 때\"라고 지적했다.',\n",
       "   'highlight_indices': '0,3;68,70;75,76'},\n",
       "  {'index': 6,\n",
       "   'sentence': '뒤늦게나마 이 대표가 자성의 목소리를 내긴 했으나 당 안팎의 쇄신 요구에 어떻게 응할지 구체적 플랜을 제시하지 못해 여전히 안이하다는 지적도 나온다.',\n",
       "   'highlight_indices': '6,7;41,44;65,68'}],\n",
       " [{'index': 7,\n",
       "   'sentence': '이 대표는 28 일 윤호중 사무총장을 단장으로 하는 총선기획단을 발족했고 조만간 인재영입위원회도 출범시킬 계획이라고 밝혔다.',\n",
       "   'highlight_indices': '0,1;29,30;41,44'},\n",
       "  {'index': 8,\n",
       "   'sentence': '이 대표는 \"민주당의 가치를 공유하는 참신한 인물을 영입해 준비된 정책과 인물로 승부하겠다\"고 다짐했다.',\n",
       "   'highlight_indices': '0,1'},\n",
       "  {'index': 9,\n",
       "   'sentence': '하지만 당 일각에선 \"총선기획단장을 비롯한 당직 인선부터 쇄신 의지를 보여야 한다\"는 비판의 목소리가 나온다.',\n",
       "   'highlight_indices': '0,3'},\n",
       "  {'index': 10,\n",
       "   'sentence': '무조건 물러나는 게 능사는 아니지만 국정 혼선을 초래한 데 대해 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적도 있다.',\n",
       "   'highlight_indices': '0,3'}],\n",
       " [{'index': 11,\n",
       "   'sentence': '선거는 대중의 이해와 요구를 잘 대표하는 정치인을 뽑는 행위다.',\n",
       "   'highlight_indices': '16,17'},\n",
       "  {'index': 12,\n",
       "   'sentence': '민생을 외면하며 낡은 이념과 진영 싸움에 매몰된 구시대 인물들을 과감히 물갈이하라는 게 국민의 요구다.',\n",
       "   'highlight_indices': '36,39'},\n",
       "  {'index': 13,\n",
       "   'sentence': '대신 4 차 산업혁명의 거센 파고를 헤쳐나갈 전문성을 갖춘 젊고 유능한 인재들을 널리 구해야 하다.',\n",
       "   'highlight_indices': '45,47'},\n",
       "  {'index': 14,\n",
       "   'sentence': '이해찬 대표의 이날 유감 표명이 여권 전반의 대대적인 인적 쇄신으로 이어지길 기대한다.',\n",
       "   'highlight_indices': ''}]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub\n",
      "[{'index': 0, 'sentence': '더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"고 밝혔다.', 'highlight_indices': '67,69'}]\n",
      "item\n",
      "더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"고 밝혔다.\n",
      "sub\n",
      "[{'index': 1, 'sentence': '더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 \\'조국 사태\\'와 관련, \"국민 여러분께 매우 송구하다\"는 입장을 밝혔다.', 'highlight_indices': '52,54'}, {'index': 2, 'sentence': '이 대표는 \"검찰 개혁이란 대의에 집중하다 보니, 국민 특히 청년이 느꼈을 불공정에 대한 상대적 박탈감, 좌절감을 깊이 있게 헤아리지 못했다\"며 \"여당 대표로서 무거운 책임감을 느낀다\"고 머리를 숙였다.', 'highlight_indices': '0,1;31,33;64,66'}, {'index': 3, 'sentence': '조국 전 법무부 장관이 14 일 사퇴한 이후 이 대표가 당 안팎의 쇄신 요구에 대해 입장을 표명한 것은 이번이 처음이다.', 'highlight_indices': '25,26'}]\n",
      "item\n",
      "더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 '조국 사태'와 관련, \"국민 여러분께 매우 송구하다\"는 입장을 밝혔다.\n",
      "item\n",
      "이 대표는 \"검찰 개혁이란 대의에 집중하다 보니, 국민 특히 청년이 느꼈을 불공정에 대한 상대적 박탈감, 좌절감을 깊이 있게 헤아리지 못했다\"며 \"여당 대표로서 무거운 책임감을 느낀다\"고 머리를 숙였다.\n",
      "item\n",
      "조국 전 법무부 장관이 14 일 사퇴한 이후 이 대표가 당 안팎의 쇄신 요구에 대해 입장을 표명한 것은 이번이 처음이다.\n",
      "sub\n",
      "[{'index': 4, 'sentence': \"청와대와 여당은 '조국 정국'을 거치며 분출된 '공정'과 '정의'의 민심을 받들어 검찰 개혁에 매진하겠다면서도 두 달간 극심한 분열과 갈등을 초래한데 대해선 진지하게 성찰하는 모습을 보이지 않았다.\", 'highlight_indices': '62,63'}, {'index': 5, 'sentence': '그나마 초선인 이철희 의원이 \"당이 대통령 뒤에 비겁하게 숨어 있었다\"고 비판했고, 표창원 의원은 \"책임을 느끼는 분들이 각자 형태로 그 책임감을 행동으로 옮겨야 할 때\"라고 지적했다.', 'highlight_indices': '0,3;68,70;75,76'}, {'index': 6, 'sentence': '뒤늦게나마 이 대표가 자성의 목소리를 내긴 했으나 당 안팎의 쇄신 요구에 어떻게 응할지 구체적 플랜을 제시하지 못해 여전히 안이하다는 지적도 나온다.', 'highlight_indices': '6,7;41,44;65,68'}]\n",
      "item\n",
      "청와대와 여당은 '조국 정국'을 거치며 분출된 '공정'과 '정의'의 민심을 받들어 검찰 개혁에 매진하겠다면서도 두 달간 극심한 분열과 갈등을 초래한데 대해선 진지하게 성찰하는 모습을 보이지 않았다.\n",
      "item\n",
      "그나마 초선인 이철희 의원이 \"당이 대통령 뒤에 비겁하게 숨어 있었다\"고 비판했고, 표창원 의원은 \"책임을 느끼는 분들이 각자 형태로 그 책임감을 행동으로 옮겨야 할 때\"라고 지적했다.\n",
      "item\n",
      "뒤늦게나마 이 대표가 자성의 목소리를 내긴 했으나 당 안팎의 쇄신 요구에 어떻게 응할지 구체적 플랜을 제시하지 못해 여전히 안이하다는 지적도 나온다.\n",
      "sub\n",
      "[{'index': 7, 'sentence': '이 대표는 28 일 윤호중 사무총장을 단장으로 하는 총선기획단을 발족했고 조만간 인재영입위원회도 출범시킬 계획이라고 밝혔다.', 'highlight_indices': '0,1;29,30;41,44'}, {'index': 8, 'sentence': '이 대표는 \"민주당의 가치를 공유하는 참신한 인물을 영입해 준비된 정책과 인물로 승부하겠다\"고 다짐했다.', 'highlight_indices': '0,1'}, {'index': 9, 'sentence': '하지만 당 일각에선 \"총선기획단장을 비롯한 당직 인선부터 쇄신 의지를 보여야 한다\"는 비판의 목소리가 나온다.', 'highlight_indices': '0,3'}, {'index': 10, 'sentence': '무조건 물러나는 게 능사는 아니지만 국정 혼선을 초래한 데 대해 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적도 있다.', 'highlight_indices': '0,3'}]\n",
      "item\n",
      "이 대표는 28 일 윤호중 사무총장을 단장으로 하는 총선기획단을 발족했고 조만간 인재영입위원회도 출범시킬 계획이라고 밝혔다.\n",
      "item\n",
      "이 대표는 \"민주당의 가치를 공유하는 참신한 인물을 영입해 준비된 정책과 인물로 승부하겠다\"고 다짐했다.\n",
      "item\n",
      "하지만 당 일각에선 \"총선기획단장을 비롯한 당직 인선부터 쇄신 의지를 보여야 한다\"는 비판의 목소리가 나온다.\n",
      "item\n",
      "무조건 물러나는 게 능사는 아니지만 국정 혼선을 초래한 데 대해 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적도 있다.\n",
      "sub\n",
      "[{'index': 11, 'sentence': '선거는 대중의 이해와 요구를 잘 대표하는 정치인을 뽑는 행위다.', 'highlight_indices': '16,17'}, {'index': 12, 'sentence': '민생을 외면하며 낡은 이념과 진영 싸움에 매몰된 구시대 인물들을 과감히 물갈이하라는 게 국민의 요구다.', 'highlight_indices': '36,39'}, {'index': 13, 'sentence': '대신 4 차 산업혁명의 거센 파고를 헤쳐나갈 전문성을 갖춘 젊고 유능한 인재들을 널리 구해야 하다.', 'highlight_indices': '45,47'}, {'index': 14, 'sentence': '이해찬 대표의 이날 유감 표명이 여권 전반의 대대적인 인적 쇄신으로 이어지길 기대한다.', 'highlight_indices': ''}]\n",
      "item\n",
      "선거는 대중의 이해와 요구를 잘 대표하는 정치인을 뽑는 행위다.\n",
      "item\n",
      "민생을 외면하며 낡은 이념과 진영 싸움에 매몰된 구시대 인물들을 과감히 물갈이하라는 게 국민의 요구다.\n",
      "item\n",
      "대신 4 차 산업혁명의 거센 파고를 헤쳐나갈 전문성을 갖춘 젊고 유능한 인재들을 널리 구해야 하다.\n",
      "item\n",
      "이해찬 대표의 이날 유감 표명이 여권 전반의 대대적인 인적 쇄신으로 이어지길 기대한다.\n"
     ]
    }
   ],
   "source": [
    "for sublist in test:\n",
    "    print('sub')\n",
    "    print(sublist)\n",
    "    for item in sublist:\n",
    "        print('item')\n",
    "        print(item['sentence'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2522030203.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[41], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    out = [[dd['sentence'] for dd in sublist]; print('sub',sublist) for sublist in test]\u001b[0m\n\u001b[0m                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "out = [[dd['sentence'] for dd in sublist]print('sub',sublist) for sublist in test]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a['documents']:\n",
    "    for ds in i['text']:\n",
    "        if len(ds) != 1:\n",
    "            print(ds)\n",
    "            print('----')\n",
    "            break\n",
    "print('No len more one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7008, 7008)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "PATH = '/opt/ml/input/summarization/data/valid_original.json'\n",
    "# def load_data(path):\n",
    "output = defaultdict(list)\n",
    "with open(PATH) as f:\n",
    "    a = json.load(f)\n",
    "for documents in a['documents']:\n",
    "    tmp = ''.join(['\\n'.join([ds['sentence'] for ds in sublist]) for sublist in documents['text']])\n",
    "    label = documents['abstractive'][0]\n",
    "    output['origin_text'].append(tmp)\n",
    "    output['groundTruth'].append(label)\n",
    "    # return output\n",
    "len(output['origin_text']), len(output['groundTruth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "dd = Dataset.from_pandas(pd.DataFrame(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['origin_text', 'groundTruth'],\n",
       "    num_rows: 7008\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import AutoTokenizer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import T5TokenizerFast as T5Tokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('KETI-AIR/ke-t5-base')\n",
    "tokenizer = T5Tokenizer.from_pretrained('KETI-AIR/ke-t5-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'summarize: '\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"origin_text\"]]\n",
    "    output = {}\n",
    "    model_inputs = tokenizer(inputs, max_length=1024,  truncation=True, padding= 'max_length', add_special_tokens = True,return_tensors = 'pt')\n",
    "    # model_inputs = tokenizer(inputs, max_length=1024,  truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"groundTruth\"], max_length=128, truncation=True,padding= 'max_length', add_special_tokens = True,return_tensors = 'pt')\n",
    "    # labels = tokenizer(text_target=examples[\"groundTruth\"], max_length=128, truncation=True)\n",
    "\n",
    "    labels[\"labels\"] = [\n",
    "        [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"labels\"]\n",
    "    model_inputs[\"decoder_input_ids\"] = labels[\"input_ids\"]\n",
    "    # model_inputs[\"decoder_input_ids\"] = labels[\"input_ids\"]\n",
    "    # output[\"decoder_attention_mask\"] = labels[\"attention_mask\"].squeeze(0)\n",
    "    return model_inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89dc5c7d9b834b69828932651b4f130d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7008 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2975</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_map_single</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2972 │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(example, pa.Table):                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2973 │   │   │   │   │   │   │   │   </span>writer.write_row(example)                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2974 │   │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2975 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   │   </span>writer.write(example)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2976 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2977 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, batch <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> pbar:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2978 │   │   │   │   │   │   </span>indices = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">479</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">476 │   │   │   │   # Re-intializing to empty list for next batch</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">477 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.hkey_record = []                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">478 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>479 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.write_examples_on_file()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">480 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">check_duplicate_keys</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482 │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"Raises error if duplicates found in a batch\"\"\"</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">437</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write_examples_on_file</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">434 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> col <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> cols:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">435 │   │   │   # Since current_examples contains (example, key) tuples</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">436 │   │   │   </span>batch_examples[col] = [row[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][col] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> row <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.current_examples]           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>437 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.write_batch(batch_examples=batch_examples)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">438 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.current_examples = []                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">439 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">440 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write_rows_on_file</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">536</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write_batch</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">533 │   │   │   </span>col_type = features[col] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> features <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">534 │   │   │   </span>col_try_type = try_features[col] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> try_features <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> col <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> try_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">535 │   │   │   </span>typed_sequence = OptimizedTypedSequence(batch_examples[col], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>=col_type,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>536 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>arrays.append(pa.array(typed_sequence))                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">537 │   │   │   </span>inferred_features[col] = typed_sequence.get_inferred_type()                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">538 │   │   </span>schema = inferred_features.arrow_schema <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pa_writer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sche   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">539 │   │   </span>pa_table = pa.Table.from_arrays(arrays, schema=schema)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/ml/input/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">array.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">236</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib.array</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/ml/input/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">array.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">110</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib._handle_arrow_array_protocol</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">189</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__arrow_array__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 │   │   │   │   </span>out = list_of_np_array_to_pyarrow_listarray(data)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 │   │   │   │   </span>trying_cast_to_python_objects = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>189 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>out = pa.array(cast_to_python_objects(data, only_1d_for_numpy=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>))       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 │   │   │   # use smaller integer precisions if possible</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trying_int_optimization:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> pa.types.is_int64(out.type):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">413</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cast_to_python_objects</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">casted_obj: the casted object</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 413 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _cast_to_python_objects(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 414 │   │   </span>obj, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimize_list_ca  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 415 │   </span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 416 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">372</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> obj:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _check_non_null_non_empty_recursive(first_elmt):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 372 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>casted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 373 │   │   │   │   </span>first_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 374 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_changed_first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> optimize_list_casting:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">372</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> obj:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _check_non_null_non_empty_recursive(first_elmt):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 372 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>casted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 373 │   │   │   │   </span>first_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 374 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_changed_first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> optimize_list_casting:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">372</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> obj:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _check_non_null_non_empty_recursive(first_elmt):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 372 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>casted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 373 │   │   │   │   </span>first_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 374 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_changed_first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> optimize_list_casting:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">311</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> only_1d_for_numpy <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> obj.ndim == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 309 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> obj.detach().cpu().numpy(), <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 311 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 │   │   │   │   </span>_cast_to_python_objects(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 313 │   │   │   │   │   </span>x, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimi  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 │   │   │   │   </span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>iteration over a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-d array\n",
       "\n",
       "<span style=\"font-style: italic\">During handling of the above exception, another exception occurred:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_848/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">615501358.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_848/615501358.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2585</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">map</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2582 │   │   </span>disable_tqdm = <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> logging.is_progress_bar_enabled()                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2583 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2584 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> num_proc <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> num_proc == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2585 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._map_single(                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2586 │   │   │   │   </span>function=function,                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2587 │   │   │   │   </span>with_indices=with_indices,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2588 │   │   │   │   </span>with_rank=with_rank,                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">585</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 582 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 583 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>: <span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span> = kwargs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"self\"</span>)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 584 │   │   # apply actual function</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 585 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>out: Union[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"DatasetDict\"</span>] = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 586 │   │   </span>datasets: List[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(out.values()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(out, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> [ou  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 587 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> dataset <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> datasets:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 588 │   │   │   # Remove task templates if a column mapping of the template is no longer val</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">552</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 549 │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"output_all_columns\"</span>: <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._output_all_columns,                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 550 │   │   </span>}                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 551 │   │   # apply actual function</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 552 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>out: Union[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">\"DatasetDict\"</span>] = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 553 │   │   </span>datasets: List[<span style=\"color: #808000; text-decoration-color: #808000\">\"Dataset\"</span>] = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(out.values()) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(out, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> [ou  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 554 │   │   # re-apply format to the output</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 555 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> dataset <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> datasets:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fingerprint.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">480</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">wrapper</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">477 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">478 │   │   │   # Call actual function</span>                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">479 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>480 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>out = func(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args, **kwargs)                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">481 │   │   │   </span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">482 │   │   │   # Update fingerprint of in-place transforms + update in-place history of tra</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">483 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_dataset.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3005</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_map_single</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3002 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">Exception</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyboardInterrupt</span>):                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3003 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> update_data:                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3004 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> writer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3005 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>writer.finalize()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3006 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> tmp_file <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3007 │   │   │   │   │   │   </span>tmp_file.close()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3008 │   │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> os.path.exists(tmp_file.name):                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">566</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">finalize</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">563 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.check_duplicate_keys()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">564 │   │   │   # Re-intializing to empty list for next batch</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">565 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.hkey_record = []                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>566 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.write_examples_on_file()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">567 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pa_writer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">568 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.schema:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">569 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._build_writer(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.schema)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">437</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write_examples_on_file</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">434 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> col <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> cols:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">435 │   │   │   # Since current_examples contains (example, key) tuples</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">436 │   │   │   </span>batch_examples[col] = [row[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>][col] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> row <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.current_examples]           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>437 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.write_batch(batch_examples=batch_examples)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">438 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.current_examples = []                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">439 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">440 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write_rows_on_file</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">536</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">write_batch</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">533 │   │   │   </span>col_type = features[col] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> features <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">534 │   │   │   </span>col_try_type = try_features[col] <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> try_features <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> col <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> try_   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">535 │   │   │   </span>typed_sequence = OptimizedTypedSequence(batch_examples[col], <span style=\"color: #00ffff; text-decoration-color: #00ffff\">type</span>=col_type,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>536 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>arrays.append(pa.array(typed_sequence))                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">537 │   │   │   </span>inferred_features[col] = typed_sequence.get_inferred_type()                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">538 │   │   </span>schema = inferred_features.arrow_schema <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pa_writer <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sche   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">539 │   │   </span>pa_table = pa.Table.from_arrays(arrays, schema=schema)                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/ml/input/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">array.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">236</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib.array</span>                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/ml/input/pyarrow/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">array.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">110</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pyarrow.lib._handle_arrow_array_protocol</span>                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">arrow_writer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">189</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__arrow_array__</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">186 │   │   │   │   </span>out = list_of_np_array_to_pyarrow_listarray(data)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">187 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">188 │   │   │   │   </span>trying_cast_to_python_objects = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>189 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>out = pa.array(cast_to_python_objects(data, only_1d_for_numpy=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>))       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">190 │   │   │   # use smaller integer precisions if possible</span>                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">191 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trying_int_optimization:                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> pa.types.is_int64(out.type):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">413</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">cast_to_python_objects</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 410 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">Returns:</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 411 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">casted_obj: the casted object</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 412 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 413 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _cast_to_python_objects(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 414 │   │   </span>obj, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimize_list_ca  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 415 │   </span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 416 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">372</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> obj:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _check_non_null_non_empty_recursive(first_elmt):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 372 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>casted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 373 │   │   │   │   </span>first_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 374 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_changed_first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> optimize_list_casting:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">372</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> obj:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _check_non_null_non_empty_recursive(first_elmt):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 372 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>casted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 373 │   │   │   │   </span>first_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 374 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_changed_first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> optimize_list_casting:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">372</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 369 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> obj:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 370 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _check_non_null_non_empty_recursive(first_elmt):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 371 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">break</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 372 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>casted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 373 │   │   │   │   </span>first_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 374 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 375 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_changed_first_elmt <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> optimize_list_casting:                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/datasets/features/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">features.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">311</span> in                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_cast_to_python_objects</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 308 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> only_1d_for_numpy <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> obj.ndim == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 309 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> obj.detach().cpu().numpy(), <span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 310 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 311 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> [                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 312 │   │   │   │   </span>_cast_to_python_objects(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 313 │   │   │   │   │   </span>x, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimi  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 314 │   │   │   │   </span>)[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>iteration over a <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-d array\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m2975\u001b[0m in \u001b[92m_map_single\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2972 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(example, pa.Table):                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2973 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   \u001b[0mwriter.write_row(example)                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2974 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2975 \u001b[2m│   │   │   │   │   │   │   │   \u001b[0mwriter.write(example)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2976 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2977 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m i, batch \u001b[95min\u001b[0m pbar:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2978 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mindices = \u001b[96mlist\u001b[0m(                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m479\u001b[0m in \u001b[92mwrite\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m476 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# Re-intializing to empty list for next batch\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m477 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.hkey_record = []                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m478 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m479 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.write_examples_on_file()                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m480 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcheck_duplicate_keys\u001b[0m(\u001b[96mself\u001b[0m):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[33m\"\"\"Raises error if duplicates found in a batch\"\"\"\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m437\u001b[0m in \u001b[92mwrite_examples_on_file\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m434 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m col \u001b[95min\u001b[0m cols:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m435 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Since current_examples contains (example, key) tuples\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m436 \u001b[0m\u001b[2m│   │   │   \u001b[0mbatch_examples[col] = [row[\u001b[94m0\u001b[0m][col] \u001b[94mfor\u001b[0m row \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.current_examples]           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m437 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.write_batch(batch_examples=batch_examples)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m438 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.current_examples = []                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m439 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m440 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrite_rows_on_file\u001b[0m(\u001b[96mself\u001b[0m):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m536\u001b[0m in \u001b[92mwrite_batch\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m533 \u001b[0m\u001b[2m│   │   │   \u001b[0mcol_type = features[col] \u001b[94mif\u001b[0m features \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m534 \u001b[0m\u001b[2m│   │   │   \u001b[0mcol_try_type = try_features[col] \u001b[94mif\u001b[0m try_features \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m col \u001b[95min\u001b[0m try_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m535 \u001b[0m\u001b[2m│   │   │   \u001b[0mtyped_sequence = OptimizedTypedSequence(batch_examples[col], \u001b[96mtype\u001b[0m=col_type,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m536 \u001b[2m│   │   │   \u001b[0marrays.append(pa.array(typed_sequence))                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m537 \u001b[0m\u001b[2m│   │   │   \u001b[0minferred_features[col] = typed_sequence.get_inferred_type()                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m538 \u001b[0m\u001b[2m│   │   \u001b[0mschema = inferred_features.arrow_schema \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.pa_writer \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.sche   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m539 \u001b[0m\u001b[2m│   │   \u001b[0mpa_table = pa.Table.from_arrays(arrays, schema=schema)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/ml/input/pyarrow/\u001b[0m\u001b[1;33marray.pxi\u001b[0m:\u001b[94m236\u001b[0m in \u001b[92mpyarrow.lib.array\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/ml/input/pyarrow/\u001b[0m\u001b[1;33marray.pxi\u001b[0m:\u001b[94m110\u001b[0m in \u001b[92mpyarrow.lib._handle_arrow_array_protocol\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m189\u001b[0m in \u001b[92m__arrow_array__\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mout = list_of_np_array_to_pyarrow_listarray(data)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtrying_cast_to_python_objects = \u001b[94mTrue\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m189 \u001b[2m│   │   │   │   \u001b[0mout = pa.array(cast_to_python_objects(data, only_1d_for_numpy=\u001b[94mTrue\u001b[0m))       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# use smaller integer precisions if possible\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.trying_int_optimization:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m pa.types.is_int64(out.type):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m413\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcast_to_python_objects\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mcasted_obj: the casted object\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 413 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _cast_to_python_objects(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 414 \u001b[0m\u001b[2m│   │   \u001b[0mobj, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimize_list_ca  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 415 \u001b[0m\u001b[2m│   \u001b[0m)[\u001b[94m0\u001b[0m]                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 416 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m372\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m first_elmt \u001b[95min\u001b[0m obj:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m _check_non_null_non_empty_recursive(first_elmt):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 372 \u001b[2m│   │   │   \u001b[0mcasted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfirst_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 374 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m has_changed_first_elmt \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m optimize_list_casting:                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m372\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m first_elmt \u001b[95min\u001b[0m obj:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m _check_non_null_non_empty_recursive(first_elmt):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 372 \u001b[2m│   │   │   \u001b[0mcasted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfirst_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 374 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m has_changed_first_elmt \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m optimize_list_casting:                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m372\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m first_elmt \u001b[95min\u001b[0m obj:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m _check_non_null_non_empty_recursive(first_elmt):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 372 \u001b[2m│   │   │   \u001b[0mcasted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfirst_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 374 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m has_changed_first_elmt \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m optimize_list_casting:                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m311\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m only_1d_for_numpy \u001b[95mor\u001b[0m obj.ndim == \u001b[94m1\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 309 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m obj.detach().cpu().numpy(), \u001b[94mTrue\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 311 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m [                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_cast_to_python_objects(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 313 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mx, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimi  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 314 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)[\u001b[94m0\u001b[0m]                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0miteration over a \u001b[1;36m0\u001b[0m-d array\n",
       "\n",
       "\u001b[3mDuring handling of the above exception, another exception occurred:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_848/\u001b[0m\u001b[1;33m615501358.py\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_848/615501358.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m2585\u001b[0m in \u001b[92mmap\u001b[0m                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2582 \u001b[0m\u001b[2m│   │   \u001b[0mdisable_tqdm = \u001b[95mnot\u001b[0m logging.is_progress_bar_enabled()                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2583 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2584 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m num_proc \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mor\u001b[0m num_proc == \u001b[94m1\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2585 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._map_single(                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2586 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfunction=function,                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2587 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mwith_indices=with_indices,                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2588 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mwith_rank=with_rank,                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m585\u001b[0m in \u001b[92mwrapper\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 582 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 583 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m: \u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m = kwargs.pop(\u001b[33m\"\u001b[0m\u001b[33mself\u001b[0m\u001b[33m\"\u001b[0m)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 584 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 585 \u001b[2m│   │   \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 586 \u001b[0m\u001b[2m│   │   \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 587 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 588 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Remove task templates if a column mapping of the template is no longer val\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m552\u001b[0m in \u001b[92mwrapper\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 549 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33moutput_all_columns\u001b[0m\u001b[33m\"\u001b[0m: \u001b[96mself\u001b[0m._output_all_columns,                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 550 \u001b[0m\u001b[2m│   │   \u001b[0m}                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 551 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# apply actual function\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 552 \u001b[2m│   │   \u001b[0mout: Union[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m, \u001b[33m\"\u001b[0m\u001b[33mDatasetDict\u001b[0m\u001b[33m\"\u001b[0m] = func(\u001b[96mself\u001b[0m, *args, **kwargs)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 553 \u001b[0m\u001b[2m│   │   \u001b[0mdatasets: List[\u001b[33m\"\u001b[0m\u001b[33mDataset\u001b[0m\u001b[33m\"\u001b[0m] = \u001b[96mlist\u001b[0m(out.values()) \u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(out, \u001b[96mdict\u001b[0m) \u001b[94melse\u001b[0m [ou  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 554 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# re-apply format to the output\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 555 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m dataset \u001b[95min\u001b[0m datasets:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33mfingerprint.py\u001b[0m:\u001b[94m480\u001b[0m in \u001b[92mwrapper\u001b[0m                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m477 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m478 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Call actual function\u001b[0m                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m479 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m480 \u001b[2m│   │   │   \u001b[0mout = func(\u001b[96mself\u001b[0m, *args, **kwargs)                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m481 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m482 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Update fingerprint of in-place transforms + update in-place history of tra\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m483 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_dataset.py\u001b[0m:\u001b[94m3005\u001b[0m in \u001b[92m_map_single\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3002 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m (\u001b[96mException\u001b[0m, \u001b[96mKeyboardInterrupt\u001b[0m):                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3003 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m update_data:                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3004 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m writer \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3005 \u001b[2m│   │   │   │   │   │   \u001b[0mwriter.finalize()                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3006 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m tmp_file \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3007 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtmp_file.close()                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3008 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m os.path.exists(tmp_file.name):                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m566\u001b[0m in \u001b[92mfinalize\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m563 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.check_duplicate_keys()                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m564 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Re-intializing to empty list for next batch\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m565 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.hkey_record = []                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m566 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.write_examples_on_file()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m567 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.pa_writer \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m568 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.schema:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m569 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._build_writer(\u001b[96mself\u001b[0m.schema)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m437\u001b[0m in \u001b[92mwrite_examples_on_file\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m434 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m col \u001b[95min\u001b[0m cols:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m435 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Since current_examples contains (example, key) tuples\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m436 \u001b[0m\u001b[2m│   │   │   \u001b[0mbatch_examples[col] = [row[\u001b[94m0\u001b[0m][col] \u001b[94mfor\u001b[0m row \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.current_examples]           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m437 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.write_batch(batch_examples=batch_examples)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m438 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.current_examples = []                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m439 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m440 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mwrite_rows_on_file\u001b[0m(\u001b[96mself\u001b[0m):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m536\u001b[0m in \u001b[92mwrite_batch\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m533 \u001b[0m\u001b[2m│   │   │   \u001b[0mcol_type = features[col] \u001b[94mif\u001b[0m features \u001b[94melse\u001b[0m \u001b[94mNone\u001b[0m                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m534 \u001b[0m\u001b[2m│   │   │   \u001b[0mcol_try_type = try_features[col] \u001b[94mif\u001b[0m try_features \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m col \u001b[95min\u001b[0m try_   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m535 \u001b[0m\u001b[2m│   │   │   \u001b[0mtyped_sequence = OptimizedTypedSequence(batch_examples[col], \u001b[96mtype\u001b[0m=col_type,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m536 \u001b[2m│   │   │   \u001b[0marrays.append(pa.array(typed_sequence))                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m537 \u001b[0m\u001b[2m│   │   │   \u001b[0minferred_features[col] = typed_sequence.get_inferred_type()                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m538 \u001b[0m\u001b[2m│   │   \u001b[0mschema = inferred_features.arrow_schema \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.pa_writer \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96mself\u001b[0m.sche   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m539 \u001b[0m\u001b[2m│   │   \u001b[0mpa_table = pa.Table.from_arrays(arrays, schema=schema)                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/ml/input/pyarrow/\u001b[0m\u001b[1;33marray.pxi\u001b[0m:\u001b[94m236\u001b[0m in \u001b[92mpyarrow.lib.array\u001b[0m                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/ml/input/pyarrow/\u001b[0m\u001b[1;33marray.pxi\u001b[0m:\u001b[94m110\u001b[0m in \u001b[92mpyarrow.lib._handle_arrow_array_protocol\u001b[0m                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/opt/ml/input/pyarrow/array.pxi'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/\u001b[0m\u001b[1;33marrow_writer.py\u001b[0m:\u001b[94m189\u001b[0m in \u001b[92m__arrow_array__\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m186 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mout = list_of_np_array_to_pyarrow_listarray(data)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m187 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m188 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtrying_cast_to_python_objects = \u001b[94mTrue\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m189 \u001b[2m│   │   │   │   \u001b[0mout = pa.array(cast_to_python_objects(data, only_1d_for_numpy=\u001b[94mTrue\u001b[0m))       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m190 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# use smaller integer precisions if possible\u001b[0m                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m191 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.trying_int_optimization:                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m pa.types.is_int64(out.type):                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m413\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mcast_to_python_objects\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 410 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33mReturns:\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 411 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33mcasted_obj: the casted object\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 412 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 413 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m _cast_to_python_objects(                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 414 \u001b[0m\u001b[2m│   │   \u001b[0mobj, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimize_list_ca  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 415 \u001b[0m\u001b[2m│   \u001b[0m)[\u001b[94m0\u001b[0m]                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 416 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m372\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m first_elmt \u001b[95min\u001b[0m obj:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m _check_non_null_non_empty_recursive(first_elmt):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 372 \u001b[2m│   │   │   \u001b[0mcasted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfirst_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 374 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m has_changed_first_elmt \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m optimize_list_casting:                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m372\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m first_elmt \u001b[95min\u001b[0m obj:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m _check_non_null_non_empty_recursive(first_elmt):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 372 \u001b[2m│   │   │   \u001b[0mcasted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfirst_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 374 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m has_changed_first_elmt \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m optimize_list_casting:                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m372\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 369 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfor\u001b[0m first_elmt \u001b[95min\u001b[0m obj:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 370 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m _check_non_null_non_empty_recursive(first_elmt):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 371 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mbreak\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 372 \u001b[2m│   │   │   \u001b[0mcasted_first_elmt, has_changed_first_elmt = _cast_to_python_objects(          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 373 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfirst_elmt, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=o  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 374 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 375 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m has_changed_first_elmt \u001b[95mor\u001b[0m \u001b[95mnot\u001b[0m optimize_list_casting:                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/datasets/features/\u001b[0m\u001b[1;33mfeatures.py\u001b[0m:\u001b[94m311\u001b[0m in                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_cast_to_python_objects\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 308 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m only_1d_for_numpy \u001b[95mor\u001b[0m obj.ndim == \u001b[94m1\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 309 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m obj.detach().cpu().numpy(), \u001b[94mTrue\u001b[0m                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 310 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 311 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m [                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 312 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_cast_to_python_objects(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 313 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mx, only_1d_for_numpy=only_1d_for_numpy, optimize_list_casting=optimi  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 314 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)[\u001b[94m0\u001b[0m]                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0miteration over a \u001b[1;36m0\u001b[0m-d array\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_pad_token_id  = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")\n",
    "dataset = dd.map(preprocess_function, batched=False, remove_columns = ['origin_text','groundTruth'])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 7008\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_848/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">2898668808.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_848/2898668808.py'</span>                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_collator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">588</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__call__</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 585 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 586 │   │   │   │   │   </span>feature[<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>] = np.concatenate([remainder, feature[<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>]]).a  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 587 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 588 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>features = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.tokenizer.pad(                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 589 │   │   │   </span>features,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 590 │   │   │   </span>padding=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.padding,                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 591 │   │   │   </span>max_length=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.max_length,                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2937</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pad</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2934 │   │   # The model's main input name, usually `input_ids`, has be passed for padding</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2935 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model_input_names[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>] <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> encoded_inputs:                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2936 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2937 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"You should supply an encoding or a list of encodings to this method \"</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2938 │   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">f\"that includes {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.model_input_names[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>]<span style=\"color: #808000; text-decoration-color: #808000\">}, but you provided {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">list</span>(enco  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2939 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2940 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'Dataset'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'keys'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_848/\u001b[0m\u001b[1;33m2898668808.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_848/2898668808.py'\u001b[0m                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/data/\u001b[0m\u001b[1;33mdata_collator.py\u001b[0m:\u001b[94m588\u001b[0m in \u001b[92m__call__\u001b[0m        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 585 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 586 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mfeature[\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m] = np.concatenate([remainder, feature[\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m]]).a  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 587 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 588 \u001b[2m│   │   \u001b[0mfeatures = \u001b[96mself\u001b[0m.tokenizer.pad(                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 589 \u001b[0m\u001b[2m│   │   │   \u001b[0mfeatures,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 590 \u001b[0m\u001b[2m│   │   │   \u001b[0mpadding=\u001b[96mself\u001b[0m.padding,                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 591 \u001b[0m\u001b[2m│   │   │   \u001b[0mmax_length=\u001b[96mself\u001b[0m.max_length,                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m2937\u001b[0m in \u001b[92mpad\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2934 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# The model's main input name, usually `input_ids`, has be passed for padding\u001b[0m     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2935 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.model_input_names[\u001b[94m0\u001b[0m] \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m encoded_inputs:                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2936 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2937 \u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33mYou should supply an encoding or a list of encodings to this method \u001b[0m\u001b[33m\"\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2938 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mthat includes \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.model_input_names[\u001b[94m0\u001b[0m]\u001b[33m}\u001b[0m\u001b[33m, but you provided \u001b[0m\u001b[33m{\u001b[0m\u001b[96mlist\u001b[0m(enco  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2939 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2940 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'Dataset'\u001b[0m object has no attribute \u001b[32m'keys'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_collator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'더불어민주당 이해찬 대표가 30 일 오후 국회에서 기자간담회를 열고 조국 전 법무부 장관 사태와 관련해 \"국민 여러분께 매우 송구하다\"고 밝혔다.더불어민주당 이해찬 대표가 30 일 기자간담회를 열고 \\'조국 사태\\'와 관련, \"국민 여러분께 매우 송구하다\"는 입장을 밝혔다.\\n이 대표는 \"검찰 개혁이란 대의에 집중하다 보니, 국민 특히 청년이 느꼈을 불공정에 대한 상대적 박탈감, 좌절감을 깊이 있게 헤아리지 못했다\"며 \"여당 대표로서 무거운 책임감을 느낀다\"고 머리를 숙였다.\\n조국 전 법무부 장관이 14 일 사퇴한 이후 이 대표가 당 안팎의 쇄신 요구에 대해 입장을 표명한 것은 이번이 처음이다.청와대와 여당은 \\'조국 정국\\'을 거치며 분출된 \\'공정\\'과 \\'정의\\'의 민심을 받들어 검찰 개혁에 매진하겠다면서도 두 달간 극심한 분열과 갈등을 초래한데 대해선 진지하게 성찰하는 모습을 보이지 않았다.\\n그나마 초선인 이철희 의원이 \"당이 대통령 뒤에 비겁하게 숨어 있었다\"고 비판했고, 표창원 의원은 \"책임을 느끼는 분들이 각자 형태로 그 책임감을 행동으로 옮겨야 할 때\"라고 지적했다.\\n뒤늦게나마 이 대표가 자성의 목소리를 내긴 했으나 당 안팎의 쇄신 요구에 어떻게 응할지 구체적 플랜을 제시하지 못해 여전히 안이하다는 지적도 나온다.이 대표는 28 일 윤호중 사무총장을 단장으로 하는 총선기획단을 발족했고 조만간 인재영입위원회도 출범시킬 계획이라고 밝혔다.\\n이 대표는 \"민주당의 가치를 공유하는 참신한 인물을 영입해 준비된 정책과 인물로 승부하겠다\"고 다짐했다.\\n하지만 당 일각에선 \"총선기획단장을 비롯한 당직 인선부터 쇄신 의지를 보여야 한다\"는 비판의 목소리가 나온다.\\n무조건 물러나는 게 능사는 아니지만 국정 혼선을 초래한 데 대해 당 지도부가 겸허하게 책임지는 모습을 보이는 게 쇄신의 출발점이 돼야 한다는 지적도 있다.선거는 대중의 이해와 요구를 잘 대표하는 정치인을 뽑는 행위다.\\n민생을 외면하며 낡은 이념과 진영 싸움에 매몰된 구시대 인물들을 과감히 물갈이하라는 게 국민의 요구다.\\n대신 4 차 산업혁명의 거센 파고를 헤쳐나갈 전문성을 갖춘 젊고 유능한 인재들을 널리 구해야 하다.\\n이해찬 대표의 이날 유감 표명이 여권 전반의 대대적인 인적 쇄신으로 이어지길 기대한다.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['origin_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'summarize: ' + output['origin_text'][0]\n",
    "inputs = tokenizer(sent,add_special_tokens=True, truncation=True,return_tensors='pt')\n",
    "de = tokenizer(output['groundTruth'][0],add_special_tokens=True, truncation=True,return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(decoder_input_ids = de['input_ids'], labels=de['input_ids'],**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2SeqLMOutput(loss=tensor(147.2637, grad_fn=<NllLossBackward0>), logits=tensor([[[ 2.3790, 18.9980, 20.6807,  ..., -3.1859,  3.0847,  1.9540],\n",
       "         [-0.1972, 19.7271, 20.6071,  ..., -3.1082,  3.0474,  2.0316],\n",
       "         [ 2.0674, 19.9125, 20.0974,  ..., -3.0355,  2.7973,  2.0690],\n",
       "         ...,\n",
       "         [ 0.1672, 18.3445, 19.7046,  ..., -2.9122,  2.5408,  1.9513],\n",
       "         [ 2.5304, 10.2279, 10.0522,  ..., -1.8114,  1.6218,  0.9822],\n",
       "         [ 1.7814, 10.6815,  9.3948,  ..., -1.7652,  1.7379,  0.8434]]],\n",
       "       grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-0.3257, -0.1605,  0.2317,  ..., -0.4802, -0.8282,  0.9251],\n",
       "          [-0.0136,  0.3577,  0.1052,  ..., -0.5052, -0.0940,  0.8944],\n",
       "          [-0.7688, -0.5338,  0.3585,  ..., -0.4467, -0.8136, -0.0738],\n",
       "          ...,\n",
       "          [-0.4684,  1.1759, -0.0082,  ..., -0.4196,  0.3034,  0.5599],\n",
       "          [-0.2294,  0.6175,  0.0713,  ..., -0.0666,  0.4006, -0.0553],\n",
       "          [-0.8415, -0.6839, -0.4414,  ..., -0.4604, -0.1467,  0.1283]],\n",
       "\n",
       "         [[ 0.4798,  0.5653,  1.1666,  ...,  1.6580, -0.6407, -0.8182],\n",
       "          [ 0.7066,  1.0267,  0.2614,  ..., -0.1569, -0.9932,  0.7784],\n",
       "          [ 1.3043, -1.0904, -1.0601,  ...,  0.0158,  0.7766, -1.1415],\n",
       "          ...,\n",
       "          [-0.2850,  0.4138,  1.1775,  ...,  0.5382, -1.4091,  1.0274],\n",
       "          [ 0.0368,  0.3817, -0.3567,  ...,  0.6078, -0.1503, -0.1106],\n",
       "          [-0.3878, -1.2093, -0.0594,  ..., -0.0962, -0.6320, -0.6979]],\n",
       "\n",
       "         [[-1.3893,  1.2212,  0.2112,  ...,  0.9055,  1.4675,  0.9017],\n",
       "          [-1.3223,  0.7956,  0.5850,  ..., -0.2711, -0.6542,  0.1157],\n",
       "          [-0.2660, -0.0167,  0.1074,  ...,  0.4023,  0.7017,  0.7952],\n",
       "          ...,\n",
       "          [-0.1652,  0.0948,  0.7182,  ..., -0.4333, -0.6783, -0.4384],\n",
       "          [-0.4698,  1.6217, -0.0229,  ...,  0.3006, -0.1960,  0.1491],\n",
       "          [ 0.4663,  1.4720,  0.0393,  ...,  0.7663,  2.1719,  0.1071]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9868, -0.5025,  0.2703,  ..., -0.6795,  0.6383, -0.3240],\n",
       "          [-0.6674, -1.2938, -0.3978,  ...,  1.0047,  1.2611, -0.8092],\n",
       "          [-1.6090, -2.3416,  1.3801,  ..., -1.1291,  1.9099,  0.3957],\n",
       "          ...,\n",
       "          [ 0.4820, -0.1052,  0.1381,  ..., -1.5408,  0.2085, -0.0811],\n",
       "          [ 0.3297,  0.1572, -0.1976,  ...,  0.0308, -0.4525,  0.2597],\n",
       "          [-0.6379, -0.4844,  1.3047,  ...,  1.3468,  0.1966,  1.6504]],\n",
       "\n",
       "         [[-0.4107,  0.9400,  0.3702,  ...,  0.4865,  2.1750,  1.0504],\n",
       "          [-0.4959,  2.1966,  0.4998,  ..., -0.3809,  0.1882, -1.1613],\n",
       "          [-0.1510, -0.0388,  1.6563,  ...,  0.8966,  1.8209,  0.8324],\n",
       "          ...,\n",
       "          [-0.7641,  0.8428, -0.8240,  ..., -1.6083, -0.4953, -0.4065],\n",
       "          [-1.6900,  1.1516,  0.9448,  ..., -1.2928, -0.2333, -0.6839],\n",
       "          [-0.6746,  0.6897, -0.3722,  ...,  0.2230,  1.2284, -0.1138]],\n",
       "\n",
       "         [[-0.0910, -0.8577,  0.3762,  ..., -0.6423,  0.4900,  1.3323],\n",
       "          [-1.9252,  0.0780, -0.8108,  ..., -0.8007,  0.7317,  0.6705],\n",
       "          [-1.8151,  0.9926,  0.0351,  ..., -0.8813, -0.6863,  0.6373],\n",
       "          ...,\n",
       "          [ 2.2883, -0.2641,  1.6833,  ...,  0.0347,  0.6330, -1.7001],\n",
       "          [ 0.8030,  0.6713,  1.4323,  ...,  1.4637,  1.1767,  0.9852],\n",
       "          [ 0.0852, -0.4640,  0.5318,  ...,  1.6138,  0.8811,  1.2499]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-0.0313, -0.1085, -0.0996,  ...,  0.6484, -0.4843, -0.3393],\n",
       "          [ 0.9662, -0.7507,  0.4757,  ...,  0.8422, -0.9807,  0.0283],\n",
       "          [ 0.0445, -0.1108, -0.1031,  ...,  1.0285, -1.0237, -0.5496],\n",
       "          ...,\n",
       "          [-0.3406, -0.4304,  0.3149,  ...,  0.1470, -0.5784, -0.8088],\n",
       "          [ 1.0257, -0.6283,  0.2439,  ...,  0.7729, -1.7228,  0.4649],\n",
       "          [ 0.0533,  0.2896, -0.6904,  ...,  0.6271, -0.6501,  0.2288]],\n",
       "\n",
       "         [[ 0.1341,  0.2833,  1.0424,  ..., -0.8850, -0.0102, -0.1632],\n",
       "          [-0.2683, -0.1342,  0.4783,  ..., -1.3860, -0.5217, -0.0646],\n",
       "          [-0.3525, -0.3293, -1.0183,  ..., -0.6820,  0.8060, -1.1320],\n",
       "          ...,\n",
       "          [-0.2194, -0.0678,  0.7504,  ..., -0.0471,  0.3360,  0.5655],\n",
       "          [ 0.0379, -0.0775,  0.1189,  ..., -0.1700,  0.1066,  0.0317],\n",
       "          [-0.2627,  0.0709,  0.3349,  ...,  0.5706,  0.1715,  0.3743]],\n",
       "\n",
       "         [[-1.4739,  0.1265,  0.1369,  ..., -0.6112, -0.5642, -1.0337],\n",
       "          [-0.2557, -0.4798,  0.2535,  ..., -0.5744, -0.6809,  0.1432],\n",
       "          [-0.0083,  0.2320,  0.6350,  ..., -0.0858,  0.5031,  0.1346],\n",
       "          ...,\n",
       "          [-1.4856, -0.4511,  0.4505,  ..., -0.3926, -1.0488, -0.3095],\n",
       "          [-0.0204, -0.3962,  0.1067,  ...,  0.1707, -0.2715, -0.2831],\n",
       "          [ 1.4247, -0.6429, -0.2177,  ...,  0.5208,  0.2147, -0.2196]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2560,  0.4113, -0.0071,  ..., -0.6048,  0.5849,  1.5390],\n",
       "          [ 0.4769,  0.9605, -1.3756,  ..., -1.0989, -0.1805,  0.6250],\n",
       "          [-0.8654, -0.2291, -1.2111,  ..., -0.2695,  0.1381, -0.0667],\n",
       "          ...,\n",
       "          [-1.3066,  0.1732,  0.6755,  ..., -0.2962, -1.2005, -0.1177],\n",
       "          [ 0.3409,  0.2957,  0.0521,  ..., -0.4213, -0.6908,  0.0280],\n",
       "          [ 0.2071,  0.5311,  0.6487,  ...,  0.4617,  0.5452, -0.4432]],\n",
       "\n",
       "         [[-0.1261,  0.1752, -0.4718,  ...,  0.5922, -0.1194, -0.2605],\n",
       "          [ 0.2889, -2.0512,  0.3386,  ...,  0.2142, -0.3349, -0.2194],\n",
       "          [ 0.0603, -0.8356, -0.4379,  ...,  0.1673, -0.5386,  0.8444],\n",
       "          ...,\n",
       "          [ 0.7064, -2.5006,  0.6357,  ..., -0.2619, -0.1829,  0.3311],\n",
       "          [-0.2416, -3.1668,  0.2009,  ...,  0.4275,  0.0369, -0.1804],\n",
       "          [-0.0060, -0.3620,  0.0358,  ...,  0.3348,  0.3939, -0.4309]],\n",
       "\n",
       "         [[ 0.0915,  0.5846, -0.6222,  ..., -0.2792,  0.2802,  0.3521],\n",
       "          [-0.4113, -0.2149, -0.6161,  ...,  1.1000,  0.7022,  1.2580],\n",
       "          [-1.0327,  0.6977,  0.3720,  ..., -0.9551, -0.1642,  0.4509],\n",
       "          ...,\n",
       "          [-0.5252, -1.1582, -0.4658,  ...,  0.0764,  0.4458, -0.0951],\n",
       "          [-0.8116, -0.2599, -0.8657,  ..., -0.0975,  0.2981, -0.4020],\n",
       "          [-0.3460,  0.4063,  0.7421,  ...,  0.3267,  0.1076,  0.5915]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-1.0645e+00, -1.1398e+00, -3.2218e-01,  ..., -2.9992e+00,\n",
       "           -8.6255e-01,  1.2017e+00],\n",
       "          [-2.9755e-01, -2.0320e+00,  9.4803e-02,  ..., -1.4609e+00,\n",
       "           -1.3516e-01,  6.5618e-01],\n",
       "          [-2.5550e-01, -1.5368e+00, -1.7853e-01,  ..., -9.9475e-01,\n",
       "           -1.0603e+00,  6.1091e-01],\n",
       "          ...,\n",
       "          [-1.3815e+00, -3.0625e+00,  2.0924e-01,  ..., -1.0989e+00,\n",
       "           -2.5982e+00, -6.3495e-01],\n",
       "          [-1.9596e+00, -2.8810e+00,  5.6072e-01,  ..., -3.4539e-02,\n",
       "           -4.1190e-01, -6.9408e-01],\n",
       "          [ 6.6278e-01, -6.3760e-02,  2.2224e-01,  ...,  7.7604e-01,\n",
       "           -2.5281e-01,  1.2663e-02]],\n",
       "\n",
       "         [[ 4.8665e-01,  8.4465e-01,  6.1415e-01,  ..., -9.9123e-01,\n",
       "           -1.1087e+00,  1.1667e+00],\n",
       "          [ 5.8740e-01,  1.3554e-01,  3.8386e-01,  ...,  1.0833e-01,\n",
       "           -1.6440e+00,  9.2004e-01],\n",
       "          [-5.6368e-02,  1.2043e+00, -7.9883e-02,  ..., -5.6511e-01,\n",
       "           -7.5520e-01,  1.5919e+00],\n",
       "          ...,\n",
       "          [-2.9733e-01,  8.0563e-01,  7.7075e-01,  ...,  4.1315e-01,\n",
       "           -1.2690e+00, -3.5756e-01],\n",
       "          [ 6.9450e-01,  1.7415e+00,  1.1712e+00,  ..., -1.1442e-01,\n",
       "           -1.8581e-01, -7.2774e-01],\n",
       "          [ 1.2780e-01, -2.5399e-01, -1.7275e-01,  ..., -1.3851e-01,\n",
       "            1.5291e+00, -3.5401e-02]],\n",
       "\n",
       "         [[ 2.0991e+00, -2.4604e-01, -2.0533e-01,  ...,  5.0938e-01,\n",
       "            1.3966e+00,  9.1738e-01],\n",
       "          [ 1.7174e+00,  3.9428e-01, -5.5329e-01,  ...,  1.9826e-01,\n",
       "            1.1182e+00, -9.7857e-01],\n",
       "          [ 1.5397e+00,  3.1238e-02,  7.1365e-01,  ..., -1.7566e-01,\n",
       "            1.7336e+00,  2.0789e-01],\n",
       "          ...,\n",
       "          [ 3.5698e-01, -1.4329e-01, -1.2361e+00,  ..., -1.2675e+00,\n",
       "           -5.1584e-01, -1.3466e+00],\n",
       "          [ 1.5403e-01, -9.5262e-01,  7.6037e-01,  ..., -1.1388e+00,\n",
       "           -1.0737e+00, -6.0137e-01],\n",
       "          [-3.4520e-01,  4.9641e-01, -1.5693e-01,  ..., -2.2940e-01,\n",
       "            2.2335e-01, -2.5936e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.3276e-01,  3.6381e-01, -3.4456e-02,  ...,  1.8423e+00,\n",
       "            8.6664e-01,  4.1392e-01],\n",
       "          [-1.1267e+00,  6.6247e-01, -5.8088e-01,  ..., -6.2243e-01,\n",
       "           -8.1708e-01,  9.7884e-01],\n",
       "          [-1.0925e+00,  2.3466e-01,  5.7169e-01,  ...,  4.1190e-01,\n",
       "           -1.2453e+00,  7.0573e-01],\n",
       "          ...,\n",
       "          [-6.2794e-01, -7.9670e-01, -6.3005e-01,  ...,  9.5146e-01,\n",
       "            7.0271e-01,  1.7216e-01],\n",
       "          [ 3.7131e-01, -5.4039e-02,  4.1376e-01,  ...,  7.2480e-01,\n",
       "           -6.0073e-01,  7.0322e-02],\n",
       "          [-8.9979e-02, -3.5692e-01, -2.4083e-02,  ...,  3.5131e-02,\n",
       "            1.6040e-02,  1.5443e-02]],\n",
       "\n",
       "         [[ 3.4519e-01, -6.1680e-01, -2.6902e-01,  ..., -7.6041e-01,\n",
       "            2.4484e-02,  5.1703e-02],\n",
       "          [ 5.1455e-01,  1.9917e-01,  4.6652e-01,  ..., -1.2810e+00,\n",
       "            1.5103e-01, -1.6079e-01],\n",
       "          [-2.4987e-02, -2.4938e-01, -1.1824e-01,  ..., -7.6050e-01,\n",
       "           -4.6836e-01, -2.4772e-02],\n",
       "          ...,\n",
       "          [-7.6644e-01,  5.7367e-01, -1.7185e+00,  ...,  3.5421e-02,\n",
       "            6.7487e-01,  4.1558e-02],\n",
       "          [-1.6413e-01,  4.0524e-01,  4.5328e-02,  ..., -8.3662e-01,\n",
       "            2.1116e+00, -1.2363e-01],\n",
       "          [-7.7715e-02, -9.8229e-02,  2.1589e-01,  ..., -9.6921e-03,\n",
       "           -5.1635e-01, -1.2916e-01]],\n",
       "\n",
       "         [[ 8.0841e-01, -1.9839e-02, -7.9517e-01,  ...,  9.4280e-01,\n",
       "            4.0596e-01, -3.7168e-01],\n",
       "          [ 1.1200e+00,  9.8243e-02,  6.7813e-01,  ...,  4.6193e-01,\n",
       "           -1.2795e-01,  5.8918e-01],\n",
       "          [ 1.5097e+00,  4.9062e-01, -6.6377e-01,  ...,  1.2300e+00,\n",
       "            2.3815e-01,  3.8085e-01],\n",
       "          ...,\n",
       "          [ 1.9199e-01,  1.3767e+00, -1.0742e-01,  ...,  3.6646e-01,\n",
       "           -7.3811e-01,  9.5009e-01],\n",
       "          [-1.0250e+00,  5.3702e-01,  1.6450e-01,  ..., -1.7744e-01,\n",
       "           -8.4338e-01,  1.7003e+00],\n",
       "          [-5.9377e-01,  1.3927e-01,  7.5162e-04,  ..., -6.5582e-02,\n",
       "            1.0077e-01,  1.1937e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-1.0143e-01, -1.0332e+00, -2.4166e-01,  ..., -6.2314e-01,\n",
       "           -2.8619e-01,  8.2803e-01],\n",
       "          [ 1.0853e+00, -1.1828e+00, -8.6755e-01,  ..., -4.3412e-02,\n",
       "            6.5044e-01, -1.7691e-01],\n",
       "          [-9.8252e-01, -1.5492e+00, -4.6787e-01,  ...,  1.7504e-01,\n",
       "            1.2190e+00, -2.6162e-01],\n",
       "          ...,\n",
       "          [-1.5317e+00, -3.4583e+00,  7.1060e-01,  ..., -4.0704e-01,\n",
       "            6.4369e-01, -7.3377e-01],\n",
       "          [-9.9542e-01, -2.7849e-01, -4.4423e-01,  ...,  1.2733e-01,\n",
       "           -9.6944e-01, -2.6568e-01],\n",
       "          [ 3.8259e-02, -4.5560e-02, -1.4876e-01,  ...,  6.7745e-02,\n",
       "           -5.6661e-02, -1.7625e-02]],\n",
       "\n",
       "         [[-2.7383e-01, -2.0188e-01,  5.3889e-01,  ...,  5.5655e-01,\n",
       "           -2.8996e-01, -3.9666e-01],\n",
       "          [ 2.2742e-01,  5.0887e-01,  1.1834e-01,  ..., -5.2994e-01,\n",
       "            4.6627e-01, -1.2166e-02],\n",
       "          [ 5.2333e-01,  6.0486e-01, -6.1487e-01,  ...,  6.9838e-01,\n",
       "           -6.4573e-01, -5.9617e-01],\n",
       "          ...,\n",
       "          [-5.7386e-01, -6.8900e-01, -8.8382e-01,  ...,  2.1554e+00,\n",
       "            1.4065e-01, -1.2961e-01],\n",
       "          [ 1.7149e-01, -6.4544e-01, -3.5168e-01,  ...,  1.2141e+00,\n",
       "            3.2918e-01,  2.7857e-01],\n",
       "          [-6.2947e-02,  1.5151e-01, -1.9562e-02,  ...,  2.0377e-01,\n",
       "           -9.3632e-02,  7.5543e-01]],\n",
       "\n",
       "         [[ 2.8023e-01,  3.2446e-01, -4.6778e-02,  ..., -5.0911e-02,\n",
       "           -3.2495e-01, -6.6736e-02],\n",
       "          [ 8.7400e-02,  3.3582e-01,  5.2315e-01,  ...,  1.6086e-02,\n",
       "           -3.7463e-01,  2.2536e-01],\n",
       "          [ 3.8262e-01, -3.1642e-01, -2.9728e-01,  ..., -3.5291e-01,\n",
       "           -4.8439e-02, -3.7068e-01],\n",
       "          ...,\n",
       "          [ 1.8391e+00, -5.3666e-01, -5.2964e-01,  ...,  7.8438e-02,\n",
       "           -4.2587e-01,  2.0542e-01],\n",
       "          [ 1.0196e-01,  1.9120e-01,  3.4377e-02,  ...,  7.3107e-01,\n",
       "           -3.5667e-01, -1.8557e-01],\n",
       "          [-2.1623e-02, -8.3832e-02, -2.8828e-02,  ..., -1.9522e-02,\n",
       "           -9.5966e-02, -8.5484e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3177e+00, -1.5074e-01, -1.5754e-01,  ..., -1.9493e+00,\n",
       "           -3.1389e+00,  1.3225e+00],\n",
       "          [ 1.6206e+00, -1.3479e+00,  3.9191e-01,  ..., -1.7132e+00,\n",
       "           -2.8895e+00,  1.1331e+00],\n",
       "          [ 1.3080e+00, -1.2511e+00, -5.2411e-01,  ..., -1.4042e+00,\n",
       "           -2.6622e+00,  1.2717e+00],\n",
       "          ...,\n",
       "          [-1.4991e-02, -1.2070e+00, -1.7034e-01,  ..., -7.1680e-01,\n",
       "           -8.4062e-01,  3.1013e-01],\n",
       "          [ 5.2387e-01, -1.2533e+00,  5.1751e-01,  ...,  9.8569e-01,\n",
       "            1.1921e-01,  1.1301e+00],\n",
       "          [-2.4897e-02, -8.4817e-03,  8.0329e-02,  ...,  8.2577e-02,\n",
       "            9.4982e-02, -2.0682e-02]],\n",
       "\n",
       "         [[-3.7164e-01, -3.9240e-02, -1.3939e-01,  ..., -1.1169e-01,\n",
       "           -5.3740e-02, -2.5417e-01],\n",
       "          [ 4.6114e-01,  9.9277e-01, -7.1647e-01,  ..., -3.1574e-01,\n",
       "           -1.7227e-02, -1.3047e+00],\n",
       "          [ 1.2698e-02,  3.2188e-01,  1.0558e-03,  ..., -8.5507e-01,\n",
       "            5.2859e-01, -8.6328e-01],\n",
       "          ...,\n",
       "          [-2.8568e-01, -1.2566e-01, -1.4604e-01,  ..., -4.2707e-01,\n",
       "            5.2027e-01,  1.1542e-01],\n",
       "          [-5.8639e-01,  5.0840e-01,  1.2195e+00,  ...,  1.0038e+00,\n",
       "            4.6898e-01, -1.3878e-01],\n",
       "          [ 7.0359e-04, -9.5911e-03,  4.3862e-03,  ...,  2.4907e-02,\n",
       "            1.5229e-02, -5.0471e-02]],\n",
       "\n",
       "         [[-7.9218e-02,  7.2571e-02,  9.6938e-01,  ..., -1.5711e+00,\n",
       "           -3.6782e-01,  8.7097e-01],\n",
       "          [-3.3304e-01, -1.8523e-01,  1.0183e+00,  ..., -9.5283e-01,\n",
       "            5.5699e-01,  1.0246e+00],\n",
       "          [ 4.7298e-01, -3.1539e-01,  5.0056e-01,  ..., -2.2500e-01,\n",
       "           -2.2033e-01,  2.5500e-01],\n",
       "          ...,\n",
       "          [-8.6827e-01, -6.1695e-01,  6.3763e-01,  ...,  3.5212e-01,\n",
       "           -4.5406e-02,  1.0439e+00],\n",
       "          [-2.5321e-01, -3.5641e-01,  1.0988e-01,  ...,  3.2776e-01,\n",
       "           -1.8578e-01,  2.1536e-01],\n",
       "          [-3.9997e-02, -4.4191e-01,  1.5114e-02,  ..., -7.3509e-02,\n",
       "           -3.4302e-02,  3.4977e-02]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 0.5985,  1.5281,  0.6154,  ..., -1.3131,  1.2168,  0.9944],\n",
       "          [ 0.9576,  1.2717,  0.7665,  ..., -1.1650,  1.1459,  1.3599],\n",
       "          [ 0.3284,  1.8743,  0.0384,  ..., -1.0330,  1.0635,  0.2157],\n",
       "          ...,\n",
       "          [ 0.6742,  1.5131,  0.2221,  ..., -1.2168,  1.1153,  0.8127],\n",
       "          [ 1.3053,  2.0155,  0.4322,  ..., -0.5650,  1.0985,  1.7003],\n",
       "          [ 0.1343,  0.7530,  0.2918,  ..., -0.5965,  0.4895,  0.4927]],\n",
       "\n",
       "         [[-0.1796, -0.2683, -0.1503,  ...,  0.4235,  0.7860,  0.3834],\n",
       "          [-0.3423, -0.1967,  0.6992,  ...,  0.3132,  0.9175,  0.5192],\n",
       "          [-0.0854, -0.6568, -0.1104,  ..., -0.1919,  0.2588,  0.4654],\n",
       "          ...,\n",
       "          [-0.4433, -0.8231,  0.1904,  ...,  0.5814,  0.2141, -0.1075],\n",
       "          [-0.3158, -0.2252,  0.2431,  ...,  0.4704, -0.4968,  0.5396],\n",
       "          [-0.2591, -0.6967,  0.8838,  ...,  0.2882, -0.1334,  0.4498]],\n",
       "\n",
       "         [[-0.4647,  0.0344,  0.0167,  ..., -0.4759, -0.1536,  0.7362],\n",
       "          [ 0.1532,  0.2713,  0.2209,  ...,  0.0940, -0.1164,  0.4756],\n",
       "          [-0.1444,  0.0528, -0.1145,  ..., -0.3282, -0.6644,  0.4337],\n",
       "          ...,\n",
       "          [-0.4632,  0.6827,  0.3672,  ..., -0.2212, -0.1775,  1.0600],\n",
       "          [-0.2288,  0.2916,  0.0899,  ...,  0.7545,  0.8570,  0.7064],\n",
       "          [ 0.0880, -0.4872, -0.5691,  ..., -0.2418,  0.2318,  0.2403]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1563, -0.6551,  0.8052,  ...,  0.0552,  0.6205, -0.3776],\n",
       "          [ 0.0991, -0.2938,  0.9240,  ...,  0.1207,  0.5956, -0.9238],\n",
       "          [ 0.0572, -0.3913,  0.7084,  ...,  0.6373, -0.1297, -0.3158],\n",
       "          ...,\n",
       "          [ 0.4117,  0.3673,  0.6237,  ..., -0.7396,  1.3171, -0.3195],\n",
       "          [ 1.0533, -1.2659,  0.6674,  ...,  0.0351, -0.6849, -1.2134],\n",
       "          [-0.8988, -1.1918,  0.6901,  ...,  0.0484,  0.1298,  0.7698]],\n",
       "\n",
       "         [[ 0.2993,  1.4683, -0.7370,  ...,  1.4610,  0.6602, -1.0838],\n",
       "          [ 0.1395,  0.9432,  0.3791,  ...,  0.3860, -0.1608, -0.1248],\n",
       "          [-0.6865,  1.2188, -1.1489,  ...,  1.2713,  0.9743, -1.2431],\n",
       "          ...,\n",
       "          [ 0.6219,  1.6094,  0.3532,  ...,  0.8102, -0.4408, -0.7624],\n",
       "          [ 0.2441,  0.9991,  0.9282,  ...,  0.0241, -0.7140,  0.1290],\n",
       "          [-1.4010,  1.3536,  0.2199,  ...,  0.9240, -0.0108, -0.2045]],\n",
       "\n",
       "         [[-0.4642,  0.2367, -0.0449,  ..., -0.1131,  0.6748,  0.6192],\n",
       "          [-0.3948,  0.9473,  1.0579,  ..., -0.4227, -0.3880, -0.0739],\n",
       "          [-0.2270, -0.5755,  0.3037,  ..., -1.0744, -0.4485,  0.2931],\n",
       "          ...,\n",
       "          [-0.2227,  0.4612,  0.5043,  ..., -0.6530,  0.0640,  0.4086],\n",
       "          [ 0.1778,  0.4858,  0.3038,  ..., -0.3907, -0.2226, -0.2035],\n",
       "          [-0.7819,  0.4682, -0.4293,  ...,  0.3589,  1.4119,  1.0768]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-0.1606,  0.0415,  0.0907,  ...,  0.1340, -0.0247, -0.0022],\n",
       "          [ 0.2090, -0.1426,  0.2186,  ...,  0.1200, -0.0444, -0.0086],\n",
       "          [ 0.0024, -0.0181,  0.1886,  ...,  0.4734,  0.2033, -0.0556],\n",
       "          ...,\n",
       "          [ 0.3076, -0.1127, -0.1289,  ..., -0.0708,  0.3194,  0.4027],\n",
       "          [ 0.1958, -0.0763,  0.0891,  ..., -0.3703,  0.1080,  0.1472],\n",
       "          [-0.1877, -0.0455,  0.1742,  ..., -0.1269, -0.1529,  0.1909]],\n",
       "\n",
       "         [[ 0.2636,  1.2961,  1.0778,  ..., -0.6097,  1.1055, -0.6257],\n",
       "          [-0.7421,  0.7941,  1.4026,  ..., -0.2624,  1.0633, -1.0019],\n",
       "          [ 0.4498,  1.3272,  0.5095,  ..., -0.3176,  1.5414, -0.9960],\n",
       "          ...,\n",
       "          [ 0.1032,  1.0013, -0.2411,  ..., -0.5122,  0.7822, -0.7161],\n",
       "          [-0.9762,  0.4529, -0.5569,  ...,  0.3110,  0.1055, -0.0283],\n",
       "          [ 0.4880,  0.8061,  0.4560,  ..., -0.1861,  0.2135,  0.6011]],\n",
       "\n",
       "         [[-0.1741,  0.0578, -0.1771,  ..., -0.1412,  0.0370, -0.6018],\n",
       "          [-0.1168,  0.1859,  0.2194,  ...,  0.1478,  0.1642, -0.7725],\n",
       "          [ 0.1071,  0.3151, -0.3891,  ..., -0.1520,  0.2126, -0.6760],\n",
       "          ...,\n",
       "          [ 0.2949, -0.0127,  0.0423,  ...,  0.0331, -0.1022, -0.1769],\n",
       "          [ 0.2214,  0.0113, -0.0031,  ..., -0.2556,  0.1290, -0.4305],\n",
       "          [ 0.1217,  0.1701, -0.1167,  ..., -0.3050,  0.0477, -1.0499]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.2755,  0.9018, -0.5204,  ..., -0.2284,  0.7991, -0.1413],\n",
       "          [-0.0552,  0.5357,  0.1406,  ..., -0.2657,  0.7772, -0.3310],\n",
       "          [-0.7883,  0.8393, -0.1757,  ..., -0.8643,  0.1757, -0.1016],\n",
       "          ...,\n",
       "          [ 0.2388,  0.8433, -0.1085,  ...,  0.5129,  0.1614, -0.3226],\n",
       "          [ 0.0145, -0.0697, -0.3646,  ...,  0.0631,  0.5226, -0.1113],\n",
       "          [-0.2118,  0.0032, -0.5825,  ...,  0.1097,  0.4285, -0.6147]],\n",
       "\n",
       "         [[-0.2051,  0.2578,  0.1919,  ..., -0.0016, -0.8599, -0.1638],\n",
       "          [-0.3659,  0.1955,  0.3398,  ..., -0.2111, -1.0302,  0.0114],\n",
       "          [-0.3301,  0.3817,  0.3135,  ...,  0.1009, -0.6209, -0.1670],\n",
       "          ...,\n",
       "          [-0.2337,  0.1097,  0.6568,  ..., -0.2349, -0.6593, -0.1335],\n",
       "          [-0.2860,  0.2422,  0.5380,  ..., -0.0700, -0.9649, -0.2689],\n",
       "          [ 0.1282,  0.2376,  0.2107,  ...,  0.1149, -1.2049,  0.2001]],\n",
       "\n",
       "         [[ 0.2578, -0.5395, -0.2432,  ..., -0.0053, -0.1262,  0.0804],\n",
       "          [-0.1006, -0.4148,  0.7512,  ..., -0.1737, -0.0818, -0.4384],\n",
       "          [ 0.4578, -0.2677, -0.5044,  ...,  0.1693, -0.0810,  0.2740],\n",
       "          ...,\n",
       "          [ 0.2408, -0.1586,  0.0109,  ...,  0.0285, -0.2846,  0.0449],\n",
       "          [ 0.0913, -0.1153, -0.0107,  ..., -0.3568,  0.4042, -0.0298],\n",
       "          [ 0.4273, -0.0440,  0.1997,  ...,  0.0582, -0.1244,  0.0097]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-0.9602,  0.3490,  0.9534,  ...,  0.0578,  1.4866, -0.9491],\n",
       "          [-0.7840, -0.0546,  0.1148,  ..., -1.2001,  2.0657, -2.1420],\n",
       "          [-1.6525,  0.2191,  0.5177,  ..., -0.7308,  1.1608, -1.5720],\n",
       "          ...,\n",
       "          [-0.7404, -0.9654,  0.0113,  ..., -0.3055,  1.4908, -1.7378],\n",
       "          [-0.6087, -1.2060,  0.8090,  ...,  1.1216,  1.4549, -1.6404],\n",
       "          [-0.2286,  0.4115, -0.1198,  ..., -0.3683, -1.0119,  0.1823]],\n",
       "\n",
       "         [[-0.9497,  0.8886, -0.0744,  ...,  0.4109,  1.5000,  1.1600],\n",
       "          [-0.1409,  0.7176,  1.2100,  ..., -0.9108,  1.1953,  1.4413],\n",
       "          [-1.0043,  0.3166,  1.2927,  ...,  1.4599,  0.4493,  0.3044],\n",
       "          ...,\n",
       "          [-1.4832,  1.4508,  0.0153,  ..., -0.0850,  0.7241,  0.9272],\n",
       "          [-3.6579,  0.4309,  0.0549,  ...,  0.3446,  0.0806,  0.6552],\n",
       "          [ 0.5293,  0.1371, -0.6791,  ...,  0.1653, -1.0807,  0.2905]],\n",
       "\n",
       "         [[ 0.4928, -0.6666, -0.8365,  ...,  1.5080,  1.1991, -0.3182],\n",
       "          [ 1.0060,  0.3005, -0.6344,  ...,  2.5439,  2.1262, -1.5750],\n",
       "          [-0.1331, -1.0616, -0.3973,  ...,  2.1201,  1.4372, -1.1464],\n",
       "          ...,\n",
       "          [ 0.7663, -1.1797,  0.3709,  ...,  1.6014, -0.4732,  0.9814],\n",
       "          [ 1.5907, -1.6584, -0.2149,  ...,  1.1564,  1.1007,  1.4557],\n",
       "          [ 0.1732,  0.0628, -0.2877,  ..., -1.3470,  0.0807,  0.0208]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2835, -1.1386, -0.3054,  ...,  0.3255, -0.5620, -1.0757],\n",
       "          [ 0.5968, -0.0509,  0.1047,  ...,  0.6636,  0.6283, -1.2395],\n",
       "          [ 1.0406, -0.2882, -0.1434,  ...,  0.3055, -0.1044, -0.4941],\n",
       "          ...,\n",
       "          [ 1.3811,  0.6493, -0.1093,  ...,  1.4761, -1.3366, -0.2707],\n",
       "          [ 2.6074,  0.2967,  0.9880,  ...,  1.7590, -0.1104,  0.4200],\n",
       "          [-1.0429, -0.0181, -0.1591,  ...,  0.1696,  0.0795, -0.0721]],\n",
       "\n",
       "         [[ 0.2701, -0.3177, -1.3971,  ...,  1.6851,  0.4606, -2.6293],\n",
       "          [ 0.2452, -0.0064,  0.2356,  ...,  1.5910, -0.2774, -2.4564],\n",
       "          [-0.9675, -0.1375, -0.7921,  ...,  1.6070,  0.3908, -2.6278],\n",
       "          ...,\n",
       "          [-1.1035, -1.0749, -2.7406,  ..., -1.0395, -1.0598, -2.6328],\n",
       "          [-2.5853, -0.3344, -3.1347,  ..., -0.6605, -0.7145, -2.5341],\n",
       "          [ 0.0356,  0.5282,  0.4352,  ..., -0.1197, -0.2318,  1.9969]],\n",
       "\n",
       "         [[ 0.5144,  0.5397, -0.9938,  ...,  0.9496,  0.9357, -0.0187],\n",
       "          [-0.4538, -0.0316, -0.2582,  ...,  0.7389,  1.3823,  0.4623],\n",
       "          [ 0.2397,  0.7703, -0.4043,  ...,  1.1600,  0.9847,  0.3297],\n",
       "          ...,\n",
       "          [-0.6755,  1.4114, -0.2554,  ...,  0.4899,  0.6380,  1.2659],\n",
       "          [-0.5232, -0.7139, -1.2060,  ..., -0.3338,  0.4712,  0.8370],\n",
       "          [-0.2173,  0.1385,  0.5550,  ..., -0.1626, -0.0579,  0.2147]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 4.1359e-01, -1.1869e+00, -9.4476e-01,  ...,  2.9300e-01,\n",
       "            3.5881e-02, -6.9355e-01],\n",
       "          [ 8.9899e-01, -1.5582e+00, -6.6890e-01,  ...,  8.5300e-01,\n",
       "           -8.1601e-02, -1.8383e+00],\n",
       "          [ 3.3493e-03, -1.5814e+00, -7.2006e-01,  ...,  1.2997e-01,\n",
       "           -8.2677e-01, -9.4357e-01],\n",
       "          ...,\n",
       "          [ 2.3277e+00, -4.7815e-01, -6.8589e-01,  ...,  1.3321e+00,\n",
       "           -3.4707e-02,  2.2175e-01],\n",
       "          [ 1.2304e+00,  6.7866e-01, -1.4964e+00,  ...,  4.3164e-01,\n",
       "            8.0440e-01,  6.1801e-01],\n",
       "          [-1.6179e-01,  7.7821e-02,  2.4418e-02,  ..., -8.8621e-02,\n",
       "           -6.0081e-03,  2.3362e-01]],\n",
       "\n",
       "         [[ 4.6816e-01, -4.3308e-01,  8.6385e-01,  ...,  2.3596e-01,\n",
       "           -5.9953e-02, -9.4696e-01],\n",
       "          [ 2.2430e-01, -3.1247e-01,  2.1694e+00,  ..., -7.3873e-01,\n",
       "           -5.6604e-01, -1.3404e+00],\n",
       "          [ 2.7876e-01, -4.8427e-01,  1.5429e+00,  ...,  2.2265e-01,\n",
       "            4.8063e-01, -7.6982e-01],\n",
       "          ...,\n",
       "          [ 1.0565e-01, -7.0193e-02,  7.1803e-02,  ..., -7.0525e-01,\n",
       "            1.4218e-01, -3.8306e-01],\n",
       "          [-9.7754e-01,  4.4687e-01,  1.1141e+00,  ..., -2.6455e-01,\n",
       "            7.2714e-01, -1.6126e+00],\n",
       "          [-1.5555e-02,  1.1513e-01,  8.8158e-02,  ...,  1.8616e-02,\n",
       "            8.0532e-02,  2.2726e-02]],\n",
       "\n",
       "         [[-8.1170e-01, -1.4942e+00, -4.9506e-01,  ...,  2.7828e-01,\n",
       "            3.6979e-01, -8.0416e-01],\n",
       "          [-8.8163e-01, -4.7600e-03, -5.2837e-01,  ...,  1.0312e-01,\n",
       "           -2.1602e-02, -1.0114e+00],\n",
       "          [-2.2792e-01, -3.2853e-01, -9.1276e-01,  ..., -5.6868e-01,\n",
       "           -7.0734e-01,  5.6356e-03],\n",
       "          ...,\n",
       "          [-8.3821e-01,  2.7335e-01, -8.4729e-03,  ..., -5.4711e-01,\n",
       "           -1.5374e+00,  1.0322e-01],\n",
       "          [-7.2131e-01, -7.1634e-01,  6.3531e-01,  ..., -4.6763e-02,\n",
       "           -2.0715e-01,  1.0550e+00],\n",
       "          [-1.1593e-01,  5.6433e-03,  1.1410e-02,  ..., -4.8547e-02,\n",
       "           -1.0060e-01,  5.9101e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.1146e-01, -4.8652e-01, -1.6649e-01,  ..., -2.6670e-01,\n",
       "            1.2136e+00, -7.6709e-02],\n",
       "          [-1.3270e-01, -5.4552e-01,  1.9421e-01,  ...,  3.9302e-01,\n",
       "           -2.8015e-01, -6.6904e-01],\n",
       "          [ 1.1086e-01,  8.1759e-02, -4.5944e-01,  ...,  9.3805e-01,\n",
       "           -1.7029e-01,  1.5559e-01],\n",
       "          ...,\n",
       "          [-9.8141e-01, -4.0176e-01,  1.0175e+00,  ...,  7.3692e-01,\n",
       "           -5.0828e-01, -3.1427e-01],\n",
       "          [-1.5665e+00, -3.9838e-01, -9.3331e-01,  ...,  2.0819e-01,\n",
       "            1.7812e-01, -6.0756e-01],\n",
       "          [ 8.2873e-02,  1.3399e-01,  6.8946e-02,  ..., -1.8418e-02,\n",
       "           -8.3514e-02,  3.0406e-02]],\n",
       "\n",
       "         [[-3.9774e-01, -2.7338e-01,  7.5032e-01,  ...,  1.7315e+00,\n",
       "           -4.2182e-01,  1.0700e-01],\n",
       "          [-9.1306e-02, -1.3999e-01,  6.7147e-01,  ...,  2.9074e+00,\n",
       "            2.9026e-03, -1.3341e+00],\n",
       "          [-1.1843e-01,  6.2182e-01,  8.4385e-01,  ...,  1.4778e+00,\n",
       "           -3.4400e-01, -1.4468e+00],\n",
       "          ...,\n",
       "          [-3.5504e-01,  6.1229e-01,  3.5705e-01,  ..., -3.2832e-01,\n",
       "           -6.5610e-01, -2.3763e-01],\n",
       "          [-2.0149e-01, -8.7745e-01,  7.2107e-02,  ..., -3.4775e-01,\n",
       "            3.6052e-01, -4.4427e-02],\n",
       "          [ 1.0720e-01,  2.8933e-04,  1.0222e-02,  ...,  2.1402e-01,\n",
       "            1.0775e-01,  7.1079e-02]],\n",
       "\n",
       "         [[-8.2203e-01,  1.1985e+00,  1.1106e+00,  ...,  3.9931e-01,\n",
       "           -5.9787e-01,  4.5535e-01],\n",
       "          [-5.2816e-01, -3.1332e-01,  2.2465e+00,  ..., -6.2771e-01,\n",
       "           -1.2292e+00,  7.5907e-01],\n",
       "          [-7.0161e-01,  1.3386e+00,  8.8399e-01,  ...,  4.7587e-01,\n",
       "           -4.9145e-01,  1.4238e+00],\n",
       "          ...,\n",
       "          [-7.8153e-02,  1.3702e+00, -1.4460e+00,  ...,  1.9305e+00,\n",
       "           -5.1018e-01, -6.1643e-02],\n",
       "          [-4.0018e-01, -1.5536e-01,  2.1169e-01,  ..., -9.4702e-01,\n",
       "           -7.8050e-01,  7.7179e-01],\n",
       "          [ 2.3923e-02, -4.8410e-01,  1.2725e-02,  ..., -3.9541e-01,\n",
       "           -9.4453e-02,  1.2730e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 2.4758,  0.5566,  0.6080,  ..., -0.5986,  0.9093, -1.4448],\n",
       "          [ 1.5071, -0.4320, -0.0684,  ...,  0.1988, -0.6093, -0.0374],\n",
       "          [ 2.6891,  1.4216,  0.8828,  ...,  2.5369, -0.2449, -2.3035],\n",
       "          ...,\n",
       "          [ 3.4611,  1.7232,  0.5586,  ...,  0.6008, -1.4554, -0.1606],\n",
       "          [ 0.2944, -1.6928, -1.3185,  ...,  1.9367, -1.9558, -0.9050],\n",
       "          [ 2.0727, -1.0277, -0.7026,  ...,  1.1936, -0.5553, -0.6747]],\n",
       "\n",
       "         [[ 0.5158, -1.0948,  2.1587,  ..., -0.4688, -1.8062, -0.4322],\n",
       "          [ 0.8439, -0.9898,  1.4973,  ...,  0.3885, -2.1277, -0.2960],\n",
       "          [-1.4221, -1.0305,  1.9789,  ..., -0.4716, -1.9835, -1.7756],\n",
       "          ...,\n",
       "          [ 0.7251, -2.1292,  2.5840,  ..., -1.0704, -1.6603, -1.0920],\n",
       "          [ 0.9580, -1.8827,  1.5945,  ..., -0.5968,  0.0570,  0.3807],\n",
       "          [ 0.1337, -0.8464,  1.5385,  ...,  0.8694,  0.4254, -1.1746]],\n",
       "\n",
       "         [[ 1.0127,  1.9661,  0.6681,  ...,  2.0228, -2.2113,  0.2233],\n",
       "          [-0.4354,  2.3477, -0.0400,  ...,  1.5693, -2.6178,  0.1524],\n",
       "          [-0.3467,  2.2020, -0.4882,  ...,  1.6301, -1.6048,  0.8168],\n",
       "          ...,\n",
       "          [-0.0940,  2.0802, -2.0287,  ...,  1.9500, -0.6827, -1.2429],\n",
       "          [-0.4972,  3.4779, -1.1184,  ...,  1.2255, -1.9777, -1.3951],\n",
       "          [ 0.6545,  1.7181, -0.2126,  ...,  0.8013, -0.9423,  0.0752]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.3149, -1.8765,  1.6779,  ..., -2.1172, -1.3623, -0.0479],\n",
       "          [ 0.1176, -1.4090, -0.1284,  ..., -2.1522, -2.0367,  0.5812],\n",
       "          [-2.6804, -2.0721,  1.2940,  ..., -1.9411, -0.8394,  0.4716],\n",
       "          ...,\n",
       "          [-1.2821, -1.5255,  0.5355,  ..., -1.9311, -1.3512,  1.7858],\n",
       "          [-0.5384, -1.2344, -1.4522,  ..., -1.8700, -1.1580,  0.7804],\n",
       "          [-1.6702, -1.0057, -0.2132,  ..., -1.6643, -1.2904, -1.6596]],\n",
       "\n",
       "         [[-2.2350,  1.2932, -4.4072,  ..., -0.5532, -0.7672,  2.2466],\n",
       "          [-2.4726,  2.1547, -4.0899,  ..., -0.4484, -0.9108, -0.2235],\n",
       "          [-2.3447,  1.3288, -4.5625,  ...,  0.2874, -1.9521,  1.4100],\n",
       "          ...,\n",
       "          [-3.3122,  1.9148, -3.8943,  ..., -0.3463,  0.9488,  1.8379],\n",
       "          [-2.3816,  0.9286, -3.2977,  ..., -0.5838,  0.5490,  0.7211],\n",
       "          [-3.8839, -0.2568, -4.6390,  ..., -0.0658,  0.3862,  0.5291]],\n",
       "\n",
       "         [[ 0.5457,  0.9071, -1.1333,  ..., -2.9058, -1.0365,  1.6852],\n",
       "          [ 1.0391, -0.3761, -1.2671,  ..., -0.8000, -1.9845,  0.3088],\n",
       "          [-0.4527,  0.4786, -0.3481,  ..., -2.1411, -0.8679,  0.7051],\n",
       "          ...,\n",
       "          [-1.5903, -0.2940,  0.6214,  ...,  0.1210,  3.2532,  0.8775],\n",
       "          [-1.1129, -0.2585,  1.6389,  ...,  0.7683,  0.4619, -0.1906],\n",
       "          [-1.4951, -0.5214, -0.0334,  ...,  0.2712,  0.4453,  1.5057]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-1.1306e+00, -2.2805e-01,  1.3080e+00,  ...,  1.2569e-01,\n",
       "            1.2761e+00, -3.9560e-01],\n",
       "          [-1.2534e+00,  2.4988e+00,  1.7811e+00,  ..., -7.2998e-01,\n",
       "            1.0537e+00,  7.0507e-01],\n",
       "          [-2.5712e+00,  1.0563e+00, -9.0265e-02,  ...,  1.0418e+00,\n",
       "            1.4907e+00, -2.9749e-02],\n",
       "          ...,\n",
       "          [-1.2848e+00,  8.6023e-01, -1.8578e+00,  ..., -5.8971e-01,\n",
       "            7.3295e-01, -1.6749e+00],\n",
       "          [-2.2818e+00,  1.6077e+00,  5.8404e-01,  ...,  7.9971e-01,\n",
       "           -8.0722e-01,  5.6260e-02],\n",
       "          [ 7.2274e-01,  2.4823e+00, -7.3608e-01,  ...,  4.6725e-02,\n",
       "            1.2719e+00,  2.1817e-01]],\n",
       "\n",
       "         [[ 4.1796e-01,  2.2785e+00, -8.0288e-01,  ..., -5.7850e-01,\n",
       "            3.9885e-01,  2.7564e+00],\n",
       "          [ 3.8006e-01,  9.2855e-01,  1.4986e-01,  ..., -3.9588e-01,\n",
       "           -1.2442e+00,  3.3242e+00],\n",
       "          [-1.7313e-01,  5.0706e-01,  1.8725e-01,  ..., -2.9378e-01,\n",
       "            8.8070e-01,  2.0972e+00],\n",
       "          ...,\n",
       "          [-1.4276e+00, -6.4260e-01, -6.2285e-01,  ...,  7.7675e-02,\n",
       "           -6.8552e-01, -5.4718e-02],\n",
       "          [ 1.4653e-01, -9.4050e-01, -8.8762e-01,  ...,  9.4374e-01,\n",
       "           -9.0513e-01, -5.4196e-01],\n",
       "          [ 3.8493e-01, -1.0308e-01, -5.8234e-01,  ...,  2.5141e-01,\n",
       "           -3.4233e-01,  1.5991e+00]],\n",
       "\n",
       "         [[ 1.3824e+00,  9.5177e-01,  1.0765e+00,  ...,  1.2061e+00,\n",
       "           -8.7642e-01,  1.0262e-01],\n",
       "          [ 4.9028e-01,  2.3022e+00, -6.2942e-01,  ...,  5.7542e-01,\n",
       "           -7.7231e-01, -1.5147e-01],\n",
       "          [ 1.2480e+00,  6.5047e-01, -8.5745e-01,  ..., -7.8726e-01,\n",
       "            5.4017e-01, -4.7961e-02],\n",
       "          ...,\n",
       "          [-9.8549e-01, -9.3256e-01,  1.4584e-01,  ..., -6.6170e-01,\n",
       "           -1.0953e+00, -5.2158e-01],\n",
       "          [ 1.7899e-01, -1.5197e+00, -2.7197e-01,  ..., -1.6751e-01,\n",
       "           -1.2020e+00, -2.3507e-01],\n",
       "          [ 1.0684e+00,  6.1446e-01, -7.3044e-02,  ...,  4.9994e-01,\n",
       "           -6.0964e-02,  5.3388e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.9840e-01,  1.9959e-01,  1.3286e-01,  ...,  1.7457e-01,\n",
       "            3.5285e-01, -7.9622e-01],\n",
       "          [-9.2627e-01,  1.1123e-01,  1.3679e-02,  ...,  5.8434e-01,\n",
       "            7.6088e-01, -9.0912e-01],\n",
       "          [-4.9584e-01, -1.7210e-01, -3.1994e-03,  ...,  1.7199e-01,\n",
       "            3.7339e-01, -3.3605e-01],\n",
       "          ...,\n",
       "          [ 1.6910e-01,  8.1898e-01, -2.1471e-01,  ..., -1.3291e+00,\n",
       "            3.5633e-01,  5.3608e-01],\n",
       "          [-4.0111e-01,  5.7812e-01, -2.7895e-02,  ...,  1.4765e-01,\n",
       "            5.3707e-01, -6.2205e-01],\n",
       "          [-5.8234e-01, -1.2259e-01,  3.8797e-01,  ...,  1.9972e-02,\n",
       "            3.3839e-03, -4.7231e-01]],\n",
       "\n",
       "         [[-4.5153e-01,  9.1282e-02,  2.6454e-01,  ...,  1.7935e+00,\n",
       "           -1.4499e+00,  1.1390e+00],\n",
       "          [-9.0623e-01,  1.8303e-01,  1.5464e-01,  ..., -3.6570e-01,\n",
       "            4.2360e-01,  7.8161e-02],\n",
       "          [-3.5476e-01, -4.0518e-02, -5.4597e-01,  ...,  1.2121e+00,\n",
       "           -4.8556e-01,  2.0211e+00],\n",
       "          ...,\n",
       "          [-8.1337e-01,  9.8206e-01,  1.7185e+00,  ...,  1.0586e+00,\n",
       "            1.1429e+00, -5.4269e-01],\n",
       "          [-4.1509e-01,  3.8587e-01,  9.0630e-01,  ..., -1.4357e-01,\n",
       "            3.0717e-01,  8.6258e-01],\n",
       "          [-1.0522e+00, -4.7390e-01,  1.1335e+00,  ..., -2.1985e-01,\n",
       "           -5.4699e-01,  3.1109e-02]],\n",
       "\n",
       "         [[-8.1249e-01, -1.3806e+00,  5.1120e-01,  ...,  1.2667e+00,\n",
       "            7.9726e-01, -6.0343e-01],\n",
       "          [ 3.0125e-01,  1.2801e+00,  1.7281e+00,  ...,  1.0602e-01,\n",
       "            2.7048e+00, -7.9155e-01],\n",
       "          [ 1.0239e+00, -1.5937e+00,  4.5901e-01,  ...,  9.0723e-01,\n",
       "           -1.0917e+00, -1.1322e+00],\n",
       "          ...,\n",
       "          [ 4.7693e-01, -1.4951e+00,  9.3609e-01,  ..., -1.5967e+00,\n",
       "           -2.0862e-01, -4.9970e-01],\n",
       "          [ 1.4866e+00,  7.9292e-02, -3.3593e-02,  ...,  7.3138e-01,\n",
       "            1.2642e+00, -4.9447e-01],\n",
       "          [-1.4976e+00,  2.8573e-01,  2.2762e+00,  ..., -4.7316e-01,\n",
       "            7.7549e-01,  1.3954e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-3.2479e-01, -2.0298e-01,  7.8581e-01,  ...,  2.9633e+00,\n",
       "           -1.2592e-01,  3.4333e+00],\n",
       "          [-7.3853e-01,  4.5320e-02,  1.2412e+00,  ...,  3.7041e+00,\n",
       "           -8.1008e-01,  2.3053e+00],\n",
       "          [ 2.0607e-01, -2.8087e-01,  6.6076e-01,  ...,  2.3991e+00,\n",
       "           -6.4545e-01,  2.4903e+00],\n",
       "          ...,\n",
       "          [-7.2982e-01, -2.2638e+00, -1.3441e-01,  ...,  2.1531e+00,\n",
       "            1.5923e-01,  2.2357e+00],\n",
       "          [-1.8887e+00, -2.2116e-01,  2.8358e-01,  ...,  1.8038e+00,\n",
       "           -2.5937e+00,  3.4401e-01],\n",
       "          [ 4.5307e-01,  1.1226e-01, -4.0063e-01,  ..., -1.4459e+00,\n",
       "           -3.4653e-01,  5.8221e-02]],\n",
       "\n",
       "         [[ 5.6624e-01, -2.4710e-01,  5.3031e-01,  ..., -4.3107e-02,\n",
       "           -1.2180e+00, -1.0100e+00],\n",
       "          [-3.4478e-02, -2.8567e-01,  1.4576e+00,  ..., -7.5581e-01,\n",
       "           -2.1881e-01, -1.7247e+00],\n",
       "          [ 5.8247e-01, -3.8026e-01,  8.3971e-01,  ..., -6.2717e-01,\n",
       "           -6.4546e-01, -8.9336e-01],\n",
       "          ...,\n",
       "          [-2.4132e-01,  6.0865e-01,  1.6505e+00,  ..., -3.6629e-01,\n",
       "           -2.7090e-01, -2.3214e+00],\n",
       "          [-2.0138e+00,  2.2131e+00,  1.6099e+00,  ..., -3.3011e+00,\n",
       "            1.4848e-01, -2.1010e+00],\n",
       "          [-8.5227e-01,  4.9749e-01, -8.6962e-01,  ..., -1.1438e-01,\n",
       "            8.3697e-02,  1.1408e+00]],\n",
       "\n",
       "         [[-6.1225e-01,  1.6629e+00, -3.6186e+00,  ..., -1.3411e+00,\n",
       "           -3.1046e+00,  1.6227e+00],\n",
       "          [-6.5266e-01,  6.7262e-01, -3.5016e+00,  ..., -1.9372e+00,\n",
       "           -1.9049e+00, -4.8749e-01],\n",
       "          [ 2.0852e-01,  3.9478e-01, -2.8495e+00,  ..., -1.5508e+00,\n",
       "           -2.9265e+00,  1.2078e+00],\n",
       "          ...,\n",
       "          [-7.9588e-01,  3.9072e-01, -1.0952e+00,  ...,  2.4124e+00,\n",
       "           -1.8900e+00,  3.5993e+00],\n",
       "          [-1.3743e+00,  1.2153e+00, -7.7159e-01,  ..., -3.0848e-01,\n",
       "            2.3618e-01,  5.1739e-01],\n",
       "          [ 3.1759e-01, -4.2452e-01,  4.9069e-01,  ...,  6.3265e-02,\n",
       "           -1.9185e-01, -3.5616e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.2738e-01, -5.5871e-02,  4.3466e-02,  ...,  2.1484e+00,\n",
       "            3.1910e-01,  3.2810e-01],\n",
       "          [ 3.1138e-01, -3.1189e-01, -3.4102e-01,  ...,  2.9052e+00,\n",
       "            4.4333e-01, -6.8297e-01],\n",
       "          [ 2.4632e-01, -1.4874e-01, -2.2272e-01,  ...,  1.8560e+00,\n",
       "            6.0427e-01, -2.7838e-01],\n",
       "          ...,\n",
       "          [-4.8399e-01, -3.6206e-01, -1.0505e+00,  ...,  7.5456e-01,\n",
       "            8.1079e-01, -9.9930e-01],\n",
       "          [-1.8439e-01,  1.1667e+00, -1.3655e+00,  ...,  2.4322e+00,\n",
       "           -2.2617e-02, -1.0631e+00],\n",
       "          [-1.0344e+00,  1.9698e-01, -9.2227e-01,  ..., -1.2981e+00,\n",
       "            7.2564e-02,  9.8730e-02]],\n",
       "\n",
       "         [[-5.7927e-01, -8.2631e-01,  9.0523e-01,  ..., -1.7707e+00,\n",
       "            1.2309e+00, -3.1660e-03],\n",
       "          [-1.9259e+00, -1.4010e+00,  1.9756e-02,  ..., -1.0077e+00,\n",
       "            9.2323e-01,  1.1718e+00],\n",
       "          [-1.8865e+00, -1.7757e+00,  3.6718e-01,  ..., -9.9297e-01,\n",
       "            1.1748e+00,  7.7160e-01],\n",
       "          ...,\n",
       "          [-1.4026e+00,  1.4560e+00, -8.6361e-01,  ...,  2.0866e+00,\n",
       "            2.1976e+00,  1.9422e-01],\n",
       "          [-1.4918e+00,  1.6134e+00, -4.6832e-01,  ...,  2.0948e-01,\n",
       "            2.2223e+00, -5.6628e-01],\n",
       "          [ 1.6077e-02, -3.1629e-01,  3.2397e-02,  ..., -2.1726e-01,\n",
       "           -3.4543e-03,  8.7933e-01]],\n",
       "\n",
       "         [[ 1.6924e+00, -5.5153e-01, -3.9039e-01,  ...,  9.4705e-01,\n",
       "            8.3999e-01,  5.0955e-01],\n",
       "          [ 8.7423e-01, -5.0005e-01,  4.9780e-02,  ...,  7.2872e-01,\n",
       "            2.0736e-01, -6.0101e-01],\n",
       "          [ 2.1984e+00,  6.2932e-02, -9.2077e-01,  ...,  5.7201e-01,\n",
       "            1.0570e+00, -2.8513e-01],\n",
       "          ...,\n",
       "          [ 1.5507e-01,  1.5161e+00,  3.0385e-01,  ...,  3.1623e-01,\n",
       "            4.4705e-01, -1.9126e+00],\n",
       "          [-1.3831e+00,  1.9826e+00,  7.7963e-01,  ..., -1.2457e+00,\n",
       "            8.5176e-01, -1.5711e+00],\n",
       "          [-4.1865e-01, -1.8929e-01, -4.8007e-01,  ..., -3.7398e-01,\n",
       "            3.7157e-02,  9.3336e-02]]]], grad_fn=<TransposeBackward0>), tensor([[[[ 3.2744e-01, -9.8420e-01, -9.9128e-01,  ..., -1.2663e-01,\n",
       "           -8.8005e-02, -6.1904e-01],\n",
       "          [-7.1856e-01, -5.8621e-01, -5.3827e-01,  ..., -2.4042e-01,\n",
       "           -5.2304e-01, -9.4837e-01],\n",
       "          [ 4.7799e-01, -8.4882e-01, -1.7067e+00,  ...,  5.0100e-01,\n",
       "           -2.1063e-01, -9.0290e-01],\n",
       "          ...,\n",
       "          [ 4.9715e-01, -1.2508e+00, -1.2596e-01,  ..., -1.8293e+00,\n",
       "           -1.7059e+00, -1.6166e+00],\n",
       "          [ 1.3796e+00, -4.8521e-01,  1.0471e+00,  ..., -5.9778e-01,\n",
       "           -1.6455e+00,  9.4646e-01],\n",
       "          [-4.2787e-02,  6.2647e-02, -5.7749e-02,  ..., -1.5863e-01,\n",
       "            4.1027e-03,  2.2659e-01]],\n",
       "\n",
       "         [[ 1.5846e+00, -1.1654e+00,  7.5643e-01,  ...,  1.9140e-01,\n",
       "           -2.9778e-01, -1.8322e+00],\n",
       "          [ 1.6450e-01, -3.5505e-01, -1.4133e-01,  ..., -1.0621e+00,\n",
       "           -1.4851e-01, -6.8005e-01],\n",
       "          [-3.5061e-01,  1.2724e-01,  7.4734e-01,  ..., -1.2110e+00,\n",
       "            8.6832e-01, -8.5316e-01],\n",
       "          ...,\n",
       "          [-3.2819e-01, -8.0800e-01, -9.1203e-01,  ..., -5.2186e-01,\n",
       "           -4.1434e-01, -1.0273e+00],\n",
       "          [-5.5149e-01, -1.6173e+00,  5.4258e-01,  ..., -1.1695e+00,\n",
       "            3.8498e-01,  5.1622e-01],\n",
       "          [-2.8959e-02,  1.0476e-01,  2.1473e-02,  ..., -3.8667e-02,\n",
       "           -6.4103e-02,  3.1397e-02]],\n",
       "\n",
       "         [[ 1.5918e+00,  4.0384e-01, -1.9531e+00,  ..., -9.9453e-01,\n",
       "            5.2597e-01, -3.1126e-01],\n",
       "          [-1.8719e-01,  4.3370e-01, -2.0814e+00,  ..., -7.3231e-01,\n",
       "            7.2706e-01,  1.1975e+00],\n",
       "          [ 5.0599e-01, -3.9498e-01, -1.2545e+00,  ..., -1.4691e+00,\n",
       "            2.5419e-01,  3.8658e-01],\n",
       "          ...,\n",
       "          [ 8.8093e-01,  1.4789e+00,  3.1742e-01,  ..., -1.7242e+00,\n",
       "            1.4176e+00,  1.1331e+00],\n",
       "          [ 1.0445e+00,  9.7577e-01,  3.5727e-01,  ...,  1.2389e+00,\n",
       "           -4.4444e-02,  8.0360e-01],\n",
       "          [-3.3746e-01,  4.1885e-01, -2.2656e-02,  ..., -2.1361e-01,\n",
       "           -1.7507e-01, -1.9658e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.0383e-01,  3.1635e-01,  8.7103e-01,  ..., -8.9101e-01,\n",
       "           -6.9409e-01,  7.1229e-01],\n",
       "          [ 4.1284e-01,  1.5425e-01,  9.8546e-01,  ..., -1.2314e+00,\n",
       "           -4.7943e-01,  8.4344e-01],\n",
       "          [ 1.1117e-01, -3.5814e-01,  1.0335e+00,  ..., -1.2831e+00,\n",
       "           -1.4060e-01,  9.3527e-01],\n",
       "          ...,\n",
       "          [ 4.8797e-01,  8.6605e-01, -1.3508e-01,  ..., -5.1961e-01,\n",
       "            1.5127e+00,  4.4993e-01],\n",
       "          [-2.4760e-01,  6.2393e-01, -1.0425e+00,  ...,  9.1584e-01,\n",
       "            2.3616e+00, -5.8837e-01],\n",
       "          [ 2.7155e-02,  3.9575e-02,  1.6964e-01,  ..., -3.6929e-01,\n",
       "            1.4924e-01,  3.1159e-01]],\n",
       "\n",
       "         [[-2.6321e-01,  5.8390e-01, -1.2061e+00,  ..., -8.3171e-01,\n",
       "           -4.8654e-01,  3.4741e-02],\n",
       "          [ 7.5525e-01,  1.4567e-01, -1.2800e+00,  ..., -1.6243e+00,\n",
       "           -3.8751e-01,  2.3760e-01],\n",
       "          [-1.5349e-01,  3.2729e-01, -5.4584e-01,  ..., -5.2302e-01,\n",
       "           -4.9819e-01,  4.8478e-01],\n",
       "          ...,\n",
       "          [ 1.9839e+00, -5.6305e-01, -7.8007e-01,  ..., -8.9707e-01,\n",
       "           -1.4400e-01,  2.3110e+00],\n",
       "          [-7.4656e-01, -5.1068e-01,  2.4758e-01,  ...,  5.4880e-02,\n",
       "           -8.2297e-02,  1.5953e+00],\n",
       "          [ 2.9976e-01,  8.6791e-02, -2.2789e-01,  ...,  3.5646e-03,\n",
       "           -2.6520e-02, -9.1709e-02]],\n",
       "\n",
       "         [[-3.2702e-01, -1.0894e+00, -1.1940e+00,  ..., -2.0174e+00,\n",
       "           -1.5774e-01,  6.6413e-01],\n",
       "          [-1.9967e-02, -8.1052e-01, -1.8796e+00,  ...,  2.9508e-01,\n",
       "            2.0326e+00,  1.6572e+00],\n",
       "          [ 1.1896e+00,  1.0968e-01, -8.9246e-01,  ...,  5.1206e-01,\n",
       "            1.0410e+00, -6.7078e-01],\n",
       "          ...,\n",
       "          [ 1.5341e+00,  1.0114e+00, -1.0672e+00,  ..., -1.0756e+00,\n",
       "            1.1640e+00,  3.6053e-01],\n",
       "          [ 5.5351e-01, -2.2571e+00, -1.0508e-01,  ..., -6.8065e-01,\n",
       "           -7.4429e-01, -8.6056e-01],\n",
       "          [-3.0779e-02, -6.5178e-04,  3.9006e-02,  ..., -1.4751e-01,\n",
       "           -7.9044e-03,  3.6486e-02]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[-1.2586, -0.4379,  0.9608,  ..., -0.2942,  1.9305,  2.0830],\n",
       "          [-1.4562, -0.1571,  1.5882,  ..., -0.2298, -0.1630,  1.5119],\n",
       "          [-1.5060,  0.0457,  0.1040,  ..., -0.3393,  0.8078,  2.1079],\n",
       "          ...,\n",
       "          [-0.1204,  0.9556, -0.8921,  ...,  0.2739,  1.0387, -2.6248],\n",
       "          [-1.2187,  0.7648, -1.1842,  ..., -0.7282,  2.0815, -1.0216],\n",
       "          [-1.4456, -1.4721, -0.4928,  ..., -0.3745,  1.4289, -2.1484]],\n",
       "\n",
       "         [[-0.8520, -2.3425, -0.2935,  ..., -2.6707,  1.4596, -1.3102],\n",
       "          [ 0.3284, -2.1102, -0.5435,  ..., -2.3684,  1.1641, -1.1094],\n",
       "          [-0.3734, -1.8596, -1.2774,  ..., -2.5749,  1.7161, -0.9876],\n",
       "          ...,\n",
       "          [-0.3262, -3.9152, -0.3984,  ..., -3.9589,  2.1395, -2.0366],\n",
       "          [-1.1267, -3.9064, -1.4777,  ..., -2.8441,  2.0762, -1.7196],\n",
       "          [-0.7949, -3.8633,  0.2226,  ..., -3.8201,  2.3766, -2.0946]],\n",
       "\n",
       "         [[-1.2496,  1.7905, -0.3803,  ..., -1.6143, -1.0185,  1.8546],\n",
       "          [-1.4088,  1.2047, -0.5674,  ..., -0.7006, -1.7887,  0.7235],\n",
       "          [-0.6840,  0.7133,  1.0236,  ..., -0.4542, -0.2036,  0.7433],\n",
       "          ...,\n",
       "          [-2.3069,  1.7913, -1.0016,  ...,  0.0199, -1.3052,  0.1753],\n",
       "          [-4.5830,  4.2732, -2.3362,  ...,  0.6979,  1.2942,  0.4440],\n",
       "          [-3.2016,  2.1415, -1.9930,  ...,  0.5594, -0.0386,  0.9711]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.7560,  3.4143,  1.2519,  ...,  1.7712, -0.7485,  0.2199],\n",
       "          [-0.1598,  3.5351, -1.0293,  ...,  1.8736, -0.0068,  1.6826],\n",
       "          [-0.3876,  0.4555, -1.2060,  ..., -0.2105, -0.7576,  0.6300],\n",
       "          ...,\n",
       "          [-2.2547,  5.7044,  2.0880,  ...,  0.6329, -3.9884, -0.6546],\n",
       "          [ 1.0337,  5.5618,  1.6125,  ...,  1.9234, -4.2634, -2.9141],\n",
       "          [ 0.6000,  3.5453,  0.4220,  ...,  0.4808, -3.6741, -0.8997]],\n",
       "\n",
       "         [[-1.9407, -0.4581,  0.4460,  ..., -0.8191,  2.7014, -0.5348],\n",
       "          [-0.8240,  0.0126, -0.7638,  ..., -0.4567,  0.4475, -0.3391],\n",
       "          [-1.5629, -0.0846, -0.9613,  ..., -0.9825, -0.1342, -0.3537],\n",
       "          ...,\n",
       "          [-0.1269,  0.0820,  1.9070,  ..., -1.5727,  0.6167,  1.4084],\n",
       "          [ 1.5055,  1.4487,  0.8207,  ..., -1.3280,  1.8982,  1.4449],\n",
       "          [ 0.7870, -0.5729,  0.0684,  ..., -1.2443,  1.6242,  0.0212]],\n",
       "\n",
       "         [[-0.1101,  1.1331,  0.3932,  ...,  0.3637,  1.4882, -1.6154],\n",
       "          [-0.3696,  0.5884, -0.0934,  ...,  0.3251,  1.8944, -0.5032],\n",
       "          [-0.0790,  0.5486,  0.1165,  ...,  0.9381,  0.6842, -0.8804],\n",
       "          ...,\n",
       "          [-1.5868, -1.5847,  1.8091,  ...,  1.6738,  0.3141, -0.7592],\n",
       "          [-2.0921, -1.6175,  0.1973,  ..., -0.1276, -0.0112, -0.2498],\n",
       "          [-1.4627, -1.8889,  0.6732,  ..., -0.5623, -0.8987, -0.9074]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 0.0665, -0.4753,  0.7131,  ...,  0.6619,  0.3703, -0.5439],\n",
       "          [ 0.3125,  0.6580,  0.6229,  ..., -0.0687,  0.4195,  0.0615],\n",
       "          [-0.5245, -0.4105, -0.4280,  ..., -0.7671,  0.3567, -0.7332],\n",
       "          ...,\n",
       "          [ 0.3834,  0.2606, -0.8208,  ...,  0.3384,  0.1112, -1.3041],\n",
       "          [-0.7477,  0.1468, -0.9668,  ...,  0.0336, -1.8628,  0.4931],\n",
       "          [ 0.1994, -1.0822, -0.5180,  ..., -0.6145, -0.5248,  0.2750]],\n",
       "\n",
       "         [[-0.6549, -0.2135, -1.0553,  ...,  0.3311,  0.9618,  0.1380],\n",
       "          [-0.7595, -0.1663, -0.6068,  ..., -0.3954,  0.1102,  0.8877],\n",
       "          [-0.3558, -0.5840, -0.7442,  ...,  0.6102,  0.4933, -0.2222],\n",
       "          ...,\n",
       "          [-0.9753, -0.4245, -0.6171,  ...,  0.7546,  0.2007,  0.4449],\n",
       "          [-0.0537, -0.6523,  0.3231,  ..., -1.1101,  1.0407,  0.7385],\n",
       "          [-0.6285, -0.3793, -0.3455,  ..., -0.2465, -0.1064,  0.1331]],\n",
       "\n",
       "         [[ 2.3211,  1.6348,  0.8694,  ...,  0.2806, -0.2516,  0.8959],\n",
       "          [ 2.1659,  1.3848, -0.0095,  ...,  0.4331, -0.5318,  0.6623],\n",
       "          [-0.3668,  1.4852,  0.1304,  ...,  0.1068, -0.1360, -0.0866],\n",
       "          ...,\n",
       "          [ 1.8964,  0.5521,  0.1002,  ..., -0.2076,  0.0558,  1.1931],\n",
       "          [ 2.7227, -0.3419,  0.1876,  ...,  0.7960,  0.3951,  1.6839],\n",
       "          [ 1.4752,  0.2613, -0.3916,  ..., -0.0194,  0.0161,  1.3618]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1252, -1.0254, -0.4171,  ..., -0.3929, -0.1425,  0.2768],\n",
       "          [-0.3879, -0.6810,  0.3199,  ..., -0.2671, -0.3817,  0.4382],\n",
       "          [-1.2468,  1.4786, -0.8590,  ...,  0.9520,  0.0307, -1.4812],\n",
       "          ...,\n",
       "          [ 1.1763,  0.7107,  1.1036,  ..., -0.4214, -0.5160, -0.7453],\n",
       "          [ 0.5702, -0.0967,  1.5940,  ..., -0.9931, -0.1731,  0.5236],\n",
       "          [ 0.0958,  1.4159,  0.4743,  ...,  0.2174,  0.1431, -0.1015]],\n",
       "\n",
       "         [[ 1.6329,  0.2078, -0.1728,  ..., -1.2064, -0.8099,  3.1086],\n",
       "          [ 1.0335, -0.0257, -0.2472,  ..., -0.8767, -0.3278,  0.5925],\n",
       "          [ 0.7722, -0.7711, -0.1796,  ..., -1.1255,  0.0338, -0.0065],\n",
       "          ...,\n",
       "          [ 1.5274, -0.1926,  0.1642,  ..., -0.3337, -0.6913,  1.4185],\n",
       "          [ 1.4977,  0.1090,  0.6346,  ..., -0.8607, -1.5579,  1.7219],\n",
       "          [ 0.6314, -0.5733, -0.1589,  ..., -0.2172, -0.9344,  0.5133]],\n",
       "\n",
       "         [[-0.4493,  0.3518, -1.1523,  ..., -0.5322,  0.6290,  0.0703],\n",
       "          [-0.3788, -0.2173,  0.7008,  ..., -0.3696, -0.1698, -0.0628],\n",
       "          [ 0.2138,  0.5252,  0.0612,  ..., -0.6191,  0.7768,  1.1466],\n",
       "          ...,\n",
       "          [-1.4580, -0.3967, -0.3037,  ...,  1.1648,  0.6572, -2.8220],\n",
       "          [-0.8510,  1.3589,  0.7700,  ...,  0.3477, -0.0741, -1.1714],\n",
       "          [-1.1271,  1.2689,  0.1230,  ..., -0.3822,  0.0776, -0.1455]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 1.0143,  1.5877,  2.0884,  ...,  0.4358, -1.8735, -0.8447],\n",
       "          [ 1.2807,  1.9138,  2.7678,  ...,  1.1439, -1.7072, -1.7697],\n",
       "          [ 0.5191,  2.1406,  2.6900,  ...,  1.6789, -1.2645,  0.2579],\n",
       "          ...,\n",
       "          [-0.8995,  2.0200,  1.3021,  ...,  1.6743, -1.4622,  0.7572],\n",
       "          [ 0.5398,  1.1610, -0.6344,  ...,  0.9423,  0.6405, -0.0141],\n",
       "          [-0.0605, -0.2551,  0.0985,  ..., -1.2465, -0.3322, -0.1810]],\n",
       "\n",
       "         [[-0.1645, -0.3383,  1.3391,  ...,  0.2489, -1.3486,  0.6397],\n",
       "          [ 0.1710,  0.3537,  2.0768,  ...,  0.5651, -1.3243,  1.6244],\n",
       "          [-0.1145, -0.8437,  0.9687,  ..., -0.1386, -2.5652,  0.6006],\n",
       "          ...,\n",
       "          [ 1.2151,  0.1949,  0.9416,  ...,  1.6686,  0.6541, -0.7699],\n",
       "          [ 0.4454,  0.1760,  0.8435,  ...,  2.6612,  0.5866,  0.1287],\n",
       "          [-0.0154, -0.1854,  0.1582,  ..., -0.3862, -0.3741, -0.2257]],\n",
       "\n",
       "         [[-0.4416, -0.1545, -0.5623,  ..., -0.0775, -0.2058, -2.1215],\n",
       "          [ 1.4236,  1.1949,  1.4057,  ...,  1.0836,  1.8336, -3.2146],\n",
       "          [-0.1822,  0.2260,  0.8237,  ..., -0.1844,  0.9337, -0.2093],\n",
       "          ...,\n",
       "          [ 0.5705, -0.1042,  0.3961,  ...,  0.6951,  2.5243, -0.9359],\n",
       "          [-0.3788,  1.5823,  0.2369,  ...,  0.2219,  1.3142, -1.5589],\n",
       "          [-0.8118, -0.0315, -0.6442,  ...,  0.1741, -0.7032,  0.7264]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.6479,  0.9382,  1.0760,  ..., -0.6033, -2.4514,  0.6151],\n",
       "          [-0.5175,  1.0048,  0.9057,  ..., -1.9931, -1.8714,  2.3000],\n",
       "          [ 0.2014,  1.3793,  0.4947,  ..., -0.7831, -0.5423,  1.5212],\n",
       "          ...,\n",
       "          [ 1.6476,  1.9566,  0.7924,  ...,  0.5219, -0.4348,  1.6228],\n",
       "          [ 2.6871,  0.3904,  1.4780,  ...,  0.8174, -0.0572, -0.4979],\n",
       "          [-0.4131, -1.0508, -1.2144,  ...,  0.0324,  0.5082,  0.0829]],\n",
       "\n",
       "         [[ 0.7279, -1.8829,  2.8528,  ...,  0.5009,  0.1881,  0.0643],\n",
       "          [ 1.7933,  0.1814,  1.8718,  ...,  0.6540,  0.0433,  0.1003],\n",
       "          [ 1.1285, -1.8319,  2.1038,  ...,  0.5929, -0.4100,  0.9206],\n",
       "          ...,\n",
       "          [ 1.9973, -1.9574,  0.9272,  ...,  1.1023, -0.1581,  0.5689],\n",
       "          [ 1.5562,  0.2923, -0.9739,  ...,  0.4162,  1.3150,  2.2056],\n",
       "          [-0.1052,  0.3506,  0.3615,  ...,  0.1079,  0.1271,  0.2745]],\n",
       "\n",
       "         [[-0.8109,  1.0545, -0.8318,  ..., -2.6725, -0.3456, -1.1941],\n",
       "          [-0.4990,  0.9049, -1.1433,  ..., -3.4049,  0.3483, -1.0002],\n",
       "          [ 0.3337,  0.7794, -0.1860,  ..., -2.4359,  0.0285, -1.3208],\n",
       "          ...,\n",
       "          [-0.0205, -0.9322,  0.3408,  ..., -2.0784,  0.3667, -3.4447],\n",
       "          [ 0.3450, -0.9062, -1.0100,  ..., -2.4223,  0.6928, -2.2654],\n",
       "          [ 0.0185,  0.1703,  0.2484,  ...,  2.0336, -0.4802,  1.5062]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-1.4713e+00,  1.6480e+00,  8.9963e-01,  ..., -1.1486e-01,\n",
       "           -4.9264e-01,  1.6596e-01],\n",
       "          [-1.6066e+00,  1.2089e+00,  7.8340e-01,  ..., -2.8005e-01,\n",
       "           -1.4139e+00,  4.4954e-01],\n",
       "          [-1.1128e+00,  2.0417e+00,  2.3361e-01,  ...,  2.4098e-01,\n",
       "           -5.4542e-01, -2.0789e-01],\n",
       "          ...,\n",
       "          [-1.9123e-02,  2.6535e-01,  1.0161e+00,  ..., -9.7082e-02,\n",
       "            3.2625e-01,  2.8650e-01],\n",
       "          [-4.6560e-01, -1.1038e-01, -5.7245e-01,  ..., -1.4250e+00,\n",
       "            5.2461e-01, -3.5384e-01],\n",
       "          [ 5.0509e-03, -1.3222e-01, -7.5627e-02,  ..., -2.7502e-02,\n",
       "            3.5028e-02,  1.6123e-01]],\n",
       "\n",
       "         [[-1.3142e+00,  6.1929e-01, -2.3617e-01,  ...,  3.4956e-01,\n",
       "            1.8361e+00, -3.7004e-02],\n",
       "          [-4.6280e-01, -1.0389e-01, -1.1185e+00,  ..., -2.7747e-02,\n",
       "            8.7609e-01, -6.5487e-01],\n",
       "          [ 5.5838e-01,  9.0273e-01, -1.7270e+00,  ..., -8.4047e-02,\n",
       "            1.7278e+00, -7.2860e-01],\n",
       "          ...,\n",
       "          [ 6.8793e-01,  1.6842e+00, -7.0850e-01,  ...,  3.3160e-01,\n",
       "            1.9027e-01,  7.6325e-01],\n",
       "          [ 6.3916e-01,  1.1047e-02,  2.9862e-01,  ...,  1.5156e+00,\n",
       "            1.2221e+00,  1.3137e+00],\n",
       "          [-1.1862e-02,  4.2689e-01,  6.5029e-02,  ...,  2.0287e-02,\n",
       "            9.9262e-02, -1.4557e-01]],\n",
       "\n",
       "         [[ 3.4876e-01, -9.1611e-01, -2.2582e-01,  ...,  8.3163e-01,\n",
       "           -4.0882e-01,  4.8090e-01],\n",
       "          [-4.6191e-01,  6.0768e-01,  6.5440e-01,  ..., -9.1301e-01,\n",
       "            1.5210e+00,  1.0127e+00],\n",
       "          [-3.6873e-01, -4.7661e-01, -1.9801e-01,  ...,  7.6135e-01,\n",
       "           -3.7470e-01,  1.1047e-01],\n",
       "          ...,\n",
       "          [-1.1698e+00,  7.9698e-01,  2.5976e-01,  ..., -1.6300e-01,\n",
       "            7.0776e-01, -2.5113e-01],\n",
       "          [-4.6749e-01,  3.0710e-01, -2.1497e-01,  ...,  5.6062e-01,\n",
       "           -4.6945e-01, -1.0308e+00],\n",
       "          [-2.2567e-02,  7.4211e-02,  1.5427e-02,  ...,  2.3825e-02,\n",
       "            3.3782e-02, -9.1476e-03]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.8577e-01,  9.0264e-01,  2.5765e-01,  ...,  9.3925e-01,\n",
       "           -1.1249e+00, -3.0027e-01],\n",
       "          [-3.9696e-02,  3.3324e-01,  2.1341e-01,  ...,  3.1038e-01,\n",
       "           -5.6047e-01, -3.0902e-01],\n",
       "          [ 9.4176e-01,  2.9427e-01, -5.2190e-01,  ...,  1.1308e+00,\n",
       "           -1.1755e+00, -3.5669e-01],\n",
       "          ...,\n",
       "          [ 1.2312e+00, -1.2245e+00,  6.3046e-01,  ...,  6.6343e-02,\n",
       "            1.8719e-01,  1.1537e-02],\n",
       "          [-6.5710e-01, -3.3947e-01, -8.3279e-01,  ..., -3.4675e-01,\n",
       "           -4.4404e-01, -4.2702e-01],\n",
       "          [ 9.3185e-03,  2.1393e-02,  1.6326e-02,  ...,  3.4033e-02,\n",
       "            4.1553e-02, -1.4950e-02]],\n",
       "\n",
       "         [[-1.4987e+00, -9.5835e-01, -9.1330e-01,  ..., -6.5188e-01,\n",
       "           -1.6102e+00,  1.0054e-03],\n",
       "          [-3.4254e-01, -1.1213e+00, -8.1350e-01,  ..., -5.9676e-01,\n",
       "            8.4294e-03,  4.3846e-01],\n",
       "          [-1.7375e+00, -1.4708e+00, -5.0992e-01,  ..., -2.1001e-01,\n",
       "           -1.0964e+00, -3.0738e-01],\n",
       "          ...,\n",
       "          [-1.1378e+00,  8.1837e-01, -1.8692e+00,  ..., -1.5341e+00,\n",
       "           -1.0001e+00, -1.1116e+00],\n",
       "          [-5.0292e-01,  4.5305e-01, -1.0173e+00,  ..., -1.4312e+00,\n",
       "           -1.4456e+00, -2.3296e-01],\n",
       "          [ 3.2563e-02,  6.8458e-02, -1.6137e-02,  ...,  9.1113e-02,\n",
       "           -2.9376e-01,  3.0205e-01]],\n",
       "\n",
       "         [[-1.1567e+00, -5.2961e-01,  5.5742e-01,  ..., -1.4799e+00,\n",
       "            8.2152e-01,  7.6905e-01],\n",
       "          [-1.0549e+00, -5.2398e-01, -1.3381e+00,  ..., -1.1662e+00,\n",
       "           -1.1293e+00,  1.1558e+00],\n",
       "          [-4.3798e-01,  2.5129e-01, -4.7801e-01,  ..., -1.4244e+00,\n",
       "           -3.0337e-01,  1.4304e+00],\n",
       "          ...,\n",
       "          [-1.1149e+00, -1.3895e+00,  7.8761e-01,  ..., -3.0780e-01,\n",
       "           -5.7109e-01, -4.3560e-01],\n",
       "          [ 3.3477e-01, -9.4599e-02,  5.6899e-01,  ..., -1.9386e+00,\n",
       "           -2.7772e-01,  2.6313e-01],\n",
       "          [-2.0425e-01,  1.9806e-01, -1.9872e-01,  ..., -2.1587e-01,\n",
       "            9.0601e-02, -7.0352e-02]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[-2.5944,  1.7676, -5.4690,  ...,  1.0548, -1.4715,  5.1644],\n",
       "          [-2.3917,  2.2816, -6.4992,  ...,  1.5040, -1.3483,  2.5939],\n",
       "          [-0.1698,  1.0554, -3.2127,  ...,  0.0838, -0.8691,  5.4723],\n",
       "          ...,\n",
       "          [-2.5738,  0.9278, -1.6472,  ..., -1.5273, -0.8255,  1.2534],\n",
       "          [-2.0209, -2.4838, -2.4658,  ..., -1.3959, -0.9571, -5.2143],\n",
       "          [-5.0946, -1.4630, -3.1840,  ..., -0.7257, -0.4498, -4.7934]],\n",
       "\n",
       "         [[-1.8800, -3.4813, -0.1109,  ..., -0.1386,  0.7858,  0.0630],\n",
       "          [-3.7052, -3.0625, -2.2338,  ...,  0.9654, -3.1053, -0.1303],\n",
       "          [-0.7292, -3.0368, -0.7767,  ..., -0.1865, -2.0935,  0.8840],\n",
       "          ...,\n",
       "          [-1.9346, -2.9912, -2.7336,  ..., -2.2555, -3.1976,  0.9580],\n",
       "          [-9.7392, -2.6587, -0.8421,  ...,  4.6623,  1.3245, -1.2936],\n",
       "          [-9.6077, -6.7696, -2.0973,  ...,  5.2946,  1.0128,  0.4738]],\n",
       "\n",
       "         [[-0.7698, -0.1045, -2.7874,  ..., -0.5271, -0.4038, -2.2351],\n",
       "          [ 0.7425,  1.0665, -2.9945,  ..., -1.4374, -1.3302, -1.6311],\n",
       "          [ 1.2616,  0.3757, -1.3331,  ..., -1.1786, -0.4453, -0.1229],\n",
       "          ...,\n",
       "          [ 0.2126,  1.9673, -0.7554,  ...,  0.2723, -0.6523, -1.1615],\n",
       "          [-0.1132,  3.7889, -0.2871,  ..., -0.1799, -1.8733, -0.8052],\n",
       "          [ 0.9753,  3.0784, -1.3758,  ..., -0.8141, -2.7796, -1.3294]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.8038,  9.5506, 15.1185,  ..., -1.4456,  5.0600, -3.1575],\n",
       "          [-3.2829,  9.2886, 16.4480,  ..., -0.8337,  4.1223, -4.0910],\n",
       "          [-3.5085,  3.9135, 11.7255,  ...,  0.3520,  3.1918, -1.3642],\n",
       "          ...,\n",
       "          [-3.5031,  8.7769, 14.0031,  ..., -0.7699,  4.1548, -1.5824],\n",
       "          [-3.6470,  9.6947, 13.5078,  ..., -1.3028,  1.8161, -2.3335],\n",
       "          [-5.0941, 13.0818, 18.6639,  ..., -0.9255,  3.8953, -4.6630]],\n",
       "\n",
       "         [[ 0.0852,  3.2971, -3.1551,  ..., -3.1846,  0.7415, -2.6984],\n",
       "          [ 0.3582,  2.9570, -1.2505,  ..., -2.3539,  1.3272, -1.9080],\n",
       "          [-0.9320,  1.5573, -3.0159,  ..., -0.1487,  0.9936, -2.2991],\n",
       "          ...,\n",
       "          [ 2.1124,  3.2875,  0.2984,  ..., -2.4703,  2.7160, -2.5737],\n",
       "          [ 0.0491,  3.3976, -0.3995,  ..., -6.8841,  0.0854, -3.4826],\n",
       "          [-1.4562,  4.0050, -1.2387,  ..., -7.4546,  0.0336, -4.2864]],\n",
       "\n",
       "         [[ 0.6362,  1.7045, -3.7169,  ..., -0.1424,  2.0350, 10.8227],\n",
       "          [-0.4204,  2.0176, -4.9403,  ...,  2.6392, -0.7961, 11.6873],\n",
       "          [ 0.9893,  0.4529, -1.2724,  ..., -0.2472, -0.4690,  7.8283],\n",
       "          ...,\n",
       "          [ 1.2734,  0.2398, -2.6452,  ...,  1.5921, -0.3711, 10.0235],\n",
       "          [ 2.5643,  2.7337, -3.7405,  ...,  3.6935, -1.3679, 11.9861],\n",
       "          [ 2.9375,  1.9644, -5.7107,  ...,  3.7671, -0.5003, 12.5485]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ -3.8144,  -1.8471,   2.1673,  ...,  -2.1065,   3.2069,  -3.2897],\n",
       "          [ -1.5346,   0.8999,   2.7467,  ...,  -1.4755,   3.6414,  -3.1697],\n",
       "          [ -1.3614,  -2.4214,   3.5658,  ...,  -1.8620,   1.0854,  -2.1711],\n",
       "          ...,\n",
       "          [  0.6145,  -2.4584,   4.2164,  ...,  -3.8615,   3.8605,  -4.7142],\n",
       "          [  4.3370,   0.8724,   6.4361,  ...,  -7.1611,   6.1666,  -9.2103],\n",
       "          [  5.2511,   0.3958,   7.0146,  ...,  -7.2812,   6.0295, -11.3775]],\n",
       "\n",
       "         [[  1.4559,  -1.5947,   0.0499,  ...,  -2.1872,   1.2792,  -0.6348],\n",
       "          [ -0.0458,  -4.6369,   1.4067,  ...,  -3.4472,   0.6823,  -0.7946],\n",
       "          [  1.4923,  -2.1774,   1.0709,  ...,  -1.8371,   0.7225,   0.2734],\n",
       "          ...,\n",
       "          [  1.2270,  -3.6418,  -0.0736,  ...,  -0.3776,   1.1129,  -0.5098],\n",
       "          [  1.2626,  -2.0352,  -0.2475,  ...,   0.9942,  -1.3390,  -1.2178],\n",
       "          [  1.6388,  -4.1514,   0.5547,  ...,  -1.0740,   0.0864,  -0.7447]],\n",
       "\n",
       "         [[ -1.1954,  -2.0183,   0.3747,  ...,  -0.2532,  -2.5924,   0.3524],\n",
       "          [ -0.1664,  -1.5041,   0.1914,  ...,  -2.0300,  -5.3112,   3.1593],\n",
       "          [ -0.4603,   0.2814,   0.6294,  ...,   2.5309,  -3.5840,   0.1519],\n",
       "          ...,\n",
       "          [ -1.7346,  -3.2724,  -0.6396,  ...,  -2.2484,  -5.6129,   1.2578],\n",
       "          [ -6.2110,  -2.9430,   0.4461,  ...,  -7.5440,  -8.1753,   1.5657],\n",
       "          [ -5.3723,   0.6000,   0.1846,  ...,  -8.0784, -10.6691,   2.9633]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  1.4013,  -1.1189,  -0.2719,  ...,  -0.1402,  -0.5210,  -0.2042],\n",
       "          [  2.8560,  -2.3001,  -0.9814,  ...,   4.5904,   0.6404,  -0.4698],\n",
       "          [  0.0119,  -1.3592,   0.1060,  ...,   0.1929,  -0.4856,  -0.1365],\n",
       "          ...,\n",
       "          [  2.2558,  -3.0095,  -0.6114,  ...,   0.3219,  -1.7965,   1.9365],\n",
       "          [  6.6074,   1.4073,   1.4409,  ...,   2.8113,  -2.5922,   0.4296],\n",
       "          [  6.3190,  -0.6311,   2.8488,  ...,   4.7384,  -2.6948,   0.5595]],\n",
       "\n",
       "         [[ -1.1899,   0.2016,  -0.4571,  ...,  -2.5364,  -0.1005,  -0.8130],\n",
       "          [  0.8550,  -0.1733,  -2.5378,  ...,  -2.1568,   0.6433,  -1.6742],\n",
       "          [  1.4011,   0.0782,   0.1492,  ...,  -0.6074,  -0.4871,   1.3775],\n",
       "          ...,\n",
       "          [  0.0216,   0.4328,  -1.3545,  ...,  -0.3463,   3.0292,   0.3963],\n",
       "          [  1.4813,  -0.0472,  -1.8546,  ...,  -0.4156,   3.3389,  -0.6569],\n",
       "          [  3.4545,  -0.9545,  -3.1338,  ...,  -1.9815,   0.8238,  -0.5292]],\n",
       "\n",
       "         [[ -2.1167,  -0.4886,  -0.5128,  ...,  -2.2541,  -0.9421,  -0.0428],\n",
       "          [  0.6090,   0.5165,  -1.3396,  ...,  -1.8129,  -0.8921,   1.8303],\n",
       "          [ -2.9816,  -2.1474,  -2.4470,  ...,  -0.8759,  -0.5512,   0.1385],\n",
       "          ...,\n",
       "          [ -2.8516,   0.2397,   1.2455,  ...,   1.5230,  -0.3233,  -1.2497],\n",
       "          [ -2.3170,  -0.5179,   1.1871,  ...,  -2.7603,  -2.9067,  -0.7284],\n",
       "          [ -3.9189,  -0.7792,   1.2099,  ...,  -1.0669,  -3.1691,   2.4620]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-1.6725e+00, -2.7838e+00, -4.1198e+00,  ..., -5.9475e-01,\n",
       "           -2.2929e+00, -2.7170e+00],\n",
       "          [-3.7840e+00, -2.9783e+00, -3.0399e+00,  ..., -1.8412e+00,\n",
       "           -5.3074e+00, -3.6280e+00],\n",
       "          [-3.5310e+00, -2.3862e+00, -2.9130e+00,  ..., -4.3204e-01,\n",
       "           -2.7399e+00, -4.4537e+00],\n",
       "          ...,\n",
       "          [-1.5717e+00, -1.7014e+00, -9.7270e-01,  ..., -9.2682e-01,\n",
       "           -7.6274e-01,  8.4156e-01],\n",
       "          [ 2.2683e-01,  4.3849e-01, -6.5304e-01,  ..., -3.0834e+00,\n",
       "            4.7838e-01,  1.7489e-01],\n",
       "          [-5.2555e-01,  5.7482e-02,  1.2582e-01,  ..., -4.9720e-01,\n",
       "            1.9679e-01,  3.8624e-01]],\n",
       "\n",
       "         [[-3.0506e+00,  5.4850e+00,  2.7413e+00,  ...,  3.6763e+00,\n",
       "           -1.9583e+00,  2.3074e+00],\n",
       "          [-3.3206e+00,  5.5313e+00,  5.2848e+00,  ...,  2.8181e+00,\n",
       "            1.1474e+00,  2.9358e+00],\n",
       "          [-2.3042e+00,  3.3319e+00,  3.5913e+00,  ...,  3.4532e+00,\n",
       "           -1.7320e+00,  1.6736e+00],\n",
       "          ...,\n",
       "          [ 1.2804e+00, -1.0291e+00,  1.7292e+00,  ..., -9.4755e-01,\n",
       "            2.2430e+00, -2.3564e+00],\n",
       "          [ 3.7021e+00, -5.5771e-01,  3.0091e+00,  ..., -1.6172e+00,\n",
       "            7.7261e+00,  2.1749e+00],\n",
       "          [-2.8845e-01, -4.4003e-01, -5.4878e-01,  ...,  4.8378e-01,\n",
       "           -2.2940e+00,  5.5513e-01]],\n",
       "\n",
       "         [[-1.2450e+00,  2.8843e-01,  6.0322e-01,  ...,  2.4009e+00,\n",
       "           -1.9559e+00, -1.2926e+00],\n",
       "          [-5.1565e-01, -4.1696e-02, -1.7367e+00,  ...,  1.0215e+00,\n",
       "           -1.3136e+00,  6.4116e-01],\n",
       "          [-1.1696e+00, -2.8793e-01, -3.8612e-01,  ...,  1.4940e+00,\n",
       "           -2.0095e+00, -3.3010e-01],\n",
       "          ...,\n",
       "          [-1.8556e+00, -2.3694e+00,  3.2082e+00,  ...,  3.6811e+00,\n",
       "            7.8558e-01, -2.5566e+00],\n",
       "          [-2.5871e+00, -2.6712e+00,  2.9577e+00,  ...,  1.6220e+00,\n",
       "            2.1120e+00, -2.5193e+00],\n",
       "          [ 1.4308e+00, -6.7140e-02,  5.4247e-01,  ..., -8.0600e-01,\n",
       "           -1.0695e+00,  7.0929e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 7.6227e-01,  6.1769e+00,  1.2519e+00,  ...,  2.9782e+00,\n",
       "            5.5520e+00, -5.2098e+00],\n",
       "          [ 1.8023e+00,  5.6594e+00,  7.7639e-01,  ..., -4.5829e-01,\n",
       "            6.2109e+00, -2.5939e+00],\n",
       "          [ 1.4064e-01,  6.2388e+00,  1.9277e+00,  ...,  2.7659e+00,\n",
       "            7.0303e+00, -3.9935e+00],\n",
       "          ...,\n",
       "          [ 3.7912e+00,  5.2679e+00, -2.8975e+00,  ..., -7.2213e-01,\n",
       "            4.0091e+00, -2.5143e-01],\n",
       "          [ 2.7076e-01,  5.7575e+00, -2.9700e+00,  ..., -9.2837e-01,\n",
       "            1.0109e+00,  1.1519e+00],\n",
       "          [ 9.7558e-01,  5.8884e-01, -3.8206e-02,  ...,  6.5405e-01,\n",
       "           -1.0976e-03,  2.8606e-01]],\n",
       "\n",
       "         [[ 5.9344e-02,  6.2654e-02,  4.6382e+00,  ..., -2.4676e+00,\n",
       "           -3.8538e+00,  3.2327e+00],\n",
       "          [ 1.2588e-01, -1.6016e+00,  4.3128e+00,  ...,  6.8268e-01,\n",
       "           -8.9155e-01,  3.1216e+00],\n",
       "          [ 1.5163e+00, -4.1980e-01,  4.8783e+00,  ..., -1.3108e+00,\n",
       "           -7.3976e-01,  1.3492e+00],\n",
       "          ...,\n",
       "          [-9.3867e-01, -6.8080e-01, -1.8855e+00,  ..., -1.3732e+00,\n",
       "           -1.0522e+00,  3.1526e+00],\n",
       "          [ 3.9562e-01,  2.2321e+00, -2.3235e+00,  ..., -3.1695e+00,\n",
       "            3.0662e+00,  4.4089e+00],\n",
       "          [-2.8261e-01,  1.0119e+00, -9.3199e-01,  ...,  5.7249e-01,\n",
       "           -3.0112e-01, -3.7040e-01]],\n",
       "\n",
       "         [[ 3.7613e+00, -8.4102e-02,  1.7091e+00,  ...,  7.1812e+00,\n",
       "           -4.5734e-01, -9.1461e-01],\n",
       "          [ 5.2934e+00,  9.7881e-01,  1.4807e+00,  ...,  7.3529e+00,\n",
       "           -9.3667e-01, -2.5565e+00],\n",
       "          [ 3.0568e+00,  1.7090e+00,  1.5008e+00,  ...,  5.9258e+00,\n",
       "            4.0086e-02,  3.6281e-01],\n",
       "          ...,\n",
       "          [ 4.4917e+00,  5.4371e-01, -4.3057e-01,  ...,  8.4300e+00,\n",
       "           -2.5718e+00,  7.5174e-01],\n",
       "          [ 3.8087e+00,  1.6449e+00,  4.2268e-01,  ...,  6.6748e+00,\n",
       "           -4.6203e+00,  9.0678e-01],\n",
       "          [-1.4766e+00, -7.5224e-01, -3.8423e-01,  ..., -4.5780e+00,\n",
       "           -3.4060e-01, -3.7174e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-8.3879e-01,  2.0661e-01,  3.1127e-01,  ...,  1.5745e-02,\n",
       "           -2.5979e-01,  7.2727e-01],\n",
       "          [-8.7880e-01,  6.6099e-01,  5.1547e-01,  ..., -3.5283e-01,\n",
       "           -3.3575e-01, -1.6822e+00],\n",
       "          [-5.5353e-01, -1.5514e+00, -4.8413e-01,  ..., -2.0106e-01,\n",
       "            1.7654e+00,  1.1109e+00],\n",
       "          ...,\n",
       "          [ 1.4584e-01, -7.0724e-02, -5.9924e-01,  ...,  9.6861e-01,\n",
       "           -1.4058e-01, -9.0469e-01],\n",
       "          [-1.3670e-01, -3.1901e-01,  1.2086e-01,  ...,  6.9134e-02,\n",
       "            3.4124e-02,  8.8893e-01],\n",
       "          [ 4.4578e-03,  5.6326e-02, -9.1800e-04,  ..., -1.2989e-01,\n",
       "            3.0479e-02, -2.3178e-01]],\n",
       "\n",
       "         [[-5.7086e-01,  6.7658e-01,  1.4038e+00,  ..., -1.3382e+00,\n",
       "           -1.3759e+00, -6.9943e-01],\n",
       "          [ 5.6494e-01,  9.5650e-01,  3.9301e-01,  ..., -1.4668e+00,\n",
       "           -1.4033e+00,  3.6627e-01],\n",
       "          [-1.2929e+00,  3.1148e-01, -4.4841e-01,  ..., -2.4723e-01,\n",
       "           -1.7625e+00,  1.1299e+00],\n",
       "          ...,\n",
       "          [-1.8455e+00, -1.4161e+00,  4.6250e-01,  ..., -8.4745e-01,\n",
       "           -1.1519e+00, -1.9225e+00],\n",
       "          [ 1.3556e+00,  9.2395e-02,  9.7592e-01,  ...,  8.9707e-01,\n",
       "           -2.1202e+00, -9.6530e-01],\n",
       "          [-8.5558e-02,  6.4596e-02, -4.2480e-02,  ...,  2.5547e-03,\n",
       "           -2.3730e-01,  2.5256e-01]],\n",
       "\n",
       "         [[-1.3021e+00,  3.0678e-02,  2.9897e-01,  ...,  1.3719e+00,\n",
       "            1.4558e-01, -1.5907e-01],\n",
       "          [ 8.2901e-01,  4.1103e-01,  1.8860e+00,  ...,  8.5251e-01,\n",
       "           -2.5910e+00,  2.2813e+00],\n",
       "          [-1.1017e+00,  6.1492e-01,  4.9300e-01,  ...,  1.3788e+00,\n",
       "            3.7268e-01,  1.7957e+00],\n",
       "          ...,\n",
       "          [-1.1945e-01, -2.6255e+00,  1.1634e+00,  ..., -5.3250e-01,\n",
       "            1.9196e+00,  1.0984e+00],\n",
       "          [-2.5419e+00,  1.0778e-01,  5.3529e-01,  ..., -5.7962e-01,\n",
       "            1.3853e-01,  9.4013e-01],\n",
       "          [-1.5969e-02,  1.0521e-02, -3.7843e-03,  ...,  3.7709e-02,\n",
       "            1.2174e-02,  2.3939e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.2119e-01, -6.3859e-01, -4.1079e-01,  ..., -6.4003e-01,\n",
       "           -9.2058e-01,  9.4217e-01],\n",
       "          [ 9.0058e-01,  1.0926e+00, -2.2100e+00,  ..., -1.4988e+00,\n",
       "           -1.8361e+00, -5.3934e-01],\n",
       "          [ 2.2793e-01,  1.0985e+00, -2.4647e+00,  ..., -2.1570e+00,\n",
       "           -1.0618e+00,  8.5327e-01],\n",
       "          ...,\n",
       "          [-1.9005e-02,  1.5172e+00, -7.8759e-01,  ..., -9.3182e-01,\n",
       "            3.8886e-02,  2.0232e+00],\n",
       "          [ 4.6027e-01,  8.7352e-01,  3.7594e-01,  ..., -2.0171e+00,\n",
       "            3.2442e-01,  1.2498e+00],\n",
       "          [-6.1712e-02, -8.5267e-02, -1.5195e-01,  ..., -1.1400e-02,\n",
       "           -1.9387e-02,  3.1282e-01]],\n",
       "\n",
       "         [[ 1.5156e+00, -1.6467e+00, -1.7535e+00,  ..., -6.6520e-01,\n",
       "            8.5067e-01,  5.4507e-01],\n",
       "          [ 3.8139e-01, -8.0512e-01, -1.5642e+00,  ..., -1.2834e+00,\n",
       "            1.7406e+00, -1.5470e+00],\n",
       "          [ 9.8138e-01, -1.7463e-01, -5.1925e-02,  ..., -1.2907e+00,\n",
       "            1.7570e-01,  3.6508e-01],\n",
       "          ...,\n",
       "          [ 5.5857e-01,  1.5059e+00,  1.0204e+00,  ..., -1.3641e+00,\n",
       "           -1.4660e+00, -3.0788e-01],\n",
       "          [ 4.1704e-01, -7.5779e-01, -1.0007e+00,  ..., -1.1970e+00,\n",
       "           -1.4754e+00,  2.8191e-03],\n",
       "          [ 1.3163e-02,  1.2438e-01,  7.6630e-02,  ...,  2.8274e-02,\n",
       "            4.8043e-02,  9.1624e-02]],\n",
       "\n",
       "         [[ 4.4433e-01, -1.7852e-01,  1.2258e+00,  ..., -4.5258e-01,\n",
       "            6.3527e-01, -8.0058e-01],\n",
       "          [ 7.9645e-01, -1.2112e+00,  1.8036e+00,  ..., -2.7469e-01,\n",
       "           -8.9829e-01, -1.5764e+00],\n",
       "          [-1.0157e-01, -1.4892e+00,  1.9840e+00,  ..., -5.6122e-01,\n",
       "           -6.1296e-01, -1.3542e+00],\n",
       "          ...,\n",
       "          [ 1.4986e+00,  1.1247e-01,  1.9287e+00,  ..., -1.4145e-02,\n",
       "           -5.6423e-02, -1.1463e-01],\n",
       "          [ 9.5294e-01,  5.2056e-01,  8.3649e-01,  ..., -1.6175e+00,\n",
       "            5.4796e-02,  1.6473e+00],\n",
       "          [-2.0113e-02,  1.1003e-01, -1.5005e-01,  ..., -5.2218e-02,\n",
       "            5.0792e-02,  1.1771e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 3.1021,  3.6026, -1.4733,  ..., -3.3487,  0.5580, -1.1556],\n",
       "          [ 3.4506,  3.8996, -2.7034,  ..., -2.7440,  0.5226, -1.3129],\n",
       "          [ 3.7443,  2.6063, -0.9436,  ..., -2.5025,  1.3843, -3.8904],\n",
       "          ...,\n",
       "          [ 5.2200,  4.5569, -2.4151,  ..., -1.0481,  2.8938, -0.4691],\n",
       "          [ 3.6044,  0.5959, -3.4068,  ..., -2.6918,  1.7896, -2.6958],\n",
       "          [ 4.4476,  1.0391, -4.0397,  ..., -3.2108,  2.0614, -3.1843]],\n",
       "\n",
       "         [[-0.7443, -1.0091, -3.1552,  ...,  4.8425,  2.9041, -1.2450],\n",
       "          [-1.1480, -0.6170, -3.5976,  ...,  3.7239,  1.3137, -1.5988],\n",
       "          [ 1.1452, -1.3097, -3.1477,  ...,  3.4202,  1.4296, -0.4965],\n",
       "          ...,\n",
       "          [-0.2313, -2.1393, -4.9084,  ...,  4.9464,  2.1867, -1.7440],\n",
       "          [-0.1916, -0.7656, -6.1932,  ...,  3.1957,  2.8563, -2.5579],\n",
       "          [ 0.5745, -1.4912, -5.6220,  ...,  2.8481,  2.1923, -3.3426]],\n",
       "\n",
       "         [[-1.1228, -5.7392,  2.9053,  ...,  1.0727,  1.1281,  0.7155],\n",
       "          [-0.4660, -4.8345,  3.5710,  ...,  1.2403,  2.1058, -0.4194],\n",
       "          [ 0.1751, -5.3889,  1.2251,  ...,  0.6772,  1.6587, -1.7582],\n",
       "          ...,\n",
       "          [ 0.6516, -5.5285,  3.2084,  ..., -1.5530,  2.6362, -1.3195],\n",
       "          [-0.3940, -5.6298,  2.2428,  ...,  0.7040,  5.2023, -4.3393],\n",
       "          [-0.5834, -5.8659,  3.1299,  ...,  1.2077,  4.5758, -4.2196]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.7556, -2.2198, -1.0891,  ..., -0.6879,  0.6245,  0.7056],\n",
       "          [-3.9190, -2.5122, -2.0607,  ...,  0.1717, -1.3302,  0.0485],\n",
       "          [-1.9986, -2.4518, -0.5494,  ..., -1.1030,  0.8244, -0.1862],\n",
       "          ...,\n",
       "          [-1.2318, -3.1990,  0.7555,  ..., -0.5183,  1.1373, -0.9786],\n",
       "          [-3.6858, -4.3458, -2.4218,  ..., -1.6502,  0.8122, -1.7835],\n",
       "          [-3.5792, -3.3972, -1.4920,  ..., -2.3062,  2.2982, -1.6919]],\n",
       "\n",
       "         [[ 0.2661, -0.9364,  0.6075,  ..., -1.2096, -2.6768, -0.1001],\n",
       "          [-0.2055, -0.8408,  1.5665,  ..., -2.0343, -2.3869,  1.3200],\n",
       "          [ 0.6973,  1.1061,  1.8550,  ..., -0.9473, -0.5016,  2.0926],\n",
       "          ...,\n",
       "          [-0.7502, -1.3619,  0.5533,  ..., -0.5199, -0.7197,  2.4439],\n",
       "          [ 0.4038, -2.1601,  0.5122,  ..., -0.4061,  1.1851,  4.3256],\n",
       "          [ 0.8210, -3.0208,  1.3877,  ...,  0.2332,  2.3859,  4.0922]],\n",
       "\n",
       "         [[-5.2109,  1.9395, -1.4264,  ..., -1.6744,  2.1216,  1.2414],\n",
       "          [-5.1144,  2.4582, -3.3556,  ..., -1.8593,  2.6151,  3.1859],\n",
       "          [-4.9583,  1.7841, -2.5667,  ..., -1.2186,  2.6647,  1.5418],\n",
       "          ...,\n",
       "          [-5.3393,  3.8330, -0.8280,  ...,  1.2973,  2.9243,  4.5881],\n",
       "          [-6.3675,  6.2143, -1.3338,  ...,  0.4359,  2.5199,  3.3587],\n",
       "          [-5.6785,  5.2855, -3.1451,  ...,  1.3815,  1.9764,  2.3226]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 0.7836, -0.6865, -2.3905,  ..., -0.4175, -2.8834, -0.0739],\n",
       "          [ 1.2219, -0.5015, -1.7452,  ..., -1.5239,  0.9361, -1.3972],\n",
       "          [ 0.8153, -1.0214,  0.9551,  ..., -3.0890,  0.7258,  0.1459],\n",
       "          ...,\n",
       "          [ 2.9014,  0.3236,  0.6574,  ..., -2.1936,  0.8676,  0.1510],\n",
       "          [ 2.3019,  1.2052, -0.2566,  ..., -3.5144,  2.9804, -1.7839],\n",
       "          [ 3.9592,  1.3984,  0.7566,  ..., -5.1574,  3.3946, -3.3373]],\n",
       "\n",
       "         [[-0.8808, -2.0723, -1.0149,  ...,  0.9104, -1.0343, -1.8015],\n",
       "          [ 0.1624, -1.8007, -0.4913,  ...,  0.9115, -1.2648, -3.0563],\n",
       "          [-0.5295, -0.6333, -1.8511,  ...,  2.9708, -1.0195, -1.5005],\n",
       "          ...,\n",
       "          [ 0.4322,  0.1128, -0.7501,  ...,  0.6953, -3.5556, -3.0112],\n",
       "          [ 1.1034, -0.1236, -2.4386,  ...,  1.2405, -4.5781, -3.3977],\n",
       "          [ 0.9528, -0.7699, -3.5347,  ...,  3.6074, -4.5605, -4.2184]],\n",
       "\n",
       "         [[ 0.6975, -3.3854,  0.4237,  ..., -1.2393,  3.7042,  0.6662],\n",
       "          [ 0.9052, -1.7760,  1.5681,  ..., -1.2350,  5.0740,  0.1377],\n",
       "          [ 2.6504, -2.8693, -1.2361,  ..., -0.9042,  5.7020,  1.1192],\n",
       "          ...,\n",
       "          [ 1.2241, -3.8627, -0.6940,  ..., -2.2089,  1.6245, -1.5325],\n",
       "          [ 4.6904,  0.8312, -4.7786,  ...,  1.0265,  3.8422, -2.6825],\n",
       "          [ 4.2687, -2.1201, -4.9452,  ..., -2.7395,  2.6935, -3.5046]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.4685,  2.3780,  2.9222,  ...,  0.4533,  0.4877, -0.4782],\n",
       "          [ 1.9699,  4.3322,  2.6355,  ..., -0.1370,  1.1242, -1.3120],\n",
       "          [ 1.0126,  0.5545,  2.8592,  ...,  0.7051,  0.0174, -1.9454],\n",
       "          ...,\n",
       "          [-0.0445,  3.4641,  3.5065,  ..., -2.0589, -1.5097,  0.6001],\n",
       "          [-2.6526,  3.7365,  2.2929,  ..., -0.8729, -1.2011, -1.6449],\n",
       "          [-2.1665,  2.7683,  2.0588,  ..., -1.1325, -2.8943, -2.3350]],\n",
       "\n",
       "         [[-1.5481, -0.1051, -0.3589,  ...,  1.6408, -0.9635,  2.6100],\n",
       "          [-1.4981, -0.1591,  1.1711,  ..., -0.1771,  0.5464,  1.6807],\n",
       "          [-1.3402, -2.8767, -1.5333,  ..., -1.9224,  1.1155,  0.6325],\n",
       "          ...,\n",
       "          [-1.8960, -1.4808, -0.0418,  ..., -0.5248,  0.7988,  0.2897],\n",
       "          [-2.6135, -3.5834, -0.8484,  ..., -1.2365,  2.2472, -0.8788],\n",
       "          [-3.8838, -3.4549, -2.1385,  ...,  0.5764,  0.9480, -0.8732]],\n",
       "\n",
       "         [[-0.5249, -1.8523, -0.5417,  ..., -0.7829, -0.6511,  0.0431],\n",
       "          [-1.4542, -1.2833, -0.5842,  ...,  0.0184,  0.4444, -0.6133],\n",
       "          [ 1.2026, -1.7747, -1.0725,  ..., -2.0066,  0.4410,  1.0143],\n",
       "          ...,\n",
       "          [ 2.5646,  0.6005,  0.3237,  ...,  1.6419,  1.8820,  0.7654],\n",
       "          [-0.7106, -3.2994,  0.5382,  ...,  2.3658,  4.4243, -1.9014],\n",
       "          [-0.8275, -2.2320, -0.0802,  ...,  2.2738,  4.6500, -2.3471]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 3.0819e+00, -1.1718e+00,  4.0433e+00,  ..., -1.2676e+00,\n",
       "            3.9814e+00, -1.8044e+00],\n",
       "          [ 3.4705e+00, -2.2868e+00,  4.3555e+00,  ...,  2.9971e-01,\n",
       "            4.2704e+00, -1.4217e+00],\n",
       "          [ 1.9981e+00, -3.7927e+00,  4.3675e+00,  ...,  3.8789e-01,\n",
       "            3.7577e+00, -4.4996e+00],\n",
       "          ...,\n",
       "          [-1.0149e+00, -2.4776e+00,  1.0294e+00,  ..., -2.5175e+00,\n",
       "            5.4097e+00, -2.0444e-01],\n",
       "          [-6.2748e+00, -2.1471e+00,  3.6664e+00,  ...,  1.0258e+00,\n",
       "            6.1926e+00, -2.6714e+00],\n",
       "          [-1.1330e+00,  6.4299e-02, -2.6551e-01,  ..., -9.8723e-01,\n",
       "           -2.6459e+00,  6.4571e-01]],\n",
       "\n",
       "         [[-8.8270e-01, -2.3681e+00,  2.5492e+00,  ..., -1.1065e+00,\n",
       "           -1.5004e-01, -4.3217e+00],\n",
       "          [-1.0785e+00, -1.4113e+00,  4.6632e+00,  ..., -2.2714e+00,\n",
       "           -3.4340e-02, -5.4551e+00],\n",
       "          [-1.0208e+00, -1.5911e+00,  2.5616e+00,  ..., -2.2209e+00,\n",
       "           -1.1630e+00, -2.6896e+00],\n",
       "          ...,\n",
       "          [-4.6594e+00, -5.7893e-01,  1.5800e+00,  ...,  7.3081e-02,\n",
       "           -3.8415e+00, -4.6808e+00],\n",
       "          [-4.3857e+00,  8.5328e-01,  1.4764e+00,  ..., -1.6714e+00,\n",
       "           -1.0776e+00, -6.4476e-01],\n",
       "          [-9.3451e-01, -4.4924e-01, -2.7478e-01,  ...,  9.3340e-01,\n",
       "           -4.4767e-01,  1.4257e+00]],\n",
       "\n",
       "         [[ 3.6025e-01, -3.8575e+00, -6.9166e-01,  ..., -9.2921e-01,\n",
       "            1.1726e+00,  1.5791e+00],\n",
       "          [-6.0855e-02, -1.0728e+01, -1.2276e+00,  ..., -5.7010e+00,\n",
       "            3.5043e+00,  5.5954e-01],\n",
       "          [-6.7365e+00, -5.8078e+00, -1.3257e+00,  ..., -1.4698e+00,\n",
       "            5.3130e+00, -2.1292e+00],\n",
       "          ...,\n",
       "          [-1.1428e+00, -9.9692e+00, -1.8416e-01,  ..., -1.0158e-02,\n",
       "           -2.1860e+00,  1.9433e-01],\n",
       "          [-2.8239e-01, -6.2669e+00,  1.2487e-01,  ...,  5.1265e+00,\n",
       "            3.0044e+00, -1.7640e+00],\n",
       "          [-9.1161e-01,  4.6659e+00, -2.0197e-01,  ...,  9.1632e-01,\n",
       "           -8.0651e-01, -4.6860e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.2800e-01, -1.6792e+00, -1.9269e+00,  ..., -9.4593e-01,\n",
       "           -4.0939e-02, -2.3934e+00],\n",
       "          [-1.8010e+00, -1.6997e+00, -7.3336e-01,  ..., -5.1113e+00,\n",
       "            9.1717e-01, -1.7382e+00],\n",
       "          [ 7.1374e-01, -3.0239e+00, -2.0781e-01,  ..., -2.0520e+00,\n",
       "           -1.1017e+00,  3.6157e-02],\n",
       "          ...,\n",
       "          [ 1.6318e+00, -6.7398e-01, -1.5442e+00,  ...,  1.4171e-01,\n",
       "            3.2663e+00, -6.9835e+00],\n",
       "          [-1.0734e+00, -3.6487e+00, -4.9161e+00,  ..., -2.9121e+00,\n",
       "            1.2173e+00, -1.8371e+00],\n",
       "          [-3.2068e-01, -7.5410e-01,  3.0413e-01,  ...,  5.7240e-01,\n",
       "           -1.5408e+00,  1.2207e+00]],\n",
       "\n",
       "         [[ 1.8015e-01,  7.9496e+00,  5.7291e-01,  ..., -8.7035e-01,\n",
       "           -3.5547e+00,  2.3725e-01],\n",
       "          [-1.2328e+00,  7.3836e+00,  9.7471e-01,  ...,  1.0726e+00,\n",
       "           -8.0150e-01, -1.9265e+00],\n",
       "          [ 6.0886e-01,  5.9097e+00,  2.7419e-01,  ...,  2.3084e+00,\n",
       "           -3.1564e+00,  5.3663e-01],\n",
       "          ...,\n",
       "          [ 5.5721e+00,  1.0069e+01, -1.6671e+00,  ..., -1.9789e+00,\n",
       "           -3.4298e+00, -2.1209e-01],\n",
       "          [ 1.6462e+00,  9.2844e+00, -1.8504e+00,  ..., -6.5993e-01,\n",
       "           -2.5355e+00, -3.9022e-01],\n",
       "          [-7.5459e-01, -5.7031e+00, -3.1584e-01,  ..., -3.6092e-01,\n",
       "            2.8807e-01, -1.4474e+00]],\n",
       "\n",
       "         [[ 4.2626e+00, -6.5448e-01, -1.8381e+00,  ..., -7.2623e+00,\n",
       "           -1.3824e+00, -1.6423e-01],\n",
       "          [ 4.7030e+00,  1.3447e+00, -3.6035e+00,  ..., -5.0052e+00,\n",
       "            1.6935e+00,  2.8673e-01],\n",
       "          [ 5.0368e+00, -1.4299e+00,  5.6056e-01,  ..., -5.3129e+00,\n",
       "            6.3266e-01,  1.4767e+00],\n",
       "          ...,\n",
       "          [ 5.4490e+00, -1.7474e+00, -2.6478e+00,  ..., -6.5673e+00,\n",
       "            3.5596e+00, -6.5809e+00],\n",
       "          [ 3.6314e+00,  6.0155e-01, -1.4459e+00,  ..., -8.5247e+00,\n",
       "            4.8563e+00, -7.6346e+00],\n",
       "          [-1.0220e+00,  3.5402e-01,  7.2587e-01,  ...,  2.0884e+00,\n",
       "           -1.5882e+00,  4.7681e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[ 1.6623e+00,  1.5233e+00,  1.2990e+00,  ..., -1.0921e+00,\n",
       "            8.3822e-01,  1.8340e+00],\n",
       "          [ 8.0598e-01, -4.3812e-01,  1.0844e+00,  ...,  2.7491e-01,\n",
       "           -1.0268e-01,  7.0456e-01],\n",
       "          [ 2.0066e+00,  1.0537e-01,  1.1764e+00,  ...,  7.6504e-01,\n",
       "           -2.0746e+00,  2.5962e+00],\n",
       "          ...,\n",
       "          [-7.1649e-01, -5.5231e-01,  5.1214e-01,  ...,  1.0318e+00,\n",
       "            1.1245e+00,  1.4458e+00],\n",
       "          [-1.3860e-02, -1.1201e+00,  2.9778e+00,  ...,  3.0251e-01,\n",
       "            1.2113e-01,  1.4870e-01],\n",
       "          [-3.5058e-01, -1.1007e-01,  6.3772e-02,  ...,  5.4569e-02,\n",
       "            2.0429e-01,  1.5821e-01]],\n",
       "\n",
       "         [[ 4.3094e+00,  3.5104e+00,  3.9535e-01,  ..., -1.3393e+00,\n",
       "            8.5812e-01,  5.2266e+00],\n",
       "          [ 1.8200e+00,  3.2588e+00,  8.3067e-01,  ..., -4.6803e-01,\n",
       "           -9.6024e-02,  1.6377e+00],\n",
       "          [ 2.9246e+00,  2.2461e+00,  1.5102e+00,  ..., -5.6077e-01,\n",
       "            5.0341e-03,  1.5944e+00],\n",
       "          ...,\n",
       "          [ 1.4750e+00,  2.0312e+00,  4.0550e+00,  ...,  4.2404e-02,\n",
       "            1.2548e+00,  3.8387e+00],\n",
       "          [ 3.7209e-01,  2.3049e+00,  1.1891e+00,  ..., -6.2993e-01,\n",
       "            1.8722e+00,  2.3333e+00],\n",
       "          [-2.0730e-02, -4.9776e-01,  1.1842e-02,  ...,  1.7231e-01,\n",
       "           -1.2351e-02,  1.9133e-02]],\n",
       "\n",
       "         [[ 1.9252e+00,  1.4026e+00,  2.4378e+00,  ...,  2.3482e+00,\n",
       "           -1.6872e+00, -7.6838e-02],\n",
       "          [ 3.4556e+00,  1.3538e+00,  1.9004e+00,  ...,  1.9565e+00,\n",
       "           -2.8733e+00,  1.1789e+00],\n",
       "          [ 6.7446e-01,  2.6295e+00,  2.5685e+00,  ...,  3.5238e+00,\n",
       "           -2.2453e+00,  9.2312e-01],\n",
       "          ...,\n",
       "          [ 1.5235e-01, -4.7374e-02,  7.9324e-01,  ...,  4.0868e-01,\n",
       "           -9.1000e-01, -7.0940e-01],\n",
       "          [-1.0396e+00,  2.4035e+00,  1.2594e-01,  ..., -2.5126e-01,\n",
       "            1.0753e-01,  3.1427e+00],\n",
       "          [-3.3484e-02,  1.5957e-01,  1.1462e-01,  ...,  6.9492e-02,\n",
       "           -4.1396e-03, -6.5694e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.9846e-01, -5.5029e-01, -2.8281e-01,  ...,  6.7068e-01,\n",
       "            1.4694e+00,  1.2918e+00],\n",
       "          [-2.1948e+00,  2.4321e+00, -1.0596e+00,  ..., -1.1499e+00,\n",
       "           -8.5594e-01,  9.1128e-01],\n",
       "          [ 1.4200e+00, -3.6485e-01, -8.0463e-02,  ..., -1.1756e+00,\n",
       "            1.0053e+00,  7.1687e-01],\n",
       "          ...,\n",
       "          [-1.9461e+00, -3.8616e-01, -7.1175e-01,  ..., -7.2322e-01,\n",
       "           -1.3297e+00, -1.8010e-01],\n",
       "          [-8.4902e-01,  1.9343e-01, -1.4118e-02,  ..., -1.6127e+00,\n",
       "           -4.1042e-01,  2.6579e-01],\n",
       "          [ 5.6812e-01, -1.4978e-01, -1.1085e-02,  ...,  3.2485e-01,\n",
       "            1.7649e-01,  2.5434e-01]],\n",
       "\n",
       "         [[ 1.8264e+00,  2.1683e+00,  9.4334e-01,  ..., -4.7587e-01,\n",
       "           -2.4840e+00, -1.5315e-01],\n",
       "          [ 2.2375e+00,  5.4805e-01, -1.5109e-01,  ..., -1.1892e+00,\n",
       "           -2.7213e+00,  1.3606e+00],\n",
       "          [ 2.8937e+00,  7.2826e-01,  7.2390e-01,  ..., -8.0005e-01,\n",
       "           -2.1069e+00,  8.9542e-01],\n",
       "          ...,\n",
       "          [ 2.5833e-01, -2.7045e+00,  3.6209e-01,  ...,  3.4033e-01,\n",
       "           -5.8673e+00,  1.4504e+00],\n",
       "          [-4.1679e-01, -5.3414e-01,  7.9942e-01,  ...,  1.2757e+00,\n",
       "           -4.4713e-01,  1.8272e+00],\n",
       "          [-5.7310e-02, -1.3428e-01,  3.6008e-01,  ...,  2.0947e-01,\n",
       "            1.5133e-01, -3.1490e-01]],\n",
       "\n",
       "         [[ 9.3673e-01,  2.0660e-01,  2.4658e+00,  ...,  6.5680e-01,\n",
       "            1.2735e+00,  1.6641e+00],\n",
       "          [ 5.6372e-01, -1.2033e+00,  3.1151e+00,  ...,  8.4194e-01,\n",
       "            1.5074e+00,  1.9552e+00],\n",
       "          [ 3.4875e-01, -1.2497e+00,  2.3574e+00,  ...,  1.2834e+00,\n",
       "            8.2617e-01,  6.8284e-01],\n",
       "          ...,\n",
       "          [ 2.4053e+00,  4.1136e-01,  5.3122e-01,  ...,  5.4693e-01,\n",
       "            1.1877e+00,  3.0842e+00],\n",
       "          [ 1.6729e+00,  4.7764e-01,  3.3483e-01,  ..., -5.0368e-01,\n",
       "            8.3955e-01,  2.1631e+00],\n",
       "          [ 3.0023e-01, -1.2079e-01, -2.2591e-01,  ..., -2.9797e-01,\n",
       "            2.2167e-01,  9.1034e-02]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 1.0488e+00, -3.3686e+00, -8.2676e-01,  ..., -7.2806e-01,\n",
       "            1.7012e+00,  1.7529e+00],\n",
       "          [ 1.0022e+00, -3.8369e+00, -2.8098e+00,  ..., -3.5592e-01,\n",
       "            2.2053e+00,  7.0947e-01],\n",
       "          [ 1.1523e+00, -5.2450e+00, -6.7426e-01,  ..., -3.3667e-01,\n",
       "            3.8605e-01,  1.1801e+00],\n",
       "          ...,\n",
       "          [ 3.2769e+00, -4.4800e+00, -1.9727e+00,  ..., -2.7189e-01,\n",
       "            5.2850e-01,  3.7749e+00],\n",
       "          [ 6.6269e+00, -9.4195e+00, -5.7180e+00,  ..., -3.9188e+00,\n",
       "           -5.3147e+00,  2.4089e+00],\n",
       "          [ 8.3554e+00, -1.1298e+01, -6.6170e+00,  ..., -5.9767e+00,\n",
       "           -6.5703e+00,  1.2076e+00]],\n",
       "\n",
       "         [[ 6.4778e-01, -1.1669e+00, -3.3407e-02,  ...,  5.0184e+00,\n",
       "            1.5619e+00,  2.1757e+00],\n",
       "          [ 5.0109e-01, -6.7295e-01, -2.2552e+00,  ...,  3.6423e+00,\n",
       "            1.2485e+00,  1.0687e-01],\n",
       "          [ 2.4230e+00,  4.3616e-01, -2.2737e+00,  ...,  4.2756e+00,\n",
       "            2.7653e+00,  1.9258e+00],\n",
       "          ...,\n",
       "          [-5.7370e-01, -1.2365e-01,  2.6397e-01,  ...,  4.0596e+00,\n",
       "            2.2332e+00, -1.0462e+00],\n",
       "          [ 4.6087e+00, -2.4805e+00, -1.4519e+00,  ...,  7.2712e+00,\n",
       "           -1.2441e+00, -1.2677e+00],\n",
       "          [ 4.3508e+00, -3.5191e+00, -2.1696e+00,  ...,  1.0168e+01,\n",
       "            1.8833e+00, -3.3742e+00]],\n",
       "\n",
       "         [[ 5.2213e+00,  1.1426e+00,  1.2116e-01,  ...,  2.0476e+00,\n",
       "            7.1423e-01,  1.3944e+00],\n",
       "          [ 5.6596e+00,  1.4844e+00,  9.4838e-01,  ...,  2.1050e+00,\n",
       "            6.8267e-02, -1.2270e-02],\n",
       "          [ 5.0608e+00,  8.1588e-01,  3.3976e-02,  ...,  1.4407e+00,\n",
       "            7.3832e-01,  4.1075e-01],\n",
       "          ...,\n",
       "          [ 5.6568e+00,  8.3150e-01,  1.2254e+00,  ...,  1.2826e+00,\n",
       "           -9.6617e-01,  5.1563e-01],\n",
       "          [ 7.3442e+00,  2.8998e+00,  9.4428e-01,  ...,  4.0471e+00,\n",
       "            6.4540e-01,  3.4683e+00],\n",
       "          [ 7.7450e+00,  4.5595e+00,  9.5272e-03,  ...,  6.0900e+00,\n",
       "            1.3898e+00,  3.8808e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.9953e+00, -2.3413e+00,  5.8995e-01,  ..., -8.5354e-01,\n",
       "           -1.7223e-01, -1.5555e+00],\n",
       "          [-5.5732e-01, -2.8501e+00,  2.8265e-01,  ...,  6.1713e-02,\n",
       "           -1.5444e+00,  2.0005e-01],\n",
       "          [-6.7985e-01, -2.6502e+00,  2.5985e-01,  ...,  5.2813e-01,\n",
       "           -1.4128e-01, -8.5369e-01],\n",
       "          ...,\n",
       "          [-1.3946e+00,  6.6930e-02,  1.8276e-01,  ...,  2.6227e-01,\n",
       "           -9.2981e-01, -6.6442e-01],\n",
       "          [-3.2035e+00,  2.8625e+00,  3.3337e+00,  ..., -5.5173e+00,\n",
       "           -4.3985e+00, -6.6139e+00],\n",
       "          [-5.4140e+00,  2.0807e+00,  3.4721e+00,  ..., -7.9595e+00,\n",
       "           -7.7078e+00, -9.9521e+00]],\n",
       "\n",
       "         [[ 1.2194e+00,  1.4992e+00,  9.6606e-01,  ..., -8.3564e-01,\n",
       "           -5.0964e-01,  2.7566e+00],\n",
       "          [ 1.3284e-01,  1.5874e+00,  1.2587e+00,  ..., -2.0336e+00,\n",
       "            8.2003e-01,  2.6592e+00],\n",
       "          [ 1.5451e-01, -9.9986e-01,  1.6181e+00,  ..., -1.9366e+00,\n",
       "           -1.9970e+00,  1.8274e+00],\n",
       "          ...,\n",
       "          [-1.4947e+00, -3.2679e+00,  1.9628e+00,  ...,  1.6875e+00,\n",
       "           -2.2097e+00,  2.6408e+00],\n",
       "          [-3.5239e+00, -9.9762e+00,  3.8542e-01,  ..., -4.5350e+00,\n",
       "           -4.4122e-01, -1.2092e+00],\n",
       "          [-3.9862e+00, -1.3409e+01,  2.1823e+00,  ..., -3.7464e+00,\n",
       "            4.2903e-01, -6.0545e-01]],\n",
       "\n",
       "         [[-3.2766e-01, -3.2271e+00,  2.9652e-01,  ...,  2.1321e+00,\n",
       "           -3.5513e-01,  1.9090e+00],\n",
       "          [-5.0387e-01, -8.5776e-02,  1.8060e-01,  ...,  4.5482e-01,\n",
       "           -4.5101e-01,  7.1784e-01],\n",
       "          [-6.7472e-01, -2.8612e+00, -1.3628e+00,  ...,  1.7419e+00,\n",
       "           -1.8360e+00, -5.5711e-01],\n",
       "          ...,\n",
       "          [-9.0209e-01, -1.7563e-01,  1.3588e+00,  ...,  2.4715e+00,\n",
       "            6.4523e-01, -1.0303e+00],\n",
       "          [-5.8039e+00,  3.4564e+00,  3.1770e+00,  ...,  1.8397e+00,\n",
       "            4.2701e+00, -2.4723e-01],\n",
       "          [-7.8990e+00,  3.8579e+00,  2.7345e+00,  ...,  3.3069e+00,\n",
       "            6.7149e+00, -1.9348e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[-1.3453e+00, -1.4707e+00, -2.8839e-02,  ...,  2.2497e+00,\n",
       "            1.2598e+00, -1.4878e+00],\n",
       "          [-1.0253e+00, -6.6028e-01, -8.5697e-01,  ...,  3.9012e-01,\n",
       "           -6.5991e-01, -9.2023e-01],\n",
       "          [ 1.2319e-01,  1.1270e+00, -3.9028e-01,  ..., -4.0480e-01,\n",
       "            1.2771e+00, -4.0365e-01],\n",
       "          ...,\n",
       "          [ 2.3518e-01, -9.9256e-01, -1.7103e+00,  ...,  1.4055e+00,\n",
       "            9.2436e-01,  2.7407e+00],\n",
       "          [ 4.5791e+00,  3.1215e+00, -4.6697e+00,  ..., -2.4629e+00,\n",
       "            1.2910e-02, -1.5150e+00],\n",
       "          [ 7.4268e+00,  2.1728e+00, -5.2182e+00,  ..., -4.4069e+00,\n",
       "            1.4425e+00, -2.6270e+00]],\n",
       "\n",
       "         [[ 2.0114e-01,  1.4414e+00, -1.4013e+00,  ...,  3.2414e-02,\n",
       "           -8.1039e-01,  6.3300e-01],\n",
       "          [-5.8075e-01,  3.3190e+00,  9.9413e-02,  ...,  8.5578e-01,\n",
       "           -1.5273e-01,  1.2669e+00],\n",
       "          [ 7.9608e-01,  1.6551e-01, -4.0708e-01,  ...,  2.4445e+00,\n",
       "           -1.2397e+00, -1.3235e+00],\n",
       "          ...,\n",
       "          [ 7.3208e-02,  1.4956e+00,  9.6125e-01,  ...,  8.3061e-01,\n",
       "            1.2551e+00, -3.9124e-02],\n",
       "          [-6.6614e-01, -5.3362e-01, -1.0804e+00,  ..., -5.3103e-01,\n",
       "            1.3583e+00, -4.5030e+00],\n",
       "          [ 1.5545e-01, -3.4297e-01, -1.2475e-01,  ..., -2.3458e+00,\n",
       "            5.8842e+00, -5.4805e+00]],\n",
       "\n",
       "         [[-1.6038e+00,  4.0592e+00,  3.6467e+00,  ..., -1.8345e+00,\n",
       "            1.2297e+00, -2.7270e+00],\n",
       "          [ 1.0636e+00,  2.9281e+00,  2.0410e+00,  ..., -1.9434e+00,\n",
       "            1.7567e-01, -4.8347e+00],\n",
       "          [ 1.1853e+00,  2.4220e+00,  1.3498e+00,  ..., -2.7940e+00,\n",
       "            1.4191e+00, -2.6720e+00],\n",
       "          ...,\n",
       "          [ 6.6867e-01,  4.4075e+00,  2.4962e+00,  ...,  6.3647e-01,\n",
       "            1.6723e+00, -3.7608e+00],\n",
       "          [ 4.0841e-01, -8.1533e-01, -8.9513e-01,  ..., -9.3270e-01,\n",
       "            1.7318e+00,  3.0823e+00],\n",
       "          [-1.3455e+00,  1.6893e+00, -5.2433e+00,  ..., -1.4423e+00,\n",
       "            2.4464e+00,  4.8877e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3309e+00, -1.8079e-01,  8.5235e-01,  ...,  1.3838e+00,\n",
       "            5.5703e-01, -1.1851e-01],\n",
       "          [ 1.7684e-02,  2.6750e-01, -7.9056e-01,  ..., -3.6483e-01,\n",
       "           -9.9182e-01, -6.9684e-02],\n",
       "          [-2.1572e+00, -3.0137e+00, -9.2235e-01,  ..., -1.1130e+00,\n",
       "            1.0788e-02, -2.2761e+00],\n",
       "          ...,\n",
       "          [ 4.4149e-01, -1.6566e+00, -2.2943e+00,  ...,  2.2202e+00,\n",
       "            6.8045e-01, -2.2515e+00],\n",
       "          [-1.6149e+00, -3.6378e+00, -4.7343e+00,  ...,  5.5301e-01,\n",
       "            1.8450e+00, -4.7763e+00],\n",
       "          [-5.4545e+00, -4.8484e+00, -6.5776e+00,  ..., -2.4066e+00,\n",
       "            4.0715e+00, -5.9277e+00]],\n",
       "\n",
       "         [[ 4.6615e-01,  3.2953e+00,  2.2308e+00,  ..., -3.6308e+00,\n",
       "           -6.1896e-01, -3.2107e+00],\n",
       "          [ 1.1116e+00,  2.1875e+00,  2.5438e+00,  ..., -9.8349e-01,\n",
       "           -4.3324e-01, -9.6488e-01],\n",
       "          [-8.3299e-02,  3.0283e+00,  1.0572e+00,  ..., -2.2911e+00,\n",
       "            1.5893e-02, -1.0383e+00],\n",
       "          ...,\n",
       "          [ 1.6541e+00,  1.4606e+00,  1.5865e+00,  ..., -1.6462e+00,\n",
       "            3.2060e-01, -9.1684e-01],\n",
       "          [ 1.1099e+00,  8.0713e-01, -1.5201e+00,  ...,  3.3129e+00,\n",
       "           -2.1573e+00, -1.8305e+00],\n",
       "          [ 8.5672e-01,  8.4619e-01, -1.2899e+00,  ...,  5.2925e+00,\n",
       "           -1.6054e+00, -4.5069e+00]],\n",
       "\n",
       "         [[ 1.6524e+00, -3.9474e-01,  9.2029e-01,  ..., -3.5606e+00,\n",
       "            1.0584e+00,  1.6225e+00],\n",
       "          [-4.2939e-01,  2.1174e-02,  9.8589e-01,  ..., -4.3379e+00,\n",
       "           -4.3906e-01,  2.5159e+00],\n",
       "          [ 4.2696e-02, -7.8959e-01, -1.6826e+00,  ..., -4.1538e+00,\n",
       "            2.5411e-01,  3.9760e-01],\n",
       "          ...,\n",
       "          [ 4.6176e-01,  3.8263e-01, -5.9099e-03,  ...,  2.8557e-01,\n",
       "            6.6677e-01,  1.1021e+00],\n",
       "          [ 3.4308e+00,  1.4744e+00,  2.8543e+00,  ..., -4.2807e+00,\n",
       "            4.6244e+00, -2.7956e-01],\n",
       "          [ 6.8274e+00,  3.6695e+00,  2.7556e+00,  ..., -6.0024e+00,\n",
       "            4.0026e+00, -1.6880e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[ 2.5277,  0.5996, -0.3746,  ...,  1.3179, -2.0082,  1.1283],\n",
       "          [ 1.6623, -0.9975,  0.3805,  ..., -0.0178, -1.1690,  2.4215],\n",
       "          [ 3.0761, -1.7871,  1.6494,  ...,  0.9716, -0.7387,  3.2872],\n",
       "          ...,\n",
       "          [ 3.2764,  2.6137,  2.0223,  ...,  1.9782,  1.7240,  1.5404],\n",
       "          [ 3.2351,  0.2423, -1.7280,  ...,  0.4850, -0.4856,  1.6358],\n",
       "          [-0.3146,  0.2820,  0.8528,  ...,  0.1333, -0.2615,  0.3032]],\n",
       "\n",
       "         [[-2.1517, -2.8667,  1.1636,  ..., -0.4686,  2.8749, -1.0594],\n",
       "          [-3.2202, -0.4268,  1.3310,  ..., -0.5602,  2.1163, -1.0948],\n",
       "          [-2.9162, -1.5714,  1.0005,  ..., -1.3005,  2.1242, -0.9118],\n",
       "          ...,\n",
       "          [-4.1447, -0.1365,  4.3778,  ...,  0.7382,  5.2263,  0.6169],\n",
       "          [-0.4398,  2.3410,  2.2837,  ...,  1.3976,  2.8994, -1.2014],\n",
       "          [ 1.5052,  0.0970, -1.7909,  ...,  0.6722, -1.9387, -0.1603]],\n",
       "\n",
       "         [[-3.2611,  2.9800,  1.5326,  ...,  1.2610,  3.1808, -2.2231],\n",
       "          [-1.2285,  2.1405, -0.2205,  ..., -0.1325,  2.3103, -2.6801],\n",
       "          [-3.2514,  0.9347, -0.3532,  ...,  1.6166,  1.9333, -4.7861],\n",
       "          ...,\n",
       "          [ 0.0842, -0.3430,  0.9819,  ...,  1.3619,  4.4692, -3.1455],\n",
       "          [-1.2263, -3.5147, -2.1995,  ..., -3.1990,  4.2545, -1.4956],\n",
       "          [ 2.0600,  0.6727, -0.1868,  ...,  0.0930, -0.4201, -0.6080]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.7085, -4.4764,  0.5687,  ...,  4.7793, -6.2613, -7.4692],\n",
       "          [ 3.8598, -4.5230, -0.5513,  ...,  7.1926, -5.5999, -7.2965],\n",
       "          [ 0.9738, -2.9784,  0.2839,  ...,  3.1319, -3.5169, -6.6391],\n",
       "          ...,\n",
       "          [-0.5585, -1.4223, -0.3925,  ...,  2.1901, -5.2455, -4.8585],\n",
       "          [ 0.1576, -2.7494, -0.9712,  ...,  2.1472, -4.1783, -5.8829],\n",
       "          [-0.1732, -0.1256,  1.0029,  ...,  0.4442,  4.1246,  0.9145]],\n",
       "\n",
       "         [[-5.1987, -0.7513,  0.9905,  ..., -1.5853,  0.3140,  8.3193],\n",
       "          [-1.2823, -0.4780,  0.8118,  ..., -0.8713,  1.3784,  5.7636],\n",
       "          [-2.3387, -1.4015,  1.5030,  ..., -2.0851,  0.0561,  6.4197],\n",
       "          ...,\n",
       "          [ 2.9190, -3.4446,  0.9034,  ...,  1.0426,  1.3693, -0.6643],\n",
       "          [-4.1011, -0.8670, -0.4830,  ...,  1.3243,  4.9978,  1.5992],\n",
       "          [ 0.9110,  0.2882, -0.3818,  ..., -0.4399,  0.6281,  0.1947]],\n",
       "\n",
       "         [[ 2.2788,  2.0696,  6.2067,  ...,  4.5849, -0.0823, -2.1569],\n",
       "          [ 2.3927, -1.1246,  2.8077,  ...,  5.3213, -1.3232, -2.3009],\n",
       "          [ 1.0334,  0.8726,  2.6902,  ...,  1.6496, -0.5352, -4.1262],\n",
       "          ...,\n",
       "          [-1.0946, -2.3008,  0.6675,  ...,  1.1935, -5.5149, -0.5129],\n",
       "          [-1.2437, -0.3017, -1.4685,  ...,  3.7110, -4.3287, -0.9276],\n",
       "          [-1.0999, -1.4084,  0.3520,  ..., -3.2320,  1.0843,  0.3866]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-1.0053, -0.6367,  0.3296,  ..., -0.3901, -1.3054,  3.2492],\n",
       "          [-0.2180,  1.7528,  1.4546,  ..., -0.2682, -2.4373,  2.5239],\n",
       "          [ 0.7037, -0.6198, -0.5546,  ..., -0.6230, -1.4968,  1.5356],\n",
       "          ...,\n",
       "          [ 1.6067, -2.6414, -1.4615,  ...,  0.3217, -0.7046, -0.2706],\n",
       "          [ 0.1683, -3.0410,  1.3318,  ..., -0.6082, -1.1500, -0.8286],\n",
       "          [ 0.0928, -0.0775, -0.0918,  ...,  0.2075,  0.0894,  0.1430]],\n",
       "\n",
       "         [[ 1.1315, -1.5125, -0.7058,  ..., -1.6729, -0.4905,  1.0725],\n",
       "          [ 0.7800, -2.4787,  2.3899,  ..., -0.2184, -0.0333,  0.5677],\n",
       "          [ 0.7047, -1.2840,  0.7477,  ...,  1.7661, -0.6621,  0.1498],\n",
       "          ...,\n",
       "          [-3.6151, -1.1940,  1.7491,  ..., -0.4270, -1.9607,  2.4338],\n",
       "          [-0.5865, -0.7405, -0.8465,  ...,  0.8865,  0.1512,  2.3426],\n",
       "          [ 0.0994, -0.0148,  0.0748,  ..., -0.0364,  0.0637, -0.1485]],\n",
       "\n",
       "         [[ 1.2945,  1.3150, -1.7298,  ..., -3.8492, -1.6685, -2.3138],\n",
       "          [ 1.5878,  2.2217, -1.3102,  ..., -1.5894,  0.1869, -1.1890],\n",
       "          [ 2.6630,  3.6213, -1.1655,  ..., -3.6590, -0.1719, -1.6367],\n",
       "          ...,\n",
       "          [ 3.2229,  0.0430,  0.5213,  ..., -3.2889,  0.0886, -0.2261],\n",
       "          [ 1.7357, -3.6412,  3.4318,  ...,  0.3001,  0.9590, -0.5466],\n",
       "          [ 0.1168, -0.0094,  0.0329,  ..., -0.2635, -0.0355, -0.1257]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.5546,  0.8070, -1.0749,  ...,  3.5760, -2.9348,  0.4452],\n",
       "          [ 2.3737, -1.1138, -0.1033,  ...,  2.8617, -0.8269,  0.6060],\n",
       "          [ 0.3397,  0.9372,  0.8734,  ...,  1.5966, -2.9199,  1.3211],\n",
       "          ...,\n",
       "          [-2.6887,  1.0123,  1.2811,  ..., -1.8983, -1.6155, -1.2328],\n",
       "          [-0.5489, -1.1356, -0.1727,  ...,  1.0584, -3.0663, -0.5946],\n",
       "          [ 0.1125, -0.0133,  0.0802,  ..., -0.0176,  0.0041, -0.1224]],\n",
       "\n",
       "         [[ 1.4040,  0.4261,  0.5645,  ...,  0.5675, -0.0953,  0.3975],\n",
       "          [-0.5428, -2.2379, -0.8770,  ..., -0.0610,  1.6289,  1.4801],\n",
       "          [ 0.1129,  0.3947, -1.6469,  ..., -0.1385, -1.2056,  1.3796],\n",
       "          ...,\n",
       "          [-1.0690,  0.6219, -3.8379,  ...,  0.0069,  2.7732, -1.5818],\n",
       "          [-0.9880,  1.8505, -2.5762,  ..., -2.2108, -2.5249, -2.2680],\n",
       "          [-0.2272,  0.1925,  0.0364,  ...,  0.0264,  0.0153, -0.0175]],\n",
       "\n",
       "         [[-1.1455, -2.8711, -0.9416,  ..., -0.4034,  0.6327,  2.2024],\n",
       "          [ 1.8789, -1.4256,  1.6636,  ..., -0.0444,  2.6943, -0.4182],\n",
       "          [-0.4561,  0.1300,  0.3075,  ...,  0.3416, -0.6668,  1.1095],\n",
       "          ...,\n",
       "          [ 3.0116, -0.5971, -2.9729,  ..., -0.2853,  1.0077,  0.7793],\n",
       "          [-0.4865, -1.6888,  0.7602,  ...,  0.0749, -0.5939, -0.3168],\n",
       "          [ 0.3361,  0.0505,  0.0386,  ...,  0.1255, -0.2383, -0.2531]]]],\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[ -1.1903,   2.1017,  -0.1434,  ...,   3.0598,   2.8752,  -8.0523],\n",
       "          [ -0.4588,   2.3133,  -1.9400,  ...,   3.4221,   2.2458,  -8.1467],\n",
       "          [ -0.7692,   2.4942,  -1.7191,  ...,   2.0559,   1.2852,  -7.5919],\n",
       "          ...,\n",
       "          [ -2.9297,   1.1458,  -1.4052,  ...,   3.5869,   3.3606,  -9.5727],\n",
       "          [ -2.3292,   3.0782,  -1.2035,  ...,   2.3882,   3.9312, -12.9174],\n",
       "          [ -2.5135,   1.2253,  -2.0337,  ...,   2.2151,   1.9037, -13.1273]],\n",
       "\n",
       "         [[ -3.9476,  -2.3260,  -0.4411,  ...,   0.6058,  -0.3320,  -1.4977],\n",
       "          [ -2.3737,  -1.9628,  -0.4863,  ...,   0.9967,   0.7320,   0.2347],\n",
       "          [ -1.6590,  -0.5958,  -1.3132,  ...,   0.1295,   1.1846,  -1.9295],\n",
       "          ...,\n",
       "          [ -0.9676,  -2.4570,  -3.4928,  ...,   0.4924,  -0.2990,  -3.0519],\n",
       "          [  1.3603,  -1.2591,  -6.3202,  ...,  -0.8592,   3.2051,  -3.8221],\n",
       "          [  2.5282,  -1.9704,  -4.6812,  ...,  -2.3174,   2.9344,  -4.6012]],\n",
       "\n",
       "         [[ -2.3430,  -1.2287,   0.2925,  ...,   1.8064,   0.1444,   2.4533],\n",
       "          [ -1.5345,  -0.9525,  -0.4074,  ...,  -0.1711,   0.5999,   0.9672],\n",
       "          [ -3.1740,   0.2957,   0.0353,  ...,   0.0550,  -0.4088,   0.9948],\n",
       "          ...,\n",
       "          [ -1.9959,   0.3215,  -0.9239,  ...,   2.1646,   0.4241,   0.5999],\n",
       "          [  0.1293,  -0.6984,   4.6273,  ...,   0.1111,  -0.2718,  -0.4534],\n",
       "          [  0.1042,  -1.1166,   3.2420,  ...,   0.0969,  -0.1161,  -0.7588]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -2.0626,  -2.1237,  -1.0156,  ...,  -0.4328,  -0.9645,   1.8060],\n",
       "          [ -2.6487,  -2.5096,   0.4121,  ...,   0.8649,  -0.2475,   1.3877],\n",
       "          [ -2.2048,  -1.9008,  -0.2074,  ...,  -0.0698,  -1.0598,   1.8780],\n",
       "          ...,\n",
       "          [ -0.3233,  -3.4395,  -1.3391,  ...,  -1.2180,  -0.2512,   3.4097],\n",
       "          [ -4.5114,  -7.0979,   1.3795,  ...,  -4.5986,  -0.6856,   2.2431],\n",
       "          [ -4.6288,  -7.1640,   0.3905,  ...,  -3.5552,  -1.6839,   3.2946]],\n",
       "\n",
       "         [[ -0.7519,   0.6616,   0.4826,  ...,  -2.8327,   0.0184,  -1.8566],\n",
       "          [ -1.3269,  -0.0937,   0.8020,  ...,   0.2877,   0.2455,  -0.2875],\n",
       "          [ -0.5923,   0.0268,  -0.7286,  ...,  -0.9133,   0.3402,  -0.2850],\n",
       "          ...,\n",
       "          [  0.4514,   1.2481,  -0.0767,  ...,   1.1445,   0.4916,  -1.0410],\n",
       "          [  1.2235,   1.7049,   2.5724,  ...,  -0.5841,  -1.7639,  -0.3672],\n",
       "          [  0.1164,   2.7765,   1.9226,  ...,  -0.8214,  -2.1191,  -1.2669]],\n",
       "\n",
       "         [[ -1.7036,  -0.5751,  -3.1377,  ...,  -1.5947,  -0.9109,  -2.5895],\n",
       "          [ -1.8816,  -1.5422,  -0.9589,  ...,  -2.0282,   0.3651,  -1.5969],\n",
       "          [ -1.2630,  -0.4616,  -1.8797,  ...,  -0.8964,  -1.2391,  -3.2074],\n",
       "          ...,\n",
       "          [ -2.3863,  -2.3876,  -1.7381,  ...,  -2.1424,  -2.9623,  -0.1803],\n",
       "          [ -3.5228,  -3.9091,   0.6274,  ...,   2.3624,   2.1883,  -1.3259],\n",
       "          [ -3.7936,  -3.9065,   2.1497,  ...,   2.8248,  -0.2944,  -3.3499]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-0.3903,  0.3141,  2.4474,  ..., -3.0329, -0.6778, -3.1517],\n",
       "          [ 0.2128,  0.3935, -0.1387,  ..., -1.5069,  0.5767, -1.3967],\n",
       "          [ 0.9295,  0.2514, -0.9706,  ..., -0.4888,  2.2055, -4.8645],\n",
       "          ...,\n",
       "          [-0.1997,  1.6534, -0.1359,  ..., -1.1856,  2.7178, -0.8636],\n",
       "          [ 3.0377,  6.6427, -0.2601,  ..., -0.9511,  0.5901,  3.5187],\n",
       "          [ 3.5912,  4.1098, -0.9714,  ..., -3.1666,  2.0322,  4.4585]],\n",
       "\n",
       "         [[-1.3685,  1.0451, -0.6088,  ..., -1.1604,  0.1528,  1.0217],\n",
       "          [ 0.7778,  0.7226, -0.2038,  ...,  1.1296, -1.2140,  0.3993],\n",
       "          [ 1.0886, -1.2422,  0.8212,  ...,  2.6541, -1.5170,  2.1439],\n",
       "          ...,\n",
       "          [ 0.6579,  0.4706,  2.7590,  ..., -0.6261, -2.1202,  3.5189],\n",
       "          [-2.0831, -3.3092,  1.7504,  ..., -2.9873,  3.8035, -1.2230],\n",
       "          [-1.7681, -2.9970,  0.7233,  ..., -3.8864,  2.5164, -3.9109]],\n",
       "\n",
       "         [[ 5.0541, -1.5763,  0.0097,  ..., -1.6961, -2.9557,  1.0297],\n",
       "          [ 0.8204, -3.5083, -0.2523,  ..., -2.2128, -3.4496,  2.6226],\n",
       "          [ 0.2572, -2.6339, -2.3390,  ..., -2.6323, -1.5819,  1.1068],\n",
       "          ...,\n",
       "          [-0.1946, -2.2214,  0.2309,  ...,  0.5831, -1.6260,  2.3575],\n",
       "          [-0.2899,  3.7081, -3.5990,  ...,  3.1125, -4.5475, -4.3148],\n",
       "          [-0.2129,  1.0121, -1.7155,  ...,  3.6701, -1.5355, -3.3536]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.5094,  0.5157, -3.6879,  ..., -2.5835, -0.2967, -1.6255],\n",
       "          [-2.7078, -1.9373, -2.7172,  ..., -0.7490, -0.9536, -0.4573],\n",
       "          [-2.3505, -1.1287, -2.7650,  ..., -0.4441,  0.7265,  0.5983],\n",
       "          ...,\n",
       "          [-0.7383, -0.6571, -0.4813,  ...,  2.0966, -0.6087, -2.0937],\n",
       "          [-0.7128, -3.6965, -0.6733,  ..., -0.2355, -1.5427,  2.9780],\n",
       "          [-2.4714, -4.9486, -1.0360,  ..., -0.3113,  0.5187,  3.0262]],\n",
       "\n",
       "         [[-2.3698, -2.4152,  0.6154,  ...,  1.8855,  1.6667, -3.6086],\n",
       "          [-1.4339, -1.9680,  0.4931,  ...,  2.8957,  1.8574, -0.4954],\n",
       "          [ 0.8610, -3.6292, -0.4937,  ...,  2.4403,  0.3967,  0.2767],\n",
       "          ...,\n",
       "          [-0.4135, -2.9036, -0.2798,  ...,  6.4760,  3.9791,  1.1208],\n",
       "          [ 0.7373, -7.7788,  1.9894,  ...,  5.9320,  3.3120, -1.3270],\n",
       "          [ 0.0686, -7.4248,  1.8421,  ...,  3.4100,  3.4736, -0.4592]],\n",
       "\n",
       "         [[-2.6678,  1.9199, -0.0939,  ..., -1.0729,  0.7716,  0.0120],\n",
       "          [-3.8942,  1.3896, -0.9268,  ..., -2.1382, -2.2631, -0.2785],\n",
       "          [-3.5632,  1.6415, -1.0837,  ..., -2.5510,  1.5776, -0.9451],\n",
       "          ...,\n",
       "          [-3.4686,  2.1705, -1.5329,  ..., -2.4895,  0.3678, -0.3193],\n",
       "          [-2.5473, -3.3844, -6.8099,  ...,  2.9972, -0.2418, -1.5785],\n",
       "          [-1.6799, -3.1785, -5.8651,  ...,  3.0904,  1.7154, -0.6848]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-3.4347e+00, -3.1181e-01,  1.4780e-01,  ...,  2.3738e+00,\n",
       "            7.0351e-02,  2.5823e-01],\n",
       "          [-3.4509e-01,  2.5400e+00, -3.5938e+00,  ...,  3.8182e+00,\n",
       "            3.4829e+00, -2.4716e+00],\n",
       "          [-4.4497e+00, -1.1924e+00,  1.2659e+00,  ..., -9.5309e-03,\n",
       "            1.5311e-01, -7.5117e-01],\n",
       "          ...,\n",
       "          [ 9.5315e-01, -2.2118e+00, -2.5157e+00,  ..., -3.1435e+00,\n",
       "            1.1828e+00, -7.6593e-01],\n",
       "          [ 7.6115e-01, -5.8191e-01,  1.0369e+00,  ..., -2.3824e+00,\n",
       "            2.0279e+00,  1.2047e-01],\n",
       "          [ 1.8466e-01, -4.5632e-01,  1.8812e-01,  ...,  2.8281e-02,\n",
       "           -7.3449e-02, -3.4674e-02]],\n",
       "\n",
       "         [[-3.0927e+00, -3.8598e-01,  9.5502e-01,  ...,  2.3515e+00,\n",
       "           -1.6572e+00, -1.1778e-01],\n",
       "          [-5.0833e+00,  1.4538e+00, -2.6637e-02,  ...,  6.8042e-01,\n",
       "           -1.0110e+00, -3.1208e+00],\n",
       "          [-3.7664e+00,  2.7293e-01,  1.1654e+00,  ...,  3.2465e+00,\n",
       "           -6.1783e-01,  3.2346e-01],\n",
       "          ...,\n",
       "          [-2.7132e+00, -4.0183e+00,  2.0202e+00,  ...,  2.8378e+00,\n",
       "           -2.0030e+00, -1.6844e+00],\n",
       "          [-3.9625e+00, -4.1542e+00,  3.1723e+00,  ...,  6.1070e-01,\n",
       "           -1.2584e-01, -1.8922e+00],\n",
       "          [ 2.5330e-01, -6.3299e-02, -3.9950e-01,  ..., -3.8507e-01,\n",
       "           -4.2755e-01, -7.9911e-01]],\n",
       "\n",
       "         [[-2.1125e+00,  6.3050e-01, -8.8099e-01,  ..., -1.3033e+00,\n",
       "           -2.6551e-01, -2.9774e+00],\n",
       "          [-1.4769e+00, -2.1610e+00,  7.2425e-01,  ..., -1.6824e+00,\n",
       "           -3.4741e+00, -6.2748e+00],\n",
       "          [-4.0744e-01, -1.2430e+00, -5.5444e-01,  ..., -1.9182e+00,\n",
       "           -1.1506e+00, -3.8293e+00],\n",
       "          ...,\n",
       "          [-1.0330e+00, -1.7618e+00, -2.8214e+00,  ...,  3.5239e+00,\n",
       "           -2.3438e+00,  8.6416e-01],\n",
       "          [-1.5331e-01, -3.8010e-01, -5.2771e+00,  ..., -2.5037e-02,\n",
       "           -2.4749e+00, -5.2117e-01],\n",
       "          [-6.7404e-01, -1.5900e-01,  7.7534e-01,  ...,  5.3448e-02,\n",
       "            4.2084e-01,  2.4208e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.6923e+00, -2.1288e+00, -3.4277e-01,  ...,  9.5346e-01,\n",
       "           -3.4584e+00,  1.7782e+00],\n",
       "          [-2.0700e+00, -1.1495e+00,  1.3015e+00,  ...,  1.7792e+00,\n",
       "           -3.2094e+00,  4.1256e+00],\n",
       "          [-1.8139e+00, -5.4527e-01, -1.4502e+00,  ..., -5.2567e-01,\n",
       "           -4.1797e+00,  2.7635e+00],\n",
       "          ...,\n",
       "          [ 8.6637e-01, -2.7820e+00,  4.5342e-01,  ..., -7.5831e-01,\n",
       "           -3.4814e+00,  9.1793e-01],\n",
       "          [ 2.2851e+00, -7.4584e-01, -1.1502e+00,  ...,  6.6979e-01,\n",
       "           -2.8846e+00,  4.1153e-01],\n",
       "          [-6.3785e-01, -5.8889e-01,  6.2073e-01,  ...,  1.1736e-01,\n",
       "            5.3086e-01, -9.9427e-02]],\n",
       "\n",
       "         [[-9.9991e-01,  9.2844e-01,  3.4426e+00,  ..., -2.1895e+00,\n",
       "           -1.6143e+00, -3.8785e+00],\n",
       "          [-9.7723e-01, -1.8980e-03,  1.5879e+00,  ..., -4.2033e-01,\n",
       "           -1.8989e+00, -1.9154e+00],\n",
       "          [-1.7455e+00, -3.6088e-01,  6.9973e-01,  ..., -2.2191e+00,\n",
       "           -2.9700e+00, -3.0377e+00],\n",
       "          ...,\n",
       "          [-9.7898e-01,  2.8782e+00, -8.3368e-02,  ..., -3.5229e+00,\n",
       "           -4.6827e+00, -2.4756e+00],\n",
       "          [-1.2518e+00,  2.3107e+00, -1.0478e+00,  ..., -1.0078e+00,\n",
       "           -2.3307e+00, -2.1814e+00],\n",
       "          [-5.1748e-01, -4.3670e-01,  3.9204e-01,  ..., -3.7175e-01,\n",
       "            1.5584e-01, -5.4836e-01]],\n",
       "\n",
       "         [[ 7.3010e-01,  1.1012e+00, -2.9555e+00,  ..., -2.0414e+00,\n",
       "            4.5577e-02,  1.3312e+00],\n",
       "          [ 2.3159e+00,  5.4259e-01, -2.0801e+00,  ..., -1.8061e+00,\n",
       "           -1.2144e-01,  3.7507e-01],\n",
       "          [ 2.4905e+00,  3.4641e-02, -3.7137e+00,  ..., -1.0584e+00,\n",
       "            9.8887e-01, -1.3718e-01],\n",
       "          ...,\n",
       "          [-1.0019e+00, -1.5709e-01, -4.7527e+00,  ..., -9.2930e-01,\n",
       "            2.0849e+00, -1.8582e+00],\n",
       "          [ 2.3511e-01, -1.6528e+00, -5.4663e+00,  ...,  1.4465e-01,\n",
       "            7.9068e-01, -4.3620e+00],\n",
       "          [ 3.1162e-01, -4.1406e-03,  9.1953e-01,  ..., -1.9076e+00,\n",
       "            9.5822e-01,  7.5399e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-1.4916e+00, -6.8423e-01, -8.7700e-01,  ..., -4.0239e+00,\n",
       "           -7.2755e-01, -6.7844e-02],\n",
       "          [-1.0967e+00, -3.5713e+00,  1.7945e+00,  ..., -3.5123e+00,\n",
       "           -1.4974e+00, -3.1911e-01],\n",
       "          [-8.6954e-01, -2.8649e+00, -6.1471e-01,  ..., -1.9595e+00,\n",
       "           -1.2087e-01, -8.8338e-01],\n",
       "          ...,\n",
       "          [ 1.4335e+00,  7.7188e-01,  2.8787e+00,  ...,  1.1122e+00,\n",
       "           -2.7787e+00, -2.4364e-01],\n",
       "          [-8.6575e-01, -3.3045e+00,  2.0567e+00,  ..., -1.5614e+00,\n",
       "           -8.6963e-01, -3.9358e-01],\n",
       "          [-8.0829e-01, -2.8225e-01, -3.9083e-01,  ...,  3.2712e-01,\n",
       "            4.2316e-01, -1.3645e-01]],\n",
       "\n",
       "         [[-1.8013e+00,  5.2885e+00, -9.2760e-01,  ..., -2.8634e+00,\n",
       "           -1.6473e+00,  7.1607e-01],\n",
       "          [-2.3484e+00,  2.6368e+00, -2.7144e+00,  ..., -1.0241e+00,\n",
       "           -2.9316e+00, -4.1354e+00],\n",
       "          [-4.3630e-01,  3.6313e+00, -1.3605e+00,  ..., -3.1179e-01,\n",
       "           -2.4147e+00, -1.4271e+00],\n",
       "          ...,\n",
       "          [-3.5304e-01,  1.6694e+00,  6.1240e+00,  ...,  1.7957e+00,\n",
       "           -2.5919e-01,  2.5024e-01],\n",
       "          [-9.5966e-01,  1.7084e+00,  7.2367e-01,  ..., -5.1644e-02,\n",
       "           -1.5110e+00, -2.5811e-01],\n",
       "          [-3.3176e-01, -2.0740e-01, -6.5618e-02,  ..., -1.3978e-01,\n",
       "            2.2926e-01, -1.3888e-01]],\n",
       "\n",
       "         [[ 1.2531e+00, -4.3249e+00,  1.0171e+00,  ..., -3.2014e+00,\n",
       "           -9.1362e-01, -2.0403e+00],\n",
       "          [-5.5729e-01, -5.5794e-01,  1.3116e+00,  ..., -4.3782e-01,\n",
       "           -2.6036e+00, -4.1368e-01],\n",
       "          [ 1.1040e+00, -1.9926e+00, -1.2837e+00,  ..., -1.1960e+00,\n",
       "           -5.3544e-01, -9.9289e-01],\n",
       "          ...,\n",
       "          [-1.0595e+00, -6.0580e+00,  7.5873e-01,  ...,  7.7693e-01,\n",
       "           -2.6119e+00, -2.4557e+00],\n",
       "          [-1.4916e+00, -3.8107e+00, -4.6742e-01,  ..., -1.3724e+00,\n",
       "           -1.1614e+00, -3.4397e-01],\n",
       "          [-1.0642e-01,  2.7466e-01,  1.2389e-02,  ..., -3.6453e-02,\n",
       "           -4.2410e-01,  1.4629e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.1993e+00, -1.1662e+00,  3.2428e+00,  ...,  1.6067e+00,\n",
       "           -1.8678e+00, -2.2185e-01],\n",
       "          [-1.8110e+00, -4.0176e+00,  2.9816e+00,  ..., -4.3999e-01,\n",
       "           -2.2227e+00,  1.4578e+00],\n",
       "          [-1.0073e-04,  1.6729e+00,  2.6826e+00,  ...,  1.0589e+00,\n",
       "           -5.0613e-01, -2.3024e-01],\n",
       "          ...,\n",
       "          [-2.1400e+00,  1.2282e+00,  1.0544e+00,  ..., -2.2708e-02,\n",
       "            1.4410e+00,  1.6063e-01],\n",
       "          [-2.7672e+00, -2.6225e-01,  1.1569e+00,  ...,  2.0839e+00,\n",
       "           -7.1319e-01,  2.9598e-01],\n",
       "          [ 6.8632e-02,  9.0739e-02, -1.5658e-01,  ..., -1.7098e-01,\n",
       "           -1.3884e-02,  3.1959e-01]],\n",
       "\n",
       "         [[-6.3021e-01,  1.2439e+00, -1.5944e+00,  ..., -2.1610e+00,\n",
       "           -8.2727e-01, -1.0827e+00],\n",
       "          [ 3.9027e-01, -3.3885e-02, -1.7845e+00,  ..., -3.9049e+00,\n",
       "           -3.0962e+00,  9.8243e-01],\n",
       "          [-2.3488e-02, -1.3000e+00, -2.9993e+00,  ..., -1.7820e-01,\n",
       "            2.3991e-01, -1.9118e+00],\n",
       "          ...,\n",
       "          [ 6.1685e-01,  2.5040e+00, -3.5715e+00,  ...,  2.0448e+00,\n",
       "            3.1878e-01, -1.8713e+00],\n",
       "          [-1.1286e-01,  1.4372e+00,  1.1274e-01,  ...,  1.6118e+00,\n",
       "           -1.7348e-01, -1.9293e+00],\n",
       "          [ 2.5102e-01,  2.3669e-01, -2.6277e-02,  ..., -3.7584e-02,\n",
       "           -3.3866e-01, -2.2130e-01]],\n",
       "\n",
       "         [[ 3.3829e+00, -2.9770e+00,  4.4658e-01,  ..., -2.2641e-01,\n",
       "           -1.0070e+00,  3.0731e+00],\n",
       "          [ 1.1004e+00, -2.7957e+00,  1.0747e+00,  ...,  4.9818e-01,\n",
       "           -1.8980e+00,  4.6916e+00],\n",
       "          [-1.3993e+00, -3.6438e+00,  1.0837e+00,  ...,  1.4804e+00,\n",
       "           -9.9652e-01,  4.0927e+00],\n",
       "          ...,\n",
       "          [-1.6072e+00, -1.9592e-01,  7.8207e-01,  ..., -1.9573e+00,\n",
       "            2.1309e+00, -4.2851e-01],\n",
       "          [ 2.0698e+00, -1.3926e+00,  6.1754e-01,  ..., -7.2459e-02,\n",
       "            8.6547e-01, -2.8199e+00],\n",
       "          [-4.3233e-01, -2.8212e-01,  7.0291e-03,  ...,  3.1865e-01,\n",
       "           -8.4944e-02, -6.9150e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[ 4.9645e-01,  6.7070e-01,  7.2347e-02,  ...,  4.7036e-01,\n",
       "            9.8353e+00,  1.2554e+00],\n",
       "          [ 6.4277e-02,  8.3278e-01,  1.5790e+00,  ...,  1.0637e-01,\n",
       "            9.9226e+00,  1.4198e+00],\n",
       "          [-1.9078e-02,  1.6726e+00,  5.4971e-01,  ..., -1.8391e+00,\n",
       "            9.1630e+00,  1.6161e+00],\n",
       "          ...,\n",
       "          [-5.9985e-01,  1.0173e+00,  2.4437e+00,  ..., -6.1665e-01,\n",
       "            8.8363e+00,  1.0077e+00],\n",
       "          [ 1.8857e+00,  5.4388e-01,  3.3181e+00,  ..., -8.5314e-01,\n",
       "            1.0183e+01, -1.7460e+00],\n",
       "          [ 1.6480e+00,  5.6527e-01,  2.7167e+00,  ..., -1.0233e+00,\n",
       "            9.1706e+00, -1.1488e+00]],\n",
       "\n",
       "         [[ 6.5265e-01,  2.4309e+00, -8.9521e-01,  ...,  6.2645e-01,\n",
       "           -2.2806e-01, -4.4343e+00],\n",
       "          [ 1.3104e+00,  2.8427e+00, -2.4298e+00,  ...,  4.4845e-03,\n",
       "            3.9538e-01, -4.4301e+00],\n",
       "          [ 5.8497e-02,  1.8092e+00, -2.9298e+00,  ...,  5.0258e-01,\n",
       "            2.0063e+00, -2.9800e+00],\n",
       "          ...,\n",
       "          [-8.7998e-02,  3.4783e+00, -5.1224e+00,  ...,  6.5948e-01,\n",
       "            1.7004e-01, -2.6733e+00],\n",
       "          [-1.2930e+00, -9.5180e-01, -5.1155e+00,  ..., -8.0915e-01,\n",
       "            9.7456e-01, -3.4033e+00],\n",
       "          [-1.4856e-02, -1.2828e+00, -7.3826e+00,  ..., -7.7884e-01,\n",
       "            1.1162e+00, -3.7375e+00]],\n",
       "\n",
       "         [[ 9.2007e-01,  1.7072e+00,  1.0075e+00,  ...,  4.2562e-01,\n",
       "            1.0909e+00,  1.9078e+00],\n",
       "          [ 2.0995e+00,  1.0948e+00, -3.7530e-03,  ..., -4.8741e-01,\n",
       "            1.3978e+00, -7.8274e-01],\n",
       "          [ 1.5967e+00,  2.5880e-01, -6.9603e-01,  ..., -2.6975e-01,\n",
       "            5.2537e-01, -1.1624e+00],\n",
       "          ...,\n",
       "          [ 2.0592e+00,  1.1493e+00, -2.8494e+00,  ...,  8.3539e-01,\n",
       "            1.0478e+00, -2.4208e+00],\n",
       "          [-4.5564e-01, -5.2393e-01,  2.7099e+00,  ..., -1.2830e+00,\n",
       "            3.7036e+00,  4.0381e+00],\n",
       "          [ 6.1664e-01, -4.9046e-01,  1.1620e+00,  ..., -1.7505e+00,\n",
       "           -1.2100e-01,  3.7184e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.2833e+00, -1.0459e+00,  3.3787e+00,  ..., -9.6423e-01,\n",
       "            1.5633e+00,  1.4598e+00],\n",
       "          [-1.2167e+00,  8.9103e-01,  2.4325e+00,  ..., -7.5426e-01,\n",
       "            1.6070e+00,  3.7022e-01],\n",
       "          [-4.4735e-01,  1.0417e+00,  2.8858e+00,  ..., -1.7585e+00,\n",
       "            2.9903e+00, -5.7380e-01],\n",
       "          ...,\n",
       "          [-1.4322e+00,  2.4526e+00,  3.2064e+00,  ..., -2.3783e+00,\n",
       "            1.9071e+00, -2.6346e+00],\n",
       "          [ 1.2974e+00,  3.3997e+00, -1.1453e+00,  ..., -2.4457e-01,\n",
       "            1.1784e+00, -2.3365e+00],\n",
       "          [ 4.7620e-01,  2.1428e+00, -1.4891e+00,  ...,  2.7137e-01,\n",
       "           -3.0343e-01, -3.1710e+00]],\n",
       "\n",
       "         [[-1.2591e-02,  2.0113e+00, -7.8073e-01,  ...,  8.7968e-01,\n",
       "           -2.0864e+00,  1.0825e+00],\n",
       "          [-1.0682e+00, -4.9190e-01,  4.2019e-01,  ...,  4.2584e-01,\n",
       "           -2.9757e+00,  3.5815e-01],\n",
       "          [ 1.1351e+00, -8.8104e-01, -3.8163e-01,  ...,  1.0329e+00,\n",
       "           -2.7529e+00,  1.7498e+00],\n",
       "          ...,\n",
       "          [ 8.6233e-01,  1.7834e-01, -1.3233e+00,  ...,  1.6279e+00,\n",
       "           -3.3212e+00,  6.2304e-02],\n",
       "          [ 1.3533e+00, -1.6932e+00,  1.9259e+00,  ..., -5.4361e-01,\n",
       "           -3.3948e+00, -2.1263e+00],\n",
       "          [ 5.8726e-01,  8.6843e-01, -4.5038e-01,  ..., -1.6152e+00,\n",
       "           -4.0795e+00, -9.7703e-01]],\n",
       "\n",
       "         [[ 2.2971e+00, -1.2750e+00,  9.0844e-01,  ...,  2.6518e+00,\n",
       "            1.5014e+00,  4.1263e+00],\n",
       "          [ 2.0367e+00, -1.2453e+00,  1.3131e+00,  ...,  2.4211e+00,\n",
       "            3.7568e-01,  1.8307e+00],\n",
       "          [ 1.4749e+00, -2.0990e+00,  1.8046e+00,  ...,  1.5936e+00,\n",
       "            1.5150e+00,  1.2315e+00],\n",
       "          ...,\n",
       "          [ 4.6173e+00, -2.9603e+00, -1.0664e-01,  ...,  2.4984e+00,\n",
       "            1.9883e+00, -1.0881e-01],\n",
       "          [ 1.7224e+00, -3.0638e+00,  8.5503e-01,  ...,  1.4427e+00,\n",
       "           -1.4138e+00,  2.5029e+00],\n",
       "          [ 2.0793e+00, -2.3607e+00, -4.6661e-01,  ...,  1.3006e+00,\n",
       "           -1.0359e+00,  1.1424e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[ -2.5544,   3.1699,   0.0615,  ...,  -1.4190,  -1.5544,  -1.2950],\n",
       "          [ -1.9822,   2.4561,  -2.0760,  ...,  -2.8185,  -2.7076,   0.4923],\n",
       "          [ -0.2013,   1.1895,  -3.4356,  ...,  -0.4041,   1.3469,   0.6564],\n",
       "          ...,\n",
       "          [ -0.6476,   0.5621,  -1.0352,  ...,   0.5214,  -2.0133,  -0.2518],\n",
       "          [ -2.0268,   2.1243,  -6.1404,  ...,   2.7784,  -0.4050,  -2.0857],\n",
       "          [ -1.7997,   3.5227,  -5.3210,  ...,   1.4534,  -1.0500,  -2.3108]],\n",
       "\n",
       "         [[ -0.7812,   2.5726,  -5.2161,  ...,   1.0893,   0.0686,  -6.1709],\n",
       "          [  0.2652,   3.4632,  -0.6529,  ...,   1.2984,   1.2680,  -3.7370],\n",
       "          [ -1.6330,   1.6402,  -0.2593,  ...,  -1.9770,  -0.8636,  -4.1577],\n",
       "          ...,\n",
       "          [ -0.5628,  -0.3641,  -0.6457,  ...,   0.9276,   1.0119,  -3.6782],\n",
       "          [ -1.4165,   3.7889,   3.2012,  ...,   0.3104,   2.9704,   1.4295],\n",
       "          [  0.2775,   1.6060,   5.3715,  ...,  -0.5529,   2.5830,   0.0534]],\n",
       "\n",
       "         [[  9.3935,  -0.6226,   2.1945,  ...,  -1.5893,  -1.1770,   2.1368],\n",
       "          [  4.2216,  -1.0072,  -1.0346,  ...,  -3.0517,  -1.7762,   0.5218],\n",
       "          [  2.5592,   1.2134,  -0.5964,  ...,  -2.2248,   0.1514,  -0.3237],\n",
       "          ...,\n",
       "          [  0.2493,   1.1045,   1.6716,  ...,  -3.2793,  -0.8947,  -0.2851],\n",
       "          [-15.2796,   7.7760,   8.3826,  ...,  -4.6707,   1.8733,  -3.4545],\n",
       "          [-11.4158,  10.2926,   9.3904,  ...,  -5.2261,  -0.2430,  -2.6071]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -0.3104,  -3.7473,  -2.1538,  ...,  -0.8827,   0.7154,   4.3405],\n",
       "          [  0.4934,  -4.9358,  -0.5415,  ...,  -0.0546,   0.5551,   1.9459],\n",
       "          [ -1.2991,  -3.7416,  -0.1599,  ...,   1.1394,   1.2921,   2.1201],\n",
       "          ...,\n",
       "          [  0.2235,  -1.7749,  -1.7719,  ...,  -2.3594,   0.3308,   0.1320],\n",
       "          [ -1.8515,   0.9196,   0.4631,  ...,   2.4871,  -2.6950,   0.4941],\n",
       "          [  0.1683,   0.9795,  -1.2147,  ...,   1.2203,  -2.6605,   1.9469]],\n",
       "\n",
       "         [[  0.0395,   1.5529,   0.9597,  ...,  -0.2581,  -3.5136,  -0.3031],\n",
       "          [ -3.5916,   0.7582,   1.5228,  ...,   0.6170,  -1.6380,   0.6150],\n",
       "          [ -0.9471,   0.4487,   4.2354,  ...,  -0.3430,  -0.4676,   0.2787],\n",
       "          ...,\n",
       "          [ -3.8638,  -1.9569,   0.2820,  ...,   3.1406,  -1.2945,  -0.1027],\n",
       "          [  1.5356,   1.3406,   3.0756,  ...,  -0.7135,  -1.0511,  -2.0297],\n",
       "          [  1.8840,   2.2465,   3.0407,  ...,  -0.5398,  -1.0119,  -2.9853]],\n",
       "\n",
       "         [[ -1.6914,  -0.6751,  -1.2934,  ...,   0.3401,   0.4718,  -3.7633],\n",
       "          [ -3.1802,  -0.1438,  -2.3633,  ...,   2.3779,  -1.8367,  -2.0600],\n",
       "          [ -3.6437,  -1.0316,  -3.0165,  ...,   1.1059,  -0.7276,  -0.5337],\n",
       "          ...,\n",
       "          [ -3.4556,   0.6959,  -1.2363,  ...,   1.8204,  -1.0619,  -1.2330],\n",
       "          [  1.9150,  -0.1865,  -5.4254,  ...,  -1.7804,   1.6344,  -0.2892],\n",
       "          [  1.3172,  -0.8084,  -3.5765,  ...,  -0.4758,   2.0499,   1.1285]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 1.2670e+00,  7.7106e-02,  6.5424e+00,  ...,  5.3691e+00,\n",
       "           -8.7397e+00, -2.7730e+00],\n",
       "          [ 1.1981e+00,  6.3723e-01,  6.5897e+00,  ...,  4.4864e+00,\n",
       "           -6.8013e+00, -4.4410e+00],\n",
       "          [ 1.9237e+00,  5.7606e-01,  4.6318e+00,  ...,  3.7415e+00,\n",
       "           -8.0213e+00, -2.1127e+00],\n",
       "          ...,\n",
       "          [-4.1019e+00, -1.8163e+00,  6.3677e+00,  ...,  2.5784e+00,\n",
       "           -9.8605e+00, -7.1481e-01],\n",
       "          [-2.5899e+00, -1.3510e+00,  5.5337e+00,  ...,  1.5897e+00,\n",
       "           -9.7330e+00, -1.1574e+00],\n",
       "          [-1.2539e+00, -4.8982e-01, -3.3061e+00,  ..., -2.7064e+00,\n",
       "            3.8426e+00, -5.8641e-01]],\n",
       "\n",
       "         [[-2.3594e+00, -2.3887e-01, -1.9760e+00,  ...,  4.4857e+00,\n",
       "           -3.1949e+00, -1.6017e+00],\n",
       "          [-2.2711e+00, -1.9524e+00, -9.3284e-01,  ...,  4.0352e+00,\n",
       "           -9.1752e-01,  5.4378e-01],\n",
       "          [-1.6616e+00,  7.3631e-01, -4.8363e+00,  ...,  2.7683e+00,\n",
       "           -2.1469e+00, -1.7687e+00],\n",
       "          ...,\n",
       "          [-1.6110e+00, -4.0912e+00, -2.7915e+00,  ..., -1.0520e+00,\n",
       "           -1.5295e+00, -1.6522e+00],\n",
       "          [ 1.3356e+00, -2.5639e+00, -1.0235e-01,  ..., -2.8277e+00,\n",
       "           -2.4790e+00, -1.5450e+00],\n",
       "          [-3.9669e-01,  1.1464e+00, -3.3854e-01,  ...,  2.1851e-01,\n",
       "            1.4624e-01,  7.1099e-01]],\n",
       "\n",
       "         [[-3.1034e+00,  1.4929e+00, -2.2553e-01,  ..., -3.5260e+00,\n",
       "           -4.4921e+00, -1.7890e+00],\n",
       "          [-2.9171e+00, -1.8408e-01,  1.2738e+00,  ..., -3.0779e+00,\n",
       "           -4.2635e+00, -1.0824e+00],\n",
       "          [-2.2292e+00, -1.0637e+00,  2.0496e-01,  ..., -2.4251e+00,\n",
       "           -3.9005e+00, -1.7987e+00],\n",
       "          ...,\n",
       "          [-7.5863e-01,  1.1966e+00, -3.7278e-01,  ...,  2.5450e-01,\n",
       "           -3.0324e+00,  7.0738e-01],\n",
       "          [-2.3338e+00,  9.2873e-01,  6.9062e-01,  ...,  5.9798e-01,\n",
       "           -6.3279e+00, -3.0854e+00],\n",
       "          [ 1.2363e-01,  1.0312e+00, -5.1904e-01,  ..., -1.8684e+00,\n",
       "            3.8073e+00, -3.8176e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.9558e+00,  1.5022e+00, -1.7942e+00,  ...,  6.4794e+00,\n",
       "            3.1880e+00,  5.0046e+00],\n",
       "          [ 1.5109e+00,  1.1281e+00, -1.4866e+00,  ...,  3.1268e+00,\n",
       "            4.7501e+00,  5.5647e+00],\n",
       "          [ 3.3637e+00,  2.1789e+00, -2.3614e+00,  ...,  4.2744e+00,\n",
       "            3.9743e+00,  4.6946e+00],\n",
       "          ...,\n",
       "          [ 4.5086e+00, -4.9612e-01,  3.5371e-02,  ...,  4.2618e+00,\n",
       "            2.0888e+00,  6.0614e+00],\n",
       "          [ 2.1905e+00, -1.4848e+00, -1.2708e+00,  ...,  4.2684e+00,\n",
       "            1.8268e+00,  2.8038e+00],\n",
       "          [ 1.6655e+00, -3.2414e+00, -8.3735e-02,  ...,  5.7081e-02,\n",
       "            6.8896e-02,  2.1831e-01]],\n",
       "\n",
       "         [[ 7.3617e-01,  7.3217e-01,  2.7355e+00,  ..., -1.9624e+00,\n",
       "           -1.2456e+00,  1.2244e+00],\n",
       "          [ 1.3419e+00, -6.9393e-01,  2.4004e+00,  ..., -4.0998e+00,\n",
       "           -1.6373e+00,  1.6349e+00],\n",
       "          [-3.7189e-01,  7.9988e-01,  3.2599e+00,  ..., -2.6275e+00,\n",
       "            5.8222e-01,  4.9801e-01],\n",
       "          ...,\n",
       "          [-1.7263e+00,  2.9479e+00, -1.0964e+00,  ..., -4.7290e+00,\n",
       "           -1.3117e-01,  3.2020e+00],\n",
       "          [-4.1976e+00, -6.3537e-02, -1.4596e+00,  ..., -8.0453e+00,\n",
       "            3.4374e+00,  2.2201e+00],\n",
       "          [-5.9881e-01,  1.8941e+00, -2.0763e+00,  ...,  2.9717e+00,\n",
       "            8.8238e-01, -1.3291e+00]],\n",
       "\n",
       "         [[ 4.3955e+00,  2.7864e-01,  1.2025e+00,  ...,  3.0296e+00,\n",
       "            1.4654e+00,  3.6445e+00],\n",
       "          [ 2.6350e+00, -1.0082e+00, -6.3464e-01,  ...,  1.0751e+00,\n",
       "            1.6093e+00,  2.1630e+00],\n",
       "          [ 4.7438e+00,  1.5384e-01, -3.8035e-01,  ...,  1.6988e+00,\n",
       "            2.5142e+00,  5.7460e+00],\n",
       "          ...,\n",
       "          [ 6.5743e+00,  2.5417e+00, -1.5857e+00,  ...,  2.0580e+00,\n",
       "            5.1896e+00,  6.3333e+00],\n",
       "          [ 3.6818e+00,  2.8684e+00,  6.1809e-01,  ...,  2.3757e+00,\n",
       "            4.3144e+00,  5.6574e+00],\n",
       "          [-1.3085e-01, -4.0082e-03, -1.3586e+00,  ...,  6.5539e-02,\n",
       "            8.5407e-01, -8.1153e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-2.4001e-01, -1.3556e+00, -2.8128e+00,  ...,  2.2722e+00,\n",
       "           -1.5838e+00,  1.0226e+00],\n",
       "          [ 2.9804e+00, -4.6391e+00, -1.9507e+00,  ..., -3.3670e-01,\n",
       "            1.0973e+00, -1.2176e+00],\n",
       "          [ 1.4144e+00, -1.4374e+00, -7.6458e-01,  ...,  1.7498e+00,\n",
       "            5.3277e-01,  3.7648e-01],\n",
       "          ...,\n",
       "          [-7.4273e-01, -2.5910e+00, -3.6013e+00,  ...,  1.2170e+00,\n",
       "            2.4390e+00,  3.6217e+00],\n",
       "          [ 5.1199e-01,  1.5166e+00, -2.1390e+00,  ...,  5.9656e-01,\n",
       "            1.9878e+00,  7.9299e-01],\n",
       "          [ 4.0489e-02,  1.7769e-01,  8.5580e-02,  ...,  8.1313e-03,\n",
       "            2.0614e-01,  3.5289e-03]],\n",
       "\n",
       "         [[ 3.9871e+00,  3.4919e+00,  2.5414e-01,  ..., -1.2949e+00,\n",
       "            3.8591e-01,  8.7124e-01],\n",
       "          [ 2.0807e+00,  1.0499e+00,  2.6887e+00,  ..., -2.3713e+00,\n",
       "           -1.8119e-01,  6.1857e+00],\n",
       "          [ 4.3021e+00,  2.3336e+00,  4.0460e-01,  ..., -1.9367e+00,\n",
       "           -1.2204e+00, -1.2500e-01],\n",
       "          ...,\n",
       "          [ 9.1679e-01,  1.5477e+00,  1.2871e+00,  ..., -1.0151e+00,\n",
       "            3.7674e-01, -8.6065e-01],\n",
       "          [-1.9210e+00,  1.5537e+00,  9.3919e-01,  ..., -1.3021e-01,\n",
       "            6.2125e-01,  8.8265e-01],\n",
       "          [ 7.1845e-02,  2.2057e-01, -4.2603e-01,  ..., -1.5354e-01,\n",
       "            1.8153e-01, -3.0486e-01]],\n",
       "\n",
       "         [[ 1.8621e+00,  6.4457e-01,  4.0988e-01,  ..., -3.3155e+00,\n",
       "           -2.2182e+00,  2.3535e+00],\n",
       "          [-1.6245e-02,  1.3723e+00,  6.2030e-01,  ..., -3.3249e+00,\n",
       "           -3.2952e+00, -2.9677e+00],\n",
       "          [ 2.6581e-01, -1.0308e+00,  1.7345e+00,  ..., -4.1023e+00,\n",
       "           -1.4720e+00,  2.8813e-01],\n",
       "          ...,\n",
       "          [-1.5707e-01, -1.4337e+00,  1.0851e+00,  ..., -1.8485e+00,\n",
       "            6.1063e-01,  4.4758e+00],\n",
       "          [-1.8918e+00,  1.1366e+00,  1.9445e+00,  ..., -4.4377e+00,\n",
       "            3.0435e+00,  2.2879e-01],\n",
       "          [ 1.2830e-01, -1.9230e-01, -1.7972e-01,  ..., -1.6713e-01,\n",
       "            2.1091e-02,  6.8506e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.2800e+00, -3.2649e+00,  2.0160e+00,  ..., -2.6966e+00,\n",
       "           -3.0269e-01, -3.2353e+00],\n",
       "          [ 2.9111e-01, -2.7149e+00,  2.3443e+00,  ..., -6.7063e-01,\n",
       "            1.8604e+00, -2.0543e+00],\n",
       "          [-1.2669e+00, -3.0569e+00, -9.0662e-01,  ..., -4.4456e-01,\n",
       "            1.8835e+00, -7.9633e-01],\n",
       "          ...,\n",
       "          [-2.3324e+00,  2.1633e+00, -1.6794e+00,  ...,  2.9628e+00,\n",
       "           -3.3689e-02, -1.7153e+00],\n",
       "          [ 3.8697e-01, -7.3027e-02, -6.4807e-01,  ...,  8.3894e-01,\n",
       "           -1.7554e+00, -1.2395e+00],\n",
       "          [ 1.5563e-01,  6.3079e-02,  1.2977e-01,  ...,  9.7491e-02,\n",
       "           -4.0183e-02,  1.1346e-01]],\n",
       "\n",
       "         [[ 1.8166e-01, -6.6798e-01,  7.4892e-01,  ...,  2.2397e+00,\n",
       "            2.0432e+00,  1.0729e-01],\n",
       "          [-2.3513e+00, -1.0271e+00,  1.1463e-01,  ...,  1.2923e+00,\n",
       "            6.9740e-01,  3.4237e+00],\n",
       "          [-1.6814e+00, -1.6300e+00,  1.0139e+00,  ...,  4.5256e-01,\n",
       "            1.4348e+00, -6.3927e-01],\n",
       "          ...,\n",
       "          [ 8.9820e-01, -1.2411e+00,  1.8732e+00,  ...,  6.5927e-01,\n",
       "           -3.1817e+00,  4.5405e-01],\n",
       "          [ 2.5372e+00, -9.0560e-01, -2.1982e-01,  ...,  1.9611e+00,\n",
       "            2.4977e+00,  1.6598e+00],\n",
       "          [-8.4550e-02, -2.0262e-01,  3.1853e-01,  ...,  3.7384e-01,\n",
       "            9.3355e-02,  2.8639e-01]],\n",
       "\n",
       "         [[ 3.7145e+00, -1.1968e+00,  3.2190e+00,  ..., -2.1974e+00,\n",
       "            2.8301e+00, -2.0383e+00],\n",
       "          [ 2.9639e+00,  5.1463e-01, -1.5166e+00,  ..., -2.2499e-01,\n",
       "            1.0702e-01, -4.0218e+00],\n",
       "          [ 4.2530e+00, -1.5676e+00,  1.4122e+00,  ..., -3.7230e-01,\n",
       "            2.9737e+00, -7.1899e-01],\n",
       "          ...,\n",
       "          [-3.7533e-01, -2.0644e+00,  1.4940e+00,  ...,  4.5644e-01,\n",
       "            3.0375e+00, -3.8001e+00],\n",
       "          [ 1.2594e+00, -3.2806e+00,  3.7636e+00,  ...,  1.1171e+00,\n",
       "            2.6980e+00,  2.1341e+00],\n",
       "          [-1.0177e-01, -1.1872e-02,  2.0289e-01,  ..., -3.5602e-01,\n",
       "           -5.9181e-03, -3.7948e-02]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[-0.6017, -0.6354, -2.0780,  ...,  0.6172,  0.8930, -0.5896],\n",
       "          [-1.0337, -0.6843, -2.9374,  ...,  0.6350, -0.3958, -1.3033],\n",
       "          [ 0.0612, -2.0622, -3.4032,  ..., -0.3794,  0.2168,  0.2369],\n",
       "          ...,\n",
       "          [ 1.2187, -1.0306, -4.1608,  ..., -1.6530, -0.0939, -0.0654],\n",
       "          [ 0.8394,  1.2730, -0.6768,  ..., -2.8819, -0.4075,  3.7696],\n",
       "          [-0.0741,  0.8712, -0.3814,  ..., -1.8255, -1.4454,  4.9574]],\n",
       "\n",
       "         [[ 2.1067, -1.7726, -1.7566,  ...,  0.1554,  0.4296,  0.6068],\n",
       "          [ 0.4949, -0.9899, -0.2883,  ..., -0.4764,  2.0366,  0.7150],\n",
       "          [ 0.6493, -0.8380, -0.9456,  ..., -0.9347,  1.4174, -0.3664],\n",
       "          ...,\n",
       "          [ 0.6383, -1.2761, -1.2673,  ..., -0.9661,  2.5451, -0.8401],\n",
       "          [-1.9364,  0.2805, -1.8575,  ..., -5.4404,  3.0580, -0.5254],\n",
       "          [-2.6806, -0.2608, -1.2364,  ..., -4.0593,  3.6123, -0.7656]],\n",
       "\n",
       "         [[ 0.0156, -0.4162, -1.0030,  ..., -0.5430,  0.4739,  0.6688],\n",
       "          [-0.2271, -0.2740, -1.0391,  ...,  0.5809,  0.0637,  0.0528],\n",
       "          [ 1.1637, -0.4655, -1.8163,  ..., -0.3840, -0.0707, -0.5531],\n",
       "          ...,\n",
       "          [ 1.0135,  0.9204, -0.9778,  ...,  0.6921, -0.1349, -1.0400],\n",
       "          [-1.8176, -1.1382, -1.7153,  ...,  2.8944,  0.6866, -0.0454],\n",
       "          [ 0.1022, -2.1296, -2.6522,  ...,  0.3287, -0.9987, -0.9836]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3246,  1.5468, -2.0522,  ..., -1.1224,  0.9304, -0.5994],\n",
       "          [-0.5722,  0.7943, -4.4312,  ..., -2.5723,  0.9298, -1.8004],\n",
       "          [-1.1856,  1.6314, -4.3772,  ..., -0.7618,  1.0973, -1.8198],\n",
       "          ...,\n",
       "          [-1.6150,  0.9986, -4.9932,  ..., -0.1961,  1.1870, -2.2683],\n",
       "          [-1.6778,  3.4239, -4.2088,  ..., -0.9665,  1.9684, -0.0184],\n",
       "          [-2.5537,  1.7549, -4.0847,  ..., -0.2451,  1.3579, -0.4303]],\n",
       "\n",
       "         [[ 0.0113,  0.6448, -2.7806,  ...,  0.8224, -1.2611, -1.5319],\n",
       "          [-0.6962,  1.1553, -2.2052,  ..., -0.1027, -1.2191, -1.6328],\n",
       "          [-0.8732,  0.5366, -2.5321,  ...,  1.3185, -1.3511, -2.4861],\n",
       "          ...,\n",
       "          [-1.2431, -0.6782, -1.1090,  ...,  1.0856, -0.9698, -1.8485],\n",
       "          [-0.2998, -0.0760, -3.1192,  ..., -1.4886,  0.9932, -2.2239],\n",
       "          [ 0.6267,  0.0207, -3.1230,  ..., -1.2564,  0.7315, -0.7155]],\n",
       "\n",
       "         [[ 1.8304, -1.9122,  0.2565,  ..., -0.7270,  1.2454,  0.2581],\n",
       "          [ 1.1921, -0.1944,  0.1385,  ..., -1.0292,  0.9663,  0.3479],\n",
       "          [ 0.3037, -0.6818,  0.0360,  ..., -1.2298,  1.9825, -1.3089],\n",
       "          ...,\n",
       "          [-0.6047, -2.7652, -0.2908,  ..., -0.1856,  0.6137, -1.1414],\n",
       "          [-0.4844, -2.9498, -1.7169,  ...,  0.0278, -1.2941, -4.9217],\n",
       "          [-1.6909, -1.9927, -0.6565,  ..., -1.6679, -0.8651, -3.6539]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[  1.3767,   2.1281,  -6.5034,  ...,   2.2034,  -1.1037,   1.0988],\n",
       "          [  0.0942,   3.4307,  -5.2893,  ...,   2.4542,  -1.4980,   2.3837],\n",
       "          [  1.8780,   2.4414,  -3.6503,  ...,   0.4371,  -0.7045,   0.1272],\n",
       "          ...,\n",
       "          [  0.2370,   2.7870,  -0.9506,  ...,   0.4886,   0.4612,  -0.7027],\n",
       "          [ -4.7972,   0.9327,  -0.5545,  ...,  -2.0353,   1.7501,  -0.9567],\n",
       "          [ -4.0590,   0.8505,  -1.3568,  ...,  -2.3059,   1.5734,   2.4952]],\n",
       "\n",
       "         [[ -2.1872,  -0.7488,  -5.2115,  ...,  -7.6552,  -5.7468,  -3.3527],\n",
       "          [ -6.2306,  -2.6711,  -5.0659,  ...,  -5.5381,  -2.7442,  -3.2773],\n",
       "          [ -4.4375,   2.3054,  -5.3596,  ...,  -3.5434,  -2.0463,   1.1395],\n",
       "          ...,\n",
       "          [ -4.0349,   0.8892,   0.0171,  ...,  -4.2194,  -3.8665,  -0.7705],\n",
       "          [ -0.7570, -11.4068,  -4.9613,  ...,  -8.9358,   2.9802,  -4.2737],\n",
       "          [ -2.3076,  -6.5860,  -2.6080,  ...,  -6.7432,   2.3511,  -4.6032]],\n",
       "\n",
       "         [[  3.2581,  -3.0790,  -0.2921,  ...,   0.1829,  -4.3296,   0.9168],\n",
       "          [  2.6947,   0.6854,   0.8030,  ...,   0.5195,  -5.4537,   1.1419],\n",
       "          [  2.2481,  -0.0925,  -0.1661,  ...,  -0.6361,  -4.9181,   1.1640],\n",
       "          ...,\n",
       "          [  3.0512,  -0.3576,   0.1709,  ...,   1.5490,  -3.5878,  -2.0671],\n",
       "          [  1.7967,   3.7208,   4.9428,  ...,   2.4103,   1.0258,  -6.7245],\n",
       "          [  4.6943,   3.5335,   1.9944,  ...,   2.0026,  -2.2245,  -2.7678]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[  5.8643,  -0.1549,  -1.1151,  ...,   0.3882,   1.1755,   2.6559],\n",
       "          [  8.7918,   1.2631,  -1.5376,  ...,   2.4793,   0.9598,   0.4571],\n",
       "          [  5.1148,   0.2121,   0.5986,  ...,   2.7496,   0.4796,  -0.5982],\n",
       "          ...,\n",
       "          [  5.8896,   2.3985,   2.8559,  ...,   1.3141,   2.6446,   1.6654],\n",
       "          [  8.3678,   2.8946,  -3.3614,  ...,   4.1513,  -6.0636,   0.2862],\n",
       "          [  5.1515,   1.2559,  -3.5833,  ...,   2.0276,  -5.8758,   0.2998]],\n",
       "\n",
       "         [[  0.7258,  -4.7275,   6.6818,  ...,   4.1909,   4.6900,  -2.9190],\n",
       "          [ -2.7078,  -5.1817,   4.2829,  ...,   4.1366,   5.6751,  -0.7006],\n",
       "          [ -0.0956,  -2.2882,   5.7500,  ...,   5.3943,   5.0726,  -0.7231],\n",
       "          ...,\n",
       "          [ -0.2946,  -2.0065,   2.5038,  ...,   6.2931,   4.4320,  -0.7378],\n",
       "          [ -6.6851,  -4.2884,   7.6969,  ...,   5.2500,   2.0566,   1.0296],\n",
       "          [  1.2339,  -9.2425,   3.3854,  ...,   1.5170,   5.0037,  -0.0714]],\n",
       "\n",
       "         [[ -0.9507,   0.0671,   1.6085,  ...,  -1.3850,  -3.1481,  -1.4559],\n",
       "          [ -0.6699,   2.3970,   1.6685,  ...,  -2.3494,  -2.0776,  -2.2992],\n",
       "          [ -1.2942,   2.5876,   0.9428,  ...,  -3.1958,  -3.5663,  -0.3317],\n",
       "          ...,\n",
       "          [ -2.6742,   2.8074,   0.4373,  ...,  -1.4652,  -0.9269,  -0.0468],\n",
       "          [ -0.5993,  -3.6290,  -1.5576,  ...,  -2.8453,   5.8002,  -5.0530],\n",
       "          [ -1.8233,   1.2244,  -2.1212,  ...,   1.8806,   2.8611,  -6.1354]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[  1.8189,  -4.9687,  -3.1782,  ...,   3.9072,  -0.2230,   1.1264],\n",
       "          [ -2.3838,  -7.2392,  -0.4939,  ...,   5.0049,   1.2571,  -0.4084],\n",
       "          [  2.0217,  -4.8518,   0.0564,  ...,   3.1754,   0.0577,   0.4777],\n",
       "          ...,\n",
       "          [  0.7155,  -5.1987,   3.4255,  ...,   2.8374,  -1.4807,  -1.2620],\n",
       "          [  0.5699,  -7.3133,  -0.1386,  ...,   0.2662,  -4.7662,   0.6672],\n",
       "          [  0.6298,   4.9551,   0.3806,  ...,  -3.4856,   1.0552,   0.6277]],\n",
       "\n",
       "         [[ -9.1704,   5.9099,  -1.9033,  ...,  -1.0577,   2.5498,   2.6515],\n",
       "          [-11.4888,   6.2232,   2.5215,  ...,  -2.3696,   5.0327,   4.8295],\n",
       "          [ -9.1919,   5.8912,  -1.6387,  ...,  -0.1911,   3.1040,   1.9297],\n",
       "          ...,\n",
       "          [ -7.1524,   1.8629,  -3.2733,  ...,   0.0827,  -0.1066,   1.1414],\n",
       "          [ -9.0891,   3.8939,  -0.5662,  ...,  -2.0881,   1.8289,   1.6810],\n",
       "          [  4.7756,  -1.6940,  -0.8880,  ...,  -0.2297,  -0.8767,   1.7286]],\n",
       "\n",
       "         [[  1.9670,  -0.8408,   1.9723,  ...,  -0.1413,   0.3308,   3.5481],\n",
       "          [  0.6027,   1.5915,   3.5556,  ...,  -0.4878,  -2.9673,   0.8055],\n",
       "          [ -0.5028,   0.4809,   3.7833,  ...,   1.0581,  -1.8660,   4.8926],\n",
       "          ...,\n",
       "          [  5.3855,  -1.4387,   2.5333,  ...,  -1.1666,   0.2058,   2.9599],\n",
       "          [  6.3652,  -2.0228,  -0.5114,  ...,   0.4504,   0.3204,  -0.2638],\n",
       "          [ -1.3315,   1.3489,  -0.3799,  ...,   2.4118,  -0.4873,  -0.2800]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -1.0703,   3.3408,  -4.8136,  ...,  -1.2613,   1.8749,   7.1419],\n",
       "          [ -2.2702,   2.8029,  -3.2561,  ...,  -1.3700,   1.7312,  10.6810],\n",
       "          [ -2.3349,   1.7293,  -2.0023,  ...,  -0.0641,   0.5312,   5.5270],\n",
       "          ...,\n",
       "          [ -5.0176,   3.9427,  -3.8588,  ...,   2.2646,   3.0636,   1.6397],\n",
       "          [ -4.2406,   5.4938,  -1.0521,  ...,   0.3912,   0.3050,   4.4444],\n",
       "          [  1.2416,   0.7736,  -0.8019,  ...,   1.2011,  -0.8575,  -0.2564]],\n",
       "\n",
       "         [[ -3.2078,  -5.6013,   2.0068,  ...,   1.6248,  -1.4048,  -4.8140],\n",
       "          [ -1.6140,  -4.2477,   0.9797,  ...,   0.3888,  -0.8002,  -2.5849],\n",
       "          [ -1.2866,  -3.8914,   1.2810,  ...,   0.2885,  -1.7059,  -1.8438],\n",
       "          ...,\n",
       "          [ -0.8604,  -5.4500,   2.3741,  ...,  -3.0908,   4.0658,  -0.8349],\n",
       "          [  0.7985,  -3.8988,   3.2160,  ...,   1.5162,   5.8441,  -1.9895],\n",
       "          [ -0.2384,  -0.1688,  -1.0694,  ...,   0.7115,   0.9832,   0.4007]],\n",
       "\n",
       "         [[  0.5506,  -1.2014,  -5.7226,  ...,  -2.5908,   0.2653,   1.6647],\n",
       "          [ -5.7319,  -3.1456,  -6.3346,  ...,   2.6367,   4.6972,   2.1795],\n",
       "          [ -5.5106,  -2.1375,  -3.8534,  ...,  -2.2768,   0.0553,   2.6388],\n",
       "          ...,\n",
       "          [ -0.7889,  -4.1291,  -1.5548,  ...,  -0.4781,   3.3191,  -0.9133],\n",
       "          [ -1.1773,  -0.6629,   1.7751,  ...,  -5.3903,  -5.4701,  -2.0870],\n",
       "          [  1.2511,   0.9242,  -0.5441,  ...,   0.1607,   0.2014,   0.8132]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[-3.8626e+00,  1.3735e+00, -1.3826e+00,  ..., -2.3493e+00,\n",
       "            1.7107e-01, -3.2190e+00],\n",
       "          [-3.0788e+00,  2.2724e+00, -1.0841e-01,  ..., -4.4956e+00,\n",
       "           -6.5224e-01, -3.0483e+00],\n",
       "          [-3.1532e+00, -1.2640e+00, -3.7868e-01,  ..., -2.0746e+00,\n",
       "           -1.6292e+00, -5.4269e+00],\n",
       "          ...,\n",
       "          [ 1.8803e+00, -3.5615e+00,  2.4341e+00,  ..., -3.4423e+00,\n",
       "           -1.0645e+00,  9.1629e-01],\n",
       "          [ 6.6370e-01,  2.9114e+00,  2.4896e+00,  ...,  1.5135e+00,\n",
       "           -2.9158e+00,  1.8457e+00],\n",
       "          [-2.5187e-01, -1.7584e-01, -4.1146e-01,  ...,  3.8053e-01,\n",
       "           -2.0780e-01,  2.1818e-01]],\n",
       "\n",
       "         [[-3.0335e+00, -2.7895e+00, -1.4424e+00,  ..., -2.9807e+00,\n",
       "            4.4646e+00, -4.5222e+00],\n",
       "          [-1.6923e+00, -2.4149e+00,  1.0485e+00,  ..., -1.7866e+00,\n",
       "           -2.2991e+00, -5.4835e-01],\n",
       "          [ 1.2170e+00,  1.1666e+00,  4.7965e+00,  ..., -3.7673e-01,\n",
       "            3.6913e+00,  7.5893e-01],\n",
       "          ...,\n",
       "          [-2.9364e+00,  2.5253e+00, -5.3740e-02,  ..., -1.3671e-01,\n",
       "            2.3123e+00, -2.4439e+00],\n",
       "          [ 1.1147e+00,  9.2223e-01, -1.2509e+00,  ..., -3.1256e+00,\n",
       "           -3.0736e+00,  8.2452e-02],\n",
       "          [ 2.9746e-01,  3.1472e-02, -1.4720e-01,  ..., -4.4605e-01,\n",
       "            6.9530e-02,  3.2829e-01]],\n",
       "\n",
       "         [[-1.1374e+00,  2.2222e+00,  3.6880e+00,  ...,  4.5141e+00,\n",
       "            2.0776e+00,  2.2333e+00],\n",
       "          [ 2.7091e+00,  2.8722e+00, -9.0256e-01,  ...,  1.6201e+00,\n",
       "            1.5445e+00,  1.5726e+00],\n",
       "          [ 1.7542e+00,  7.4634e-01,  3.7260e+00,  ...,  6.9419e-01,\n",
       "            3.8126e+00,  6.6197e-01],\n",
       "          ...,\n",
       "          [ 1.2578e+00,  2.5289e-01, -1.1476e+00,  ...,  1.2434e+00,\n",
       "           -2.4682e+00,  1.9675e+00],\n",
       "          [ 1.9719e+00, -3.7607e+00,  7.4558e-01,  ..., -1.0156e-01,\n",
       "            4.4967e+00,  4.0285e-01],\n",
       "          [-3.2537e-01, -6.6694e-02, -1.2821e+00,  ..., -5.3603e-01,\n",
       "           -4.5198e-01,  3.0560e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.9195e+00, -3.4288e+00, -1.8916e+00,  ..., -9.9738e-01,\n",
       "            3.0394e+00, -1.3826e+00],\n",
       "          [-1.0234e+00,  3.5946e+00,  1.8486e+00,  ..., -4.1092e+00,\n",
       "            3.8563e+00, -1.4875e+00],\n",
       "          [-3.8973e-02, -2.1755e+00, -2.6914e-01,  ..., -2.2486e+00,\n",
       "            2.1810e+00, -3.8847e+00],\n",
       "          ...,\n",
       "          [ 2.6311e+00,  1.3969e+00, -1.9048e+00,  ...,  3.1221e+00,\n",
       "           -3.4020e+00, -2.7335e+00],\n",
       "          [-2.1969e+00, -1.0164e+00,  2.4258e+00,  ...,  1.4826e-01,\n",
       "           -3.0785e+00, -1.6802e+00],\n",
       "          [-5.0104e-02,  7.3037e-02,  3.7272e-01,  ...,  2.2001e-01,\n",
       "            2.0834e-01, -1.4310e-01]],\n",
       "\n",
       "         [[ 2.7059e-02, -4.4814e+00,  4.1948e+00,  ..., -1.7910e+00,\n",
       "           -2.3494e+00,  6.3145e+00],\n",
       "          [-3.7889e-01,  1.1809e-01, -5.3908e+00,  ..., -2.7461e+00,\n",
       "            1.0407e+00,  8.7570e-01],\n",
       "          [ 2.5146e+00, -2.4266e+00, -1.8860e+00,  ..., -3.8861e-01,\n",
       "            1.7966e-01,  1.0299e+00],\n",
       "          ...,\n",
       "          [ 3.5783e+00, -3.0011e+00,  5.2220e+00,  ..., -3.1903e+00,\n",
       "           -3.1105e+00, -2.9250e+00],\n",
       "          [-1.5747e+00, -1.7579e+00,  1.6777e+00,  ...,  2.1915e-01,\n",
       "            1.2557e+00,  1.5056e-01],\n",
       "          [-1.0160e-01, -2.2126e-01, -2.8371e-01,  ..., -1.9320e-01,\n",
       "            2.4745e-01, -1.8195e-01]],\n",
       "\n",
       "         [[ 1.6179e+00, -1.0714e+00, -2.2361e+00,  ..., -2.1169e+00,\n",
       "            5.9053e+00, -2.0755e+00],\n",
       "          [ 1.5765e+00, -4.3896e-01,  3.5479e+00,  ...,  1.5472e+00,\n",
       "           -1.8381e+00,  5.3135e-01],\n",
       "          [ 1.3645e+00,  1.9606e-01,  1.8218e+00,  ...,  5.6455e+00,\n",
       "            1.4126e+00,  1.1279e+00],\n",
       "          ...,\n",
       "          [-1.3710e+00,  7.0376e-01, -1.5489e+00,  ...,  3.3524e+00,\n",
       "           -2.1265e+00,  3.1108e+00],\n",
       "          [ 2.5204e+00, -2.9957e+00,  2.1203e+00,  ...,  1.5333e+00,\n",
       "           -2.4534e+00,  2.1263e-01],\n",
       "          [-6.1836e-02,  1.0400e-01,  5.8884e-03,  ...,  7.1635e-02,\n",
       "            2.5498e-02,  1.2916e-01]]]], grad_fn=<TransposeBackward0>)), (tensor([[[[-3.0504e+00,  2.4627e+00, -2.6970e+00,  ...,  6.9374e-01,\n",
       "           -3.5648e-01, -1.3282e+00],\n",
       "          [-2.6558e+00,  1.7082e+00, -1.1176e+00,  ...,  1.7820e+00,\n",
       "           -3.9916e-01, -1.6888e+00],\n",
       "          [-1.1716e+00,  1.9033e+00, -2.4487e+00,  ...,  2.0759e+00,\n",
       "           -5.6660e-01,  5.9637e-02],\n",
       "          ...,\n",
       "          [-2.1394e+00,  1.2251e+00, -9.7093e-01,  ..., -1.1202e+00,\n",
       "            6.6362e-01, -1.0255e+00],\n",
       "          [-1.8122e+00,  7.7789e-01,  2.0058e-01,  ..., -2.5620e+00,\n",
       "           -1.6879e-02, -1.1640e-01],\n",
       "          [-9.9056e-01, -8.8380e-01,  6.8553e-01,  ..., -2.2866e+00,\n",
       "            6.6660e-01, -1.1445e+00]],\n",
       "\n",
       "         [[ 2.3084e+00,  2.4519e+00, -1.6881e+00,  ...,  1.7631e+00,\n",
       "            2.0830e-01, -2.6176e+00],\n",
       "          [ 2.5153e+00,  2.4308e+00, -2.6428e-01,  ...,  1.4745e+00,\n",
       "           -1.8622e-01, -2.2159e+00],\n",
       "          [ 1.3122e+00,  1.4626e+00,  8.7927e-01,  ...,  7.5241e-01,\n",
       "           -1.3658e+00, -1.5562e+00],\n",
       "          ...,\n",
       "          [ 1.3334e+00,  6.1086e-01,  1.2339e+00,  ...,  3.0144e-01,\n",
       "           -1.4365e+00, -1.3579e+00],\n",
       "          [ 1.2137e+00,  1.3400e+00, -9.0715e-02,  ..., -2.4552e+00,\n",
       "           -1.0426e+00,  2.5414e-01],\n",
       "          [ 1.4880e+00,  2.8607e+00, -4.5310e-01,  ..., -2.3126e+00,\n",
       "           -1.1877e+00,  9.0463e-01]],\n",
       "\n",
       "         [[ 9.6522e-01, -1.6142e-01, -1.3535e+00,  ..., -1.9485e-01,\n",
       "            3.2849e+00,  4.6037e-01],\n",
       "          [ 1.6111e-01, -8.4431e-01, -2.5159e+00,  ..., -3.6397e-01,\n",
       "            3.7665e+00, -9.9834e-01],\n",
       "          [-1.8681e-01, -5.4636e-01, -1.6605e+00,  ..., -2.6602e-01,\n",
       "            3.1266e+00,  1.1660e+00],\n",
       "          ...,\n",
       "          [-2.0186e+00,  5.4555e-01, -4.1254e-01,  ..., -2.2367e+00,\n",
       "            3.6175e+00, -2.1601e+00],\n",
       "          [-2.4971e+00,  6.0008e-01,  4.9876e-01,  ..., -5.7164e-01,\n",
       "            1.5472e+00, -2.1374e-01],\n",
       "          [-1.7149e+00,  7.7867e-01,  1.3115e+00,  ..., -2.4475e+00,\n",
       "            5.7614e-01, -8.2245e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.4949e-01,  3.2351e-01, -5.9704e-01,  ...,  4.2178e+00,\n",
       "           -3.2884e-01,  5.3012e+00],\n",
       "          [-2.1943e+00,  6.5921e-01, -8.6167e-01,  ...,  3.7607e+00,\n",
       "           -1.0074e+00,  4.0927e+00],\n",
       "          [-8.4044e-01, -5.6618e-01, -1.5233e+00,  ...,  3.0794e+00,\n",
       "           -1.1711e+00,  3.5536e+00],\n",
       "          ...,\n",
       "          [-2.0177e+00, -3.8072e-01, -2.9628e-01,  ...,  3.0070e+00,\n",
       "           -2.2738e+00,  9.5085e-01],\n",
       "          [ 1.1196e+00,  9.1928e-01, -3.3867e+00,  ...,  2.8009e+00,\n",
       "           -1.4393e+00,  1.8446e-02],\n",
       "          [ 3.1068e+00, -2.1366e-01, -2.4396e+00,  ...,  1.1528e+00,\n",
       "           -9.0555e-01, -5.6636e-01]],\n",
       "\n",
       "         [[ 2.1078e-01, -4.8630e-01,  1.2407e+00,  ...,  6.5164e-01,\n",
       "           -2.2552e+00,  1.4819e+00],\n",
       "          [-1.7899e-01, -2.1805e+00,  1.6213e+00,  ..., -4.4784e-01,\n",
       "           -3.4794e+00,  1.9624e+00],\n",
       "          [-1.1745e+00, -1.1204e+00,  2.0186e+00,  ...,  1.0289e-01,\n",
       "           -3.6872e+00,  2.0427e+00],\n",
       "          ...,\n",
       "          [ 8.5047e-01, -2.8524e+00,  1.5318e+00,  ..., -1.0116e+00,\n",
       "           -5.2771e+00,  2.4924e+00],\n",
       "          [-6.7045e-03, -1.8607e+00,  4.0854e-01,  ...,  3.0059e+00,\n",
       "            3.0999e+00,  1.2924e+00],\n",
       "          [ 1.9534e-01, -3.0829e+00,  2.2320e-01,  ...,  2.7423e+00,\n",
       "            4.1264e+00, -2.0816e-01]],\n",
       "\n",
       "         [[ 1.1582e-01,  1.6124e+00, -7.9030e+00,  ..., -2.8780e-01,\n",
       "            8.6523e-01,  1.0872e+00],\n",
       "          [-1.2536e+00,  2.8613e+00, -8.5394e+00,  ..., -2.0338e+00,\n",
       "           -9.4300e-01,  9.5962e-01],\n",
       "          [-1.2875e+00,  2.6374e+00, -8.0332e+00,  ..., -2.2400e+00,\n",
       "           -6.3103e-01,  1.0845e+00],\n",
       "          ...,\n",
       "          [-8.4872e-01,  4.0308e-01, -1.1523e+01,  ..., -1.3195e+00,\n",
       "           -9.0914e-01,  6.6225e-01],\n",
       "          [ 1.1667e+00, -4.1949e-01, -1.0737e+01,  ..., -1.1797e+00,\n",
       "            3.7502e+00,  2.4695e+00],\n",
       "          [ 1.5608e+00,  7.8846e-01, -1.0321e+01,  ..., -3.1616e+00,\n",
       "            3.2199e+00,  8.4403e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-3.4941e+00,  8.1734e-01,  2.0354e-01,  ..., -2.6604e+00,\n",
       "           -3.2849e+00, -1.9355e+00],\n",
       "          [-2.9531e+00,  1.8180e+00,  3.3738e-01,  ...,  1.0165e-01,\n",
       "           -1.4334e+00,  3.8658e-01],\n",
       "          [-4.1727e-01, -2.4405e+00,  2.9936e-01,  ...,  1.0397e+00,\n",
       "           -2.9355e+00, -1.0472e+00],\n",
       "          ...,\n",
       "          [ 1.4834e+00,  1.0371e+00,  1.5686e+00,  ...,  7.8583e-01,\n",
       "            1.3348e+00, -2.1226e+00],\n",
       "          [-2.2818e+00,  9.0756e-01,  2.4436e+00,  ...,  1.7112e+00,\n",
       "            3.7785e-01, -5.7423e-01],\n",
       "          [ 1.1612e-01, -9.8547e-01, -1.1765e+00,  ...,  8.8246e-01,\n",
       "            3.8549e+00, -2.9024e-01]],\n",
       "\n",
       "         [[-1.3246e+00, -1.6933e+00,  3.1287e+00,  ..., -3.1436e+00,\n",
       "            2.7728e+00, -3.0706e+00],\n",
       "          [-9.1784e-01, -3.7211e+00,  7.6537e-01,  ..., -2.6358e+00,\n",
       "            9.4707e-01, -2.7190e+00],\n",
       "          [ 8.8504e-02, -3.7183e+00, -6.8026e-01,  ...,  6.2997e-01,\n",
       "           -1.2806e+00, -1.8795e+00],\n",
       "          ...,\n",
       "          [-9.1070e-01, -2.5491e+00, -4.7700e+00,  ..., -1.9422e+00,\n",
       "           -5.7094e+00, -1.2178e+00],\n",
       "          [ 2.9674e+00, -1.7125e+00,  9.3472e-01,  ...,  2.6658e-01,\n",
       "           -2.1496e+00,  1.9100e+00],\n",
       "          [ 1.6310e+00, -3.7471e-01, -2.7734e+00,  ...,  3.0370e-01,\n",
       "           -2.7431e+00,  3.7747e+00]],\n",
       "\n",
       "         [[-2.0414e+00,  6.5991e+00, -8.6563e+00,  ..., -5.6037e+00,\n",
       "            4.7831e+00,  1.9601e+00],\n",
       "          [-4.2688e-01,  6.1020e+00, -8.0590e+00,  ..., -6.4201e+00,\n",
       "            3.7801e+00,  9.6716e-01],\n",
       "          [ 6.8023e-01,  2.5632e+00, -7.5136e+00,  ..., -3.9286e+00,\n",
       "            5.4056e+00,  1.6387e+00],\n",
       "          ...,\n",
       "          [-2.1023e-01,  3.9161e+00, -4.9682e+00,  ..., -4.2201e+00,\n",
       "            2.7671e+00, -6.0608e-01],\n",
       "          [ 6.9537e+00, -5.1016e+00, -2.3546e+00,  ..., -6.0044e+00,\n",
       "           -2.4613e+00,  5.1108e+00],\n",
       "          [ 6.8612e+00, -1.5752e+00, -1.6087e+00,  ..., -8.1066e+00,\n",
       "           -3.1252e+00,  3.5798e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.4818e-01, -7.9345e+00, -9.4301e-01,  ...,  2.5492e+00,\n",
       "           -1.6841e+00,  3.9781e+00],\n",
       "          [-1.5651e+00, -6.7762e+00, -7.0524e-01,  ...,  2.0206e+00,\n",
       "            9.6088e-01,  4.7674e+00],\n",
       "          [-9.1597e-01, -6.7819e+00,  7.5939e-02,  ...,  5.3381e-01,\n",
       "           -7.8759e-01,  5.4658e+00],\n",
       "          ...,\n",
       "          [-2.8037e+00, -6.6024e+00, -1.2799e+00,  ..., -1.2927e+00,\n",
       "           -1.2325e+00,  7.8529e+00],\n",
       "          [-4.8273e+00,  2.4200e+00,  3.4624e+00,  ..., -1.8388e+00,\n",
       "           -2.7334e+00,  3.4514e+00],\n",
       "          [-3.8741e+00,  2.5525e+00,  5.4732e+00,  ..., -2.2043e+00,\n",
       "           -6.4414e-01,  1.7155e+00]],\n",
       "\n",
       "         [[ 3.5370e+00,  4.2439e+00, -1.0749e+00,  ...,  2.6689e+00,\n",
       "           -9.0535e+00, -2.3790e+00],\n",
       "          [ 5.3822e+00,  2.4570e+00,  5.9290e-01,  ...,  1.9185e+00,\n",
       "           -7.0418e+00, -3.9099e+00],\n",
       "          [ 3.3128e+00,  1.0992e+00, -4.4585e-02,  ...,  2.2001e+00,\n",
       "           -6.0126e+00, -2.6228e+00],\n",
       "          ...,\n",
       "          [ 1.9456e+00,  5.7416e-01, -1.8354e-02,  ...,  6.1072e+00,\n",
       "           -5.5561e+00, -3.1533e+00],\n",
       "          [ 2.8275e+00, -2.7355e+00,  9.0416e-01,  ..., -5.2512e+00,\n",
       "            3.8926e+00, -8.1762e-01],\n",
       "          [ 2.9122e+00, -3.4506e+00,  2.8942e+00,  ..., -5.8773e+00,\n",
       "            3.5703e+00, -1.5645e+00]],\n",
       "\n",
       "         [[-2.2765e+00, -4.3170e-03,  8.0491e-01,  ...,  2.4560e+00,\n",
       "           -1.4821e+00, -3.4222e+00],\n",
       "          [-2.9521e+00, -9.7465e-01,  5.0045e-01,  ...,  1.5521e+00,\n",
       "            1.0598e+00, -3.7983e+00],\n",
       "          [-7.8547e-02,  7.3140e-01,  1.1037e+00,  ...,  4.0816e+00,\n",
       "            2.5357e+00, -1.4820e+00],\n",
       "          ...,\n",
       "          [-1.2395e+00,  2.8185e-01, -4.7834e-01,  ...,  1.1506e+00,\n",
       "            2.0114e+00, -9.7549e-01],\n",
       "          [ 2.0489e+00, -4.0356e+00, -4.2357e+00,  ...,  3.6374e+00,\n",
       "           -8.6757e-01, -1.7104e+00],\n",
       "          [ 1.8156e+00, -6.9579e+00, -7.2117e+00,  ...,  3.3664e+00,\n",
       "           -2.0899e+00, -1.2301e+00]]]], grad_fn=<TransposeBackward0>), tensor([[[[-8.8874e-01, -9.2305e-01, -3.0210e+00,  ...,  1.2393e+00,\n",
       "           -2.7775e+00, -4.5004e+00],\n",
       "          [ 1.5307e+00, -1.8776e-01, -2.2727e+00,  ...,  3.0569e+00,\n",
       "           -2.0468e+00, -1.7431e+00],\n",
       "          [ 1.9603e-01, -1.5372e-01, -1.5488e+00,  ...,  1.8602e+00,\n",
       "           -2.2009e+00, -1.6868e+00],\n",
       "          ...,\n",
       "          [-1.5670e+00,  2.2197e+00,  4.6427e-01,  ...,  2.9529e+00,\n",
       "            1.6013e+00, -9.0079e-01],\n",
       "          [ 2.6978e+00,  1.3736e+00,  3.5192e+00,  ..., -7.1860e-01,\n",
       "           -7.0616e-01, -2.9572e+00],\n",
       "          [-9.7862e-01,  3.0832e-01, -5.2261e-01,  ...,  3.6913e-02,\n",
       "           -2.0693e+00,  8.1793e-01]],\n",
       "\n",
       "         [[ 4.3087e-01,  9.6875e-02,  4.1749e+00,  ..., -1.0487e+00,\n",
       "            4.3304e+00, -1.4987e+00],\n",
       "          [-2.1442e+00,  1.8844e+00,  3.3203e+00,  ...,  8.3414e-01,\n",
       "            3.8468e+00, -2.7255e+00],\n",
       "          [-1.6837e+00,  9.4495e-01,  4.0448e+00,  ..., -1.8191e-01,\n",
       "            3.6496e+00, -1.7243e+00],\n",
       "          ...,\n",
       "          [-3.4602e+00,  1.6838e+00, -7.8856e-01,  ..., -3.5225e+00,\n",
       "            1.4423e+00, -6.7136e-04],\n",
       "          [-4.4993e+00,  5.1218e+00, -1.1648e+00,  ..., -2.7775e+00,\n",
       "            8.3814e-01, -1.1545e-01],\n",
       "          [ 6.6759e-01, -3.1241e-01,  1.2571e+00,  ...,  1.4364e+00,\n",
       "           -1.1522e+00,  8.6685e-01]],\n",
       "\n",
       "         [[-4.5058e+00,  2.6134e-01,  4.2235e+00,  ...,  3.2232e+00,\n",
       "           -1.9310e+00, -2.8695e+00],\n",
       "          [-7.8783e+00,  1.0207e+00,  1.9198e+00,  ...,  5.1188e+00,\n",
       "           -3.7595e+00, -4.7449e+00],\n",
       "          [-7.2774e+00,  1.5590e+00, -1.8263e-01,  ...,  5.0625e+00,\n",
       "           -2.8870e+00, -2.1582e+00],\n",
       "          ...,\n",
       "          [-5.0348e+00,  1.1632e+00,  2.3237e+00,  ...,  2.6009e+00,\n",
       "            2.2893e-01, -1.4460e+00],\n",
       "          [-5.8470e+00,  3.3996e-01,  3.6100e+00,  ...,  5.4837e+00,\n",
       "            3.0204e+00, -3.3099e+00],\n",
       "          [ 4.1483e+00, -4.4249e-01, -8.0647e-01,  ..., -1.0136e-01,\n",
       "           -1.3484e+00,  1.2621e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.9206e-01,  1.3167e-02, -6.1307e-01,  ...,  3.6308e+00,\n",
       "           -1.1310e+00, -2.6172e+00],\n",
       "          [ 4.0747e-01,  9.6960e-02, -7.5861e-02,  ...,  3.7261e+00,\n",
       "           -4.0505e+00, -2.7208e-01],\n",
       "          [-5.9370e-01, -3.8418e-01,  8.5175e-01,  ...,  1.2369e+00,\n",
       "           -1.4095e+00, -1.8061e+00],\n",
       "          ...,\n",
       "          [-1.4923e-01, -3.8673e-02, -5.2453e-01,  ..., -1.0504e+00,\n",
       "            1.6006e+00, -1.2588e+00],\n",
       "          [ 1.3746e+00, -4.1948e-01,  7.7067e-01,  ...,  2.1832e+00,\n",
       "           -4.4655e-01,  2.9105e-01],\n",
       "          [ 1.9587e-01,  1.2780e+00, -6.9797e-01,  ...,  8.4015e-01,\n",
       "           -1.0211e+00, -1.1225e-01]],\n",
       "\n",
       "         [[ 3.2729e-01,  3.9532e+00,  1.6799e+00,  ...,  5.5929e-01,\n",
       "            2.3685e+00, -3.3145e+00],\n",
       "          [-6.9990e-01,  1.2623e+00, -2.0777e+00,  ..., -6.5397e-03,\n",
       "            1.7692e+00, -6.0590e+00],\n",
       "          [ 3.7869e-01,  4.3870e+00,  2.9121e+00,  ...,  1.0403e+00,\n",
       "            9.6737e-01, -4.1897e+00],\n",
       "          ...,\n",
       "          [-1.7978e+00,  7.8420e-01,  1.1247e+00,  ..., -1.8488e+00,\n",
       "            5.2890e+00, -2.5188e+00],\n",
       "          [-4.3301e+00, -2.7686e+00,  7.3224e-01,  ...,  1.5988e+00,\n",
       "            2.6202e+00, -2.2157e+00],\n",
       "          [ 5.0501e-01, -1.3317e+00, -1.0981e+00,  ..., -2.9694e-01,\n",
       "           -3.6577e-01, -7.9199e-01]],\n",
       "\n",
       "         [[ 7.6522e+00, -1.2765e+00,  2.1738e+00,  ...,  5.8816e-01,\n",
       "           -6.9715e-01,  1.6517e+00],\n",
       "          [ 5.3155e+00,  1.3433e+00,  1.5246e+00,  ...,  2.6628e+00,\n",
       "           -1.0225e+00,  3.8306e+00],\n",
       "          [ 4.0672e+00,  2.2783e-02,  1.3750e+00,  ...,  2.0502e+00,\n",
       "            1.1221e+00,  1.0305e+00],\n",
       "          ...,\n",
       "          [ 1.0242e+01,  3.1250e-01, -1.3969e+00,  ...,  5.4744e+00,\n",
       "            5.9933e+00, -2.0721e-01],\n",
       "          [ 5.8711e+00, -7.5746e-01, -2.5951e-01,  ...,  9.8326e-01,\n",
       "            5.3629e+00,  1.9670e+00],\n",
       "          [-5.0751e+00, -1.9249e-01,  9.6280e-01,  ..., -4.6707e-01,\n",
       "            1.2771e+00,  8.5378e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-2.6887, -0.5858, -5.3655,  ..., -4.9599, -0.5733,  2.4664],\n",
       "          [ 1.0052, -4.9668, -0.5837,  ..., -2.8449,  1.7590,  1.9382],\n",
       "          [-3.4676,  0.6731,  0.7416,  ..., -3.5864, -0.3528, -2.4751],\n",
       "          ...,\n",
       "          [-3.7374,  0.1643, -1.3711,  ..., -3.4134, -5.8661,  5.6035],\n",
       "          [-3.7825, -0.3887,  3.5966,  ..., -4.4421, -8.4639,  4.2595],\n",
       "          [-0.1507,  0.0832,  0.0156,  ...,  0.0823, -0.1868, -0.0435]],\n",
       "\n",
       "         [[-0.2159, -1.7228, -2.2858,  ..., -0.1795, -1.8652,  1.4543],\n",
       "          [-0.5185, -0.9978, -0.2200,  ..., -1.7324,  1.4743,  4.6451],\n",
       "          [-0.6004, -0.2096, -0.6189,  ..., -3.2894, -2.3708, -1.7479],\n",
       "          ...,\n",
       "          [-7.6824, -2.1230,  5.1987,  ...,  5.0586, -2.7780, -3.9888],\n",
       "          [ 3.0583,  3.0866,  1.1841,  ...,  1.3178,  0.1463,  0.9338],\n",
       "          [-0.1012, -0.0498, -0.0950,  ...,  0.0306,  0.1451, -0.2541]],\n",
       "\n",
       "         [[ 2.4520,  3.7963,  5.4042,  ...,  2.4147,  1.4399,  6.0180],\n",
       "          [ 2.0953,  1.2401, -0.7081,  ...,  0.3383,  0.8228, -1.6497],\n",
       "          [ 2.7813,  2.1453,  4.1788,  ...,  2.6351,  0.7586, -2.1132],\n",
       "          ...,\n",
       "          [ 1.8595,  4.4010, -5.0266,  ...,  4.0327,  0.3198, -0.6586],\n",
       "          [ 1.3712,  2.9589, -0.6903,  ...,  3.3494,  3.3161, -1.8501],\n",
       "          [-0.0860,  0.0206,  0.0759,  ...,  0.0151,  0.4039,  0.1002]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.7827,  0.1896, -1.4834,  ..., -0.5870, -1.6329,  1.6042],\n",
       "          [-1.6616, -2.9580, -2.7973,  ...,  0.0425,  1.5831, -0.4948],\n",
       "          [ 0.4088,  1.6562,  3.1462,  ...,  1.9916,  1.3173,  2.2184],\n",
       "          ...,\n",
       "          [ 0.2426,  1.7716, -2.4704,  ..., -0.4141, -2.9491,  5.7753],\n",
       "          [ 7.0942, -3.9547, -2.7835,  ..., -0.0309,  0.4136, -0.6906],\n",
       "          [ 0.1075, -0.0308, -0.2095,  ...,  0.0229, -0.1680,  0.0166]],\n",
       "\n",
       "         [[-0.1949, -0.8820,  4.0263,  ...,  2.3029, -2.0771,  0.5237],\n",
       "          [ 1.2551,  4.5389,  0.4138,  ...,  2.9173, -0.5605,  3.3014],\n",
       "          [ 0.9360,  2.5125, -3.3387,  ...,  0.4718,  3.1398, -0.4801],\n",
       "          ...,\n",
       "          [-2.0353,  3.3565,  0.9298,  ...,  3.0452, -1.6272,  5.3923],\n",
       "          [-0.3103,  2.7057,  0.3870,  ...,  3.4734,  1.1510,  5.1465],\n",
       "          [ 0.3327, -0.1342, -0.4123,  ..., -0.2005,  1.5173,  0.2850]],\n",
       "\n",
       "         [[ 1.2102,  3.5916,  2.8571,  ...,  0.4323,  3.4557,  2.7634],\n",
       "          [ 5.2894,  1.4295,  0.7971,  ...,  2.4542,  4.5256,  1.3037],\n",
       "          [ 2.8527,  0.2820,  1.2077,  ...,  3.9602,  3.1503, -0.2903],\n",
       "          ...,\n",
       "          [-0.9301,  2.3124, -3.8089,  ...,  0.6792,  2.4944,  0.6925],\n",
       "          [-4.1692, -1.4665, -0.3231,  ..., -1.2426,  1.4419,  3.3637],\n",
       "          [ 0.7998, -0.2317,  0.1670,  ..., -0.7213,  0.0415, -0.0100]]]],\n",
       "       grad_fn=<TransposeBackward0>)), (tensor([[[[-1.9305,  0.9599,  0.9430,  ..., -0.2295,  1.7841,  2.4732],\n",
       "          [-1.9787,  0.3470,  0.5803,  ..., -0.4895,  1.9169,  1.8318],\n",
       "          [-2.8075, -0.1240,  0.4053,  ..., -0.9213,  2.6305,  2.3212],\n",
       "          ...,\n",
       "          [-1.7370, -1.2335,  0.3009,  ...,  0.2396,  1.7735,  2.4950],\n",
       "          [-1.7840, -0.1564,  0.5360,  ...,  1.0846,  0.5999, -2.3302],\n",
       "          [-1.4271, -1.2362, -0.7176,  ...,  0.8771,  0.3656, -1.4069]],\n",
       "\n",
       "         [[-1.0095, -0.4151,  1.7887,  ...,  0.6774, -0.4362, -0.3053],\n",
       "          [-0.6808,  0.1753,  1.9249,  ...,  0.8303,  0.6934,  0.4192],\n",
       "          [-0.9941,  0.2424,  1.7874,  ...,  0.0511,  0.0325,  0.0949],\n",
       "          ...,\n",
       "          [-0.5246, -0.8982,  2.2774,  ...,  0.8956,  1.3373,  0.0103],\n",
       "          [ 1.1997, -1.8740,  0.2974,  ...,  1.0675,  1.6327, -1.1950],\n",
       "          [ 2.9283, -1.9186,  0.2720,  ...,  0.9834,  1.0600, -0.4351]],\n",
       "\n",
       "         [[ 0.0594,  1.1853,  2.1812,  ...,  3.2948,  0.0956,  0.6324],\n",
       "          [ 0.5270,  1.0096,  0.7416,  ...,  2.8004, -0.4776,  0.5249],\n",
       "          [ 0.7521,  1.0763,  0.3084,  ...,  3.5469, -0.1823,  1.1695],\n",
       "          ...,\n",
       "          [ 0.3040,  1.7230, -0.6104,  ...,  1.5148, -0.8547,  0.6211],\n",
       "          [ 0.8658,  0.4377,  2.6122,  ...,  1.4801,  0.4866,  0.3004],\n",
       "          [-0.4293,  1.8039,  0.3889,  ...,  0.6835, -0.1570,  1.6544]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.1323,  9.0284,  2.3594,  ..., -1.9974, -0.5540, -1.5227],\n",
       "          [-0.6874,  9.3876,  1.9349,  ..., -0.8235, -0.2654, -1.4312],\n",
       "          [-0.3889,  9.2718,  2.2980,  ..., -1.6385, -1.1098, -1.4040],\n",
       "          ...,\n",
       "          [ 0.9578,  9.7035,  1.6927,  ...,  0.4201, -0.6748, -3.9213],\n",
       "          [ 3.1646, 10.1556,  0.0367,  ..., -1.3377,  0.8400, -1.9347],\n",
       "          [ 2.9561,  8.8600, -0.5459,  ..., -1.3685, -0.3325, -2.0470]],\n",
       "\n",
       "         [[ 0.4662, -0.0981,  0.6502,  ..., -0.2494,  0.7961,  1.8811],\n",
       "          [-0.2122,  0.2052,  0.4139,  ...,  0.0496,  0.6984,  1.7162],\n",
       "          [-0.1110,  0.0623, -0.6755,  ...,  0.5034,  0.5502,  1.1484],\n",
       "          ...,\n",
       "          [-0.9582,  0.6528,  0.9042,  ...,  0.0699,  0.6041,  1.7572],\n",
       "          [ 0.7322, -2.7462, -0.1484,  ..., -0.4387, -1.4783,  0.7962],\n",
       "          [ 0.2565, -2.3550, -1.0618,  ..., -0.1585,  0.0563,  1.8661]],\n",
       "\n",
       "         [[-0.2014,  2.3687,  0.1074,  ..., -0.7261, -0.9003, -0.6981],\n",
       "          [ 1.3904,  2.0250,  1.0263,  ..., -0.5860, -0.4860,  0.0305],\n",
       "          [ 1.0372,  2.8429,  0.5335,  ..., -1.2922, -0.1087,  0.0815],\n",
       "          ...,\n",
       "          [ 2.2665,  0.7979,  0.2914,  ..., -0.4606, -0.4499, -0.3600],\n",
       "          [-0.9007,  2.5047,  1.9490,  ..., -0.9285, -0.1218, -0.7419],\n",
       "          [-0.0871, -0.0901,  1.9374,  ...,  1.0013, -0.5085,  0.1651]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[  0.9229,   0.5138,  -0.9737,  ...,  -0.4025,  -2.0316,  -1.4715],\n",
       "          [ -0.6733,   1.3029,  -0.9728,  ...,  -0.0641,  -3.4745,  -3.4280],\n",
       "          [ -0.0942,   1.4380,  -2.4086,  ...,  -1.8890,  -2.8879,  -1.7250],\n",
       "          ...,\n",
       "          [ -0.1670,   2.5511,  -3.8343,  ...,  -2.7362,  -1.5003,  -2.8381],\n",
       "          [  2.5276,   1.7527,  -3.3921,  ...,   0.4991,  -1.2273,  -1.1616],\n",
       "          [  2.3835,   1.1227,  -2.0798,  ...,   0.6657,  -2.4169,   0.7557]],\n",
       "\n",
       "         [[  0.6407,  -1.9954,  -2.1937,  ...,   2.9317,  -3.6443,   1.0333],\n",
       "          [  1.4286,  -0.6183,  -3.8219,  ...,   3.3347,  -2.6512,   0.3531],\n",
       "          [  2.6238,  -2.1158,  -3.0809,  ...,   4.9283,  -2.5131,   1.2761],\n",
       "          ...,\n",
       "          [  2.8218,   0.0789,  -2.5038,  ...,   3.2622,  -2.1486,   0.9929],\n",
       "          [ -4.4549,   0.1088,   1.1179,  ...,   0.0929,  -1.6389,  -1.6973],\n",
       "          [ -6.0263,   0.4678,   2.5929,  ...,   3.1025,  -3.0068,  -0.3952]],\n",
       "\n",
       "         [[  1.5050,   8.1011, -11.6294,  ...,   3.6272,   1.8370,  -6.1105],\n",
       "          [  0.0649,   8.1965, -11.3654,  ...,   2.7048,   2.3099,  -6.9442],\n",
       "          [  0.9839,   6.9062, -10.6404,  ...,   3.6102,   3.8341,  -7.0056],\n",
       "          ...,\n",
       "          [ -1.1659,   8.4562, -11.0723,  ...,   0.4788,   7.5801,  -8.7426],\n",
       "          [ -0.8984,  -4.7872,  -3.2273,  ...,  -2.1435,  -2.3923,  -1.0091],\n",
       "          [ -1.1237,  -7.2039,  -1.2807,  ...,  -3.0656,  -2.9905,  -5.0016]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ -0.1084,  -1.0307,  -3.4925,  ...,  -1.7509,   3.5622,   0.8935],\n",
       "          [  0.4110,  -2.1692,  -3.9208,  ...,  -1.4193,   1.6661,   0.8468],\n",
       "          [  0.3860,  -2.2771,  -4.1915,  ...,  -0.6933,   1.5189,   0.3566],\n",
       "          ...,\n",
       "          [  0.6980,  -2.1006,  -6.3652,  ...,  -1.5972,   2.4725,   0.5774],\n",
       "          [ -0.4078,  -0.3026,  -2.1191,  ...,   5.8932,   1.8350,   3.4433],\n",
       "          [  0.2545,   2.9612,  -4.7797,  ...,   5.6108,   3.3932,   4.8860]],\n",
       "\n",
       "         [[ -0.5829, -10.0602,  -2.1641,  ...,   2.1442,  -4.4180,  -3.3760],\n",
       "          [ -2.1551, -10.4987,  -2.6092,  ...,   2.6883,  -5.2185,  -2.3783],\n",
       "          [ -0.3293, -10.3806,  -1.1759,  ...,   2.9774,  -4.1887,  -1.1707],\n",
       "          ...,\n",
       "          [ -3.7011,  -9.5981,  -0.6567,  ...,   3.1301,  -1.5622,  -1.4260],\n",
       "          [  5.2879,  -7.1315,   1.1526,  ...,   6.0676,  -0.1225,  -3.7951],\n",
       "          [  1.5124,  -4.1605,   1.1116,  ...,   3.4476,  -0.5655,  -2.8496]],\n",
       "\n",
       "         [[  3.9604,  -5.5439,   0.5973,  ...,  -0.1595,  -6.6915,  -6.0707],\n",
       "          [  3.9384,  -7.3079,  -0.6434,  ...,  -3.9068,  -7.7493,  -4.8932],\n",
       "          [  5.6494,  -5.4299,  -2.0329,  ...,  -4.0064,  -5.2234,  -3.1538],\n",
       "          ...,\n",
       "          [ 10.0709,  -9.8594,   1.1273,  ...,  -7.1903,  -7.9580,  -2.2185],\n",
       "          [ -2.4025,  -4.6514,   1.8973,  ...,  -0.5945,  -2.3092,  -2.7791],\n",
       "          [ -1.4285,  -9.9432,   1.8718,  ...,  -0.7114,  -2.4613,  -3.6028]]]],\n",
       "       grad_fn=<TransposeBackward0>), tensor([[[[ 2.0896e+00, -4.0156e+00, -3.9335e+00,  ...,  3.2552e+00,\n",
       "            1.0386e+00, -3.9029e-01],\n",
       "          [-9.0029e-01, -8.1986e-01, -1.2419e+00,  ..., -2.9086e-01,\n",
       "            2.2339e+00, -7.2932e-01],\n",
       "          [ 9.7054e-01, -3.8928e+00, -2.3707e+00,  ..., -5.5946e-01,\n",
       "            2.7604e+00, -1.4969e-01],\n",
       "          ...,\n",
       "          [ 4.5207e-01, -2.6739e+00, -3.1637e+00,  ...,  1.8371e+00,\n",
       "           -7.6115e-01,  1.0201e+00],\n",
       "          [ 2.4290e+00, -8.9077e-01,  3.3305e-01,  ...,  3.3374e+00,\n",
       "            4.6581e+00, -5.9420e-01],\n",
       "          [-5.1108e-01, -4.8252e-01,  1.5455e-01,  ..., -6.8298e-01,\n",
       "           -1.3769e+00,  7.1595e-01]],\n",
       "\n",
       "         [[-2.6756e+00, -1.2680e-01,  4.2555e+00,  ...,  8.6146e-01,\n",
       "            5.4756e+00,  4.8080e+00],\n",
       "          [-2.7625e+00, -1.2328e-01,  2.0376e+00,  ...,  2.0263e+00,\n",
       "            6.6707e+00,  1.9972e+00],\n",
       "          [-5.1915e-01, -6.1820e-01,  2.5616e+00,  ..., -7.4658e-01,\n",
       "            5.3351e+00,  1.2964e+00],\n",
       "          ...,\n",
       "          [-4.4981e+00,  8.7079e-01,  2.3742e+00,  ..., -8.1779e-01,\n",
       "            5.6991e+00,  1.1431e+00],\n",
       "          [-4.1826e+00, -1.1997e+00,  2.1928e+00,  ..., -4.9788e-02,\n",
       "            7.2226e+00, -5.4305e-01],\n",
       "          [-3.1701e-01,  6.4177e-01,  4.4252e-02,  ..., -6.9748e-01,\n",
       "           -5.8335e+00, -6.1425e-01]],\n",
       "\n",
       "         [[ 4.5773e+00,  4.6346e+00, -2.8837e+00,  ...,  3.6033e+00,\n",
       "            2.9859e+00, -6.3866e-01],\n",
       "          [ 6.2783e+00,  5.3274e+00, -1.9551e+00,  ...,  3.8119e+00,\n",
       "            1.6379e+00, -1.8889e+00],\n",
       "          [ 4.1487e+00,  4.9454e+00, -2.6801e+00,  ...,  3.3606e+00,\n",
       "            4.2497e+00, -2.3863e+00],\n",
       "          ...,\n",
       "          [ 4.3479e+00,  4.9923e+00, -3.0131e+00,  ...,  5.8250e+00,\n",
       "            7.3726e-01, -1.3221e+00],\n",
       "          [ 4.0626e+00,  3.7028e+00, -3.5519e+00,  ...,  5.1296e+00,\n",
       "            1.4477e+00,  1.3084e+00],\n",
       "          [-3.3776e+00, -2.0960e+00,  2.5134e+00,  ..., -5.2091e-01,\n",
       "           -8.0671e-01,  6.7381e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.3922e-01,  1.1675e+00, -9.8254e-01,  ..., -1.1263e+00,\n",
       "            1.9215e+00, -3.9903e+00],\n",
       "          [ 5.8157e-01, -2.4671e+00, -3.1318e-01,  ..., -2.0612e+00,\n",
       "           -8.8010e-01, -4.8803e+00],\n",
       "          [-4.6828e-02,  5.1228e-01,  8.7681e-01,  ..., -5.4739e-01,\n",
       "           -1.7239e+00, -3.5329e+00],\n",
       "          ...,\n",
       "          [ 3.9166e+00, -4.5858e+00, -4.6846e+00,  ...,  4.2099e+00,\n",
       "           -9.6947e+00,  1.0599e+00],\n",
       "          [ 3.6356e+00,  4.1584e-01,  8.1220e-01,  ..., -1.3218e-02,\n",
       "           -5.3826e+00, -2.4753e+00],\n",
       "          [-5.0871e-01, -1.5207e-01, -1.2903e-02,  ...,  1.3600e-01,\n",
       "           -9.8352e-01,  2.2162e-01]],\n",
       "\n",
       "         [[ 4.5136e+00, -8.3581e-02,  5.0352e-03,  ...,  2.4520e+00,\n",
       "            2.8084e+00,  1.8621e+00],\n",
       "          [ 4.9249e+00,  1.1560e+00, -9.1473e-01,  ...,  1.1637e+00,\n",
       "            2.4453e+00,  1.2829e+00],\n",
       "          [ 4.4486e+00,  8.9362e-01,  2.0323e-01,  ...,  1.3052e+00,\n",
       "            2.1292e+00,  2.5716e+00],\n",
       "          ...,\n",
       "          [ 4.5875e+00,  2.3667e+00,  3.2195e+00,  ...,  3.1505e-01,\n",
       "            5.8343e+00, -2.3953e+00],\n",
       "          [ 4.1541e+00,  3.0478e+00,  3.9431e+00,  ..., -4.8642e-02,\n",
       "            9.1892e-01, -3.0528e+00],\n",
       "          [-3.8799e+00, -1.1910e+00,  6.7239e-01,  ...,  4.4734e-01,\n",
       "           -2.1713e+00, -3.1993e-01]],\n",
       "\n",
       "         [[ 1.9536e+00, -4.0768e-01,  1.3126e+00,  ...,  1.9033e+00,\n",
       "            3.5636e+00, -5.5530e-01],\n",
       "          [ 1.6665e+00, -2.5622e+00,  2.4237e+00,  ...,  1.6586e+00,\n",
       "            5.1936e-01,  6.1798e-01],\n",
       "          [ 9.4554e-01,  1.0223e+00,  1.9427e+00,  ...,  3.2100e-01,\n",
       "            1.3488e+00,  1.4056e+00],\n",
       "          ...,\n",
       "          [ 1.7544e+00, -3.9852e-01,  4.2929e-01,  ..., -1.0153e+00,\n",
       "           -1.2291e+00,  1.9330e+00],\n",
       "          [ 4.4831e+00,  2.6798e+00, -4.0639e+00,  ..., -1.9792e+00,\n",
       "            1.0392e+00,  9.3096e-01],\n",
       "          [-3.4218e-01,  5.9747e-01, -9.5315e-01,  ..., -5.7213e-02,\n",
       "            1.5288e-01, -3.2585e-01]]]], grad_fn=<TransposeBackward0>), tensor([[[[-0.1283,  2.6855, -7.6030,  ...,  7.4855, -1.9728, -1.5247],\n",
       "          [ 2.4163,  5.6022, -3.4573,  ...,  5.3814,  3.2526, -2.0357],\n",
       "          [-1.4161,  1.2543, -4.0864,  ...,  2.2228,  3.1849, -4.8698],\n",
       "          ...,\n",
       "          [-3.1820, -0.7906, -2.6751,  ..., -0.5868,  5.5667,  1.7008],\n",
       "          [ 2.2731,  2.6851, -3.1169,  ...,  0.8002,  1.5561,  2.7962],\n",
       "          [ 0.0384, -0.4500,  0.0432,  ...,  0.0329, -0.4248,  0.4240]],\n",
       "\n",
       "         [[-4.2024, -1.9601, -1.6566,  ..., -1.3576,  0.8716, -1.3672],\n",
       "          [-1.2070, -4.4417, -0.4280,  ..., -0.5234, -4.5778,  0.5566],\n",
       "          [-2.2286, -0.0341, -1.3358,  ...,  0.8237,  1.9350, -2.6449],\n",
       "          ...,\n",
       "          [ 6.7897, -0.2208, -3.0664,  ...,  0.8579,  0.0662,  1.4891],\n",
       "          [ 1.1836,  0.2475,  1.4559,  ...,  0.5289,  3.0444,  3.6346],\n",
       "          [-0.2213,  0.3408, -0.0856,  ..., -0.6302,  0.0334, -0.0154]],\n",
       "\n",
       "         [[-0.3565,  4.3966,  9.4206,  ..., -3.2442, -4.5092, -2.9496],\n",
       "          [ 0.2834, -0.9733,  2.8857,  ..., -3.2108, -6.0207,  1.2723],\n",
       "          [ 1.0318, -1.7203,  5.2056,  ..., -2.0877, -8.1722,  0.2588],\n",
       "          ...,\n",
       "          [ 3.7029, -4.2493,  2.0752,  ...,  1.7806,  2.5263,  1.1126],\n",
       "          [ 2.1438, -5.0591,  0.3865,  ..., -1.2965,  0.2154, -3.9805],\n",
       "          [-0.5843, -0.5134,  0.5301,  ..., -0.4611,  0.7203, -0.1608]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-5.2368,  4.2309, -1.8632,  ..., -1.4900, -3.4049,  2.6875],\n",
       "          [-4.2954,  1.6443, -2.0897,  ..., -0.0209, -3.2086,  5.1620],\n",
       "          [-5.5627,  1.5171, -1.9392,  ...,  4.2025, -5.3509, -2.7668],\n",
       "          ...,\n",
       "          [-1.5975,  2.1702, -3.7428,  ...,  5.1796, -7.8814,  3.0844],\n",
       "          [ 0.5582,  0.4250, -1.7574,  ...,  0.5915, -3.2695,  1.5053],\n",
       "          [-0.4785, -0.0926, -0.5621,  ...,  0.1282, -0.4936,  0.5428]],\n",
       "\n",
       "         [[ 1.1585,  5.0700, -0.6319,  ..., -0.7692, -5.4736, -0.1082],\n",
       "          [ 2.8426,  3.8264, -1.5601,  ..., -4.3016, -2.4611,  1.7478],\n",
       "          [-1.3297,  2.9846, -1.0728,  ..., -0.6717, -2.9494, -0.1483],\n",
       "          ...,\n",
       "          [ 0.0680,  0.6781,  6.9806,  ..., -0.0249, -2.2744, -0.0275],\n",
       "          [-4.9178, -0.3650,  2.4240,  ...,  2.8641, -1.1523,  0.7780],\n",
       "          [-0.0434, -0.2481,  0.1918,  ...,  0.3381, -2.0638,  0.0280]],\n",
       "\n",
       "         [[ 0.4236,  1.5220,  1.2307,  ..., -7.3991,  5.5817, -3.0870],\n",
       "          [-1.6190, -1.9564, -0.6789,  ..., -2.5639,  6.9571,  2.4044],\n",
       "          [-5.9250, -0.2315, -0.2599,  ..., -0.4898,  3.1948,  1.7010],\n",
       "          ...,\n",
       "          [ 4.3344,  1.3386,  2.8424,  ..., -1.0823,  2.8141, -0.1723],\n",
       "          [ 1.2254, -6.8566,  1.2401,  ..., -0.0466,  2.6480, -1.3729],\n",
       "          [ 0.1629, -0.4793,  0.6520,  ...,  0.1415, -0.1479, -0.0460]]]],\n",
       "       grad_fn=<TransposeBackward0>))), decoder_hidden_states=None, decoder_attentions=None, cross_attentions=None, encoder_last_hidden_state=tensor([[[-0.0027,  0.0580, -0.0989,  ...,  0.0459,  0.0221,  0.0420],\n",
       "         [ 0.0426,  0.0801, -0.0082,  ...,  0.0841,  0.0708,  0.0995],\n",
       "         [-0.0586,  0.0759, -0.0794,  ...,  0.1318,  0.0809,  0.1083],\n",
       "         ...,\n",
       "         [-0.0240,  0.2195,  0.0923,  ..., -0.0698,  0.1626, -0.2430],\n",
       "         [ 0.0323, -0.0714,  0.0269,  ...,  0.0566,  0.1744,  0.2459],\n",
       "         [ 0.0943,  0.0018, -0.0009,  ..., -0.0011,  0.0022,  0.0027]]],\n",
       "       grad_fn=<MulBackward0>), encoder_hidden_states=None, encoder_attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(64128, 768)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(64128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(64128, 768)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 12)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=64128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1387: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 20 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/tmp/ipykernel_3366/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">3936157323.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: '/tmp/ipykernel_3366/3936157323.py'</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3468</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">decode</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3465 │   │   # Convert inputs to python lists</span>                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3466 │   │   </span>token_ids = to_py_obj(token_ids)                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3467 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3468 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._decode(                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3469 │   │   │   </span>token_ids=token_ids,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3470 │   │   │   </span>skip_special_tokens=skip_special_tokens,                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3471 │   │   │   </span>clean_up_tokenization_spaces=clean_up_tokenization_spaces,                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.8/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">tokenization_utils_fast.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">551</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_decode</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">548 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">549 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(token_ids, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">int</span>):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">550 │   │   │   </span>token_ids = [token_ids]                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>551 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>text = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">552 │   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">553 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> clean_up_tokenization_spaces:                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">554 │   │   │   </span>clean_text = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.clean_up_tokenization(text)                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">TypeError: </span>argument <span style=\"color: #008000; text-decoration-color: #008000\">'ids'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'list'</span> object cannot be interpreted as an integer\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/tmp/ipykernel_3366/\u001b[0m\u001b[1;33m3936157323.py\u001b[0m:\u001b[94m1\u001b[0m in \u001b[92m<module>\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: '/tmp/ipykernel_3366/3936157323.py'\u001b[0m                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_base.py\u001b[0m:\u001b[94m3468\u001b[0m in \u001b[92mdecode\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3465 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Convert inputs to python lists\u001b[0m                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3466 \u001b[0m\u001b[2m│   │   \u001b[0mtoken_ids = to_py_obj(token_ids)                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3467 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3468 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._decode(                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3469 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_ids=token_ids,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3470 \u001b[0m\u001b[2m│   │   │   \u001b[0mskip_special_tokens=skip_special_tokens,                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3471 \u001b[0m\u001b[2m│   │   │   \u001b[0mclean_up_tokenization_spaces=clean_up_tokenization_spaces,                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.8/site-packages/transformers/\u001b[0m\u001b[1;33mtokenization_utils_fast.py\u001b[0m:\u001b[94m551\u001b[0m in \u001b[92m_decode\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m548 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m549 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(token_ids, \u001b[96mint\u001b[0m):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m550 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_ids = [token_ids]                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m551 \u001b[2m│   │   \u001b[0mtext = \u001b[96mself\u001b[0m._tokenizer.decode(token_ids, skip_special_tokens=skip_special_tokens   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m552 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m553 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m clean_up_tokenization_spaces:                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m554 \u001b[0m\u001b[2m│   │   │   \u001b[0mclean_text = \u001b[96mself\u001b[0m.clean_up_tokenization(text)                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mTypeError: \u001b[0margument \u001b[32m'ids'\u001b[0m: \u001b[32m'list'\u001b[0m object cannot be interpreted as an integer\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer.decode(model.generate(**input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
